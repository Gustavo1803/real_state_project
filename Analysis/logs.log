2024-10-15 21:26:21,690:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\osmnx\geocoder.py:110: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  gdf = gdf.append(_geocode_query_to_gdf(q, wr, by_osmid))

2024-10-15 21:26:50,422:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\osmnx\geocoder.py:110: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  gdf = gdf.append(_geocode_query_to_gdf(q, wr, by_osmid))

2024-10-15 21:27:05,477:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\osmnx\geocoder.py:110: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  gdf = gdf.append(_geocode_query_to_gdf(q, wr, by_osmid))

2024-10-15 21:27:20,632:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\osmnx\geocoder.py:110: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  gdf = gdf.append(_geocode_query_to_gdf(q, wr, by_osmid))

2024-10-15 21:29:23,673:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\osmnx\geocoder.py:110: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  gdf = gdf.append(_geocode_query_to_gdf(q, wr, by_osmid))

2024-10-15 21:29:35,957:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\osmnx\geocoder.py:110: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  gdf = gdf.append(_geocode_query_to_gdf(q, wr, by_osmid))

2024-10-15 21:29:44,192:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\osmnx\geocoder.py:110: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  gdf = gdf.append(_geocode_query_to_gdf(q, wr, by_osmid))

2024-10-15 21:36:38,031:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\osmnx\geocoder.py:110: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  gdf = gdf.append(_geocode_query_to_gdf(q, wr, by_osmid))

2024-10-15 21:36:46,209:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\osmnx\geocoder.py:110: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  gdf = gdf.append(_geocode_query_to_gdf(q, wr, by_osmid))

2024-10-15 21:41:34,905:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\osmnx\geocoder.py:110: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  gdf = gdf.append(_geocode_query_to_gdf(q, wr, by_osmid))

2024-10-15 21:41:38,112:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\osmnx\geocoder.py:110: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  gdf = gdf.append(_geocode_query_to_gdf(q, wr, by_osmid))

2024-10-15 21:41:38,137:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\IPython\core\interactiveshell.py:3337: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.
  if await self.run_code(code, result, async_=asy):

2024-10-15 21:41:38,219:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\geopandas\geodataframe.py:1442: UserWarning: Geometry column does not contain geometry.
  warnings.warn("Geometry column does not contain geometry.")

2024-10-15 21:41:58,783:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\osmnx\geocoder.py:110: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  gdf = gdf.append(_geocode_query_to_gdf(q, wr, by_osmid))

2024-10-15 21:41:58,804:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\IPython\core\interactiveshell.py:3337: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.
  if await self.run_code(code, result, async_=asy):

2024-10-15 21:41:58,870:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\geopandas\geodataframe.py:1442: UserWarning: Geometry column does not contain geometry.
  warnings.warn("Geometry column does not contain geometry.")

2024-10-15 21:46:37,445:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\osmnx\geocoder.py:110: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  gdf = gdf.append(_geocode_query_to_gdf(q, wr, by_osmid))

2024-10-15 21:46:37,462:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\IPython\core\interactiveshell.py:3337: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.
  if await self.run_code(code, result, async_=asy):

2024-10-15 21:46:37,511:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\geopandas\geodataframe.py:1442: UserWarning: Geometry column does not contain geometry.
  warnings.warn("Geometry column does not contain geometry.")

2024-10-15 21:48:18,053:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\osmnx\geocoder.py:110: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  gdf = gdf.append(_geocode_query_to_gdf(q, wr, by_osmid))

2024-10-15 21:48:18,071:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\IPython\core\interactiveshell.py:3337: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.
  if await self.run_code(code, result, async_=asy):

2024-10-15 21:48:18,126:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\geopandas\geodataframe.py:1442: UserWarning: Geometry column does not contain geometry.
  warnings.warn("Geometry column does not contain geometry.")

2024-10-15 21:50:05,084:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\osmnx\geocoder.py:110: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  gdf = gdf.append(_geocode_query_to_gdf(q, wr, by_osmid))

2024-10-15 21:50:05,101:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\IPython\core\interactiveshell.py:3337: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.
  if await self.run_code(code, result, async_=asy):

2024-10-15 21:50:05,152:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\geopandas\geodataframe.py:1442: UserWarning: Geometry column does not contain geometry.
  warnings.warn("Geometry column does not contain geometry.")

2024-10-15 21:50:23,939:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\osmnx\geocoder.py:110: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  gdf = gdf.append(_geocode_query_to_gdf(q, wr, by_osmid))

2024-10-15 21:50:23,954:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\IPython\core\interactiveshell.py:3337: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.
  if await self.run_code(code, result, async_=asy):

2024-10-15 21:50:24,005:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\geopandas\geodataframe.py:1442: UserWarning: Geometry column does not contain geometry.
  warnings.warn("Geometry column does not contain geometry.")

2024-10-15 21:51:16,872:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-10-15 21:51:16,873:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-10-15 21:51:16,873:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-10-15 21:51:16,873:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-10-15 21:51:17,105:INFO:PyCaret RegressionExperiment
2024-10-15 21:51:17,105:INFO:Logging name: reg-default-name
2024-10-15 21:51:17,105:INFO:ML Usecase: MLUsecase.REGRESSION
2024-10-15 21:51:17,105:INFO:version 3.3.0
2024-10-15 21:51:17,105:INFO:Initializing setup()
2024-10-15 21:51:17,105:INFO:self.USI: 8004
2024-10-15 21:51:17,105:INFO:self._variable_keys: {'fold_groups_param', 'X_train', 'fold_generator', 'idx', 'USI', '_available_plots', '_ml_usecase', 'n_jobs_param', 'transform_target_param', 'html_param', 'y', 'target_param', 'y_test', 'gpu_n_jobs_param', 'memory', 'exp_name_log', 'log_plots_param', 'fold_shuffle_param', 'seed', 'X', 'gpu_param', 'logging_param', 'exp_id', 'data', 'pipeline', 'y_train', 'X_test'}
2024-10-15 21:51:17,105:INFO:Checking environment
2024-10-15 21:51:17,105:INFO:python_version: 3.10.4
2024-10-15 21:51:17,105:INFO:python_build: ('tags/v3.10.4:9d38120', 'Mar 23 2022 23:13:41')
2024-10-15 21:51:17,105:INFO:machine: AMD64
2024-10-15 21:51:17,105:INFO:platform: Windows-10-10.0.22631-SP0
2024-10-15 21:51:17,105:INFO:Memory: svmem(total=16954937344, available=3588526080, percent=78.8, used=13366411264, free=3588526080)
2024-10-15 21:51:17,105:INFO:Physical Core: 4
2024-10-15 21:51:17,106:INFO:Logical Core: 8
2024-10-15 21:51:17,106:INFO:Checking libraries
2024-10-15 21:51:17,106:INFO:System:
2024-10-15 21:51:17,106:INFO:    python: 3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]
2024-10-15 21:51:17,106:INFO:executable: c:\Users\genin\AppData\Local\Programs\Python\Python310\python.exe
2024-10-15 21:51:17,106:INFO:   machine: Windows-10-10.0.22631-SP0
2024-10-15 21:51:17,106:INFO:PyCaret required dependencies:
2024-10-15 21:51:17,964:INFO:                 pip: 23.1
2024-10-15 21:51:17,964:INFO:          setuptools: 67.7.1
2024-10-15 21:51:17,964:INFO:             pycaret: 3.3.0
2024-10-15 21:51:17,964:INFO:             IPython: 8.3.0
2024-10-15 21:51:17,964:INFO:          ipywidgets: 8.1.2
2024-10-15 21:51:17,964:INFO:                tqdm: 4.66.2
2024-10-15 21:51:17,965:INFO:               numpy: 1.22.4
2024-10-15 21:51:17,965:INFO:              pandas: 1.4.2
2024-10-15 21:51:17,965:INFO:              jinja2: 3.1.2
2024-10-15 21:51:17,965:INFO:               scipy: 1.10.1
2024-10-15 21:51:17,965:INFO:              joblib: 1.2.0
2024-10-15 21:51:17,965:INFO:             sklearn: 1.4.1.post1
2024-10-15 21:51:17,965:INFO:                pyod: 1.1.3
2024-10-15 21:51:17,965:INFO:            imblearn: 0.12.0
2024-10-15 21:51:17,965:INFO:   category_encoders: 2.6.3
2024-10-15 21:51:17,965:INFO:            lightgbm: 4.3.0
2024-10-15 21:51:17,965:INFO:               numba: 0.58.1
2024-10-15 21:51:17,965:INFO:            requests: 2.27.1
2024-10-15 21:51:17,965:INFO:          matplotlib: 3.5.2
2024-10-15 21:51:17,965:INFO:          scikitplot: 0.3.7
2024-10-15 21:51:17,965:INFO:         yellowbrick: 1.5
2024-10-15 21:51:17,965:INFO:              plotly: 5.19.0
2024-10-15 21:51:17,965:INFO:    plotly-resampler: Not installed
2024-10-15 21:51:17,965:INFO:             kaleido: 0.2.1
2024-10-15 21:51:17,965:INFO:           schemdraw: 0.15
2024-10-15 21:51:17,965:INFO:         statsmodels: 0.14.1
2024-10-15 21:51:17,965:INFO:              sktime: 0.26.0
2024-10-15 21:51:17,965:INFO:               tbats: 1.1.3
2024-10-15 21:51:17,965:INFO:            pmdarima: 2.0.4
2024-10-15 21:51:17,965:INFO:              psutil: 5.9.0
2024-10-15 21:51:17,965:INFO:          markupsafe: 2.1.1
2024-10-15 21:51:17,965:INFO:             pickle5: Not installed
2024-10-15 21:51:17,965:INFO:         cloudpickle: 3.0.0
2024-10-15 21:51:17,965:INFO:         deprecation: 2.1.0
2024-10-15 21:51:17,965:INFO:              xxhash: 3.4.1
2024-10-15 21:51:17,966:INFO:           wurlitzer: Not installed
2024-10-15 21:51:17,966:INFO:PyCaret optional dependencies:
2024-10-15 21:51:18,164:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\trio\_core\_multierror.py:412: RuntimeWarning: IPython detected, but you already have a custom exception handler installed. I'll skip installing Trio's custom handler, but this means exception groups will not show full tracebacks.
  warnings.warn(

2024-10-15 21:51:22,601:INFO:                shap: 0.44.1
2024-10-15 21:51:22,602:INFO:           interpret: 0.5.1
2024-10-15 21:51:22,602:INFO:                umap: 0.5.5
2024-10-15 21:51:22,602:INFO:     ydata_profiling: 4.6.5
2024-10-15 21:51:22,602:INFO:  explainerdashboard: 0.4.5
2024-10-15 21:51:22,602:INFO:             autoviz: Not installed
2024-10-15 21:51:22,602:INFO:           fairlearn: 0.7.0
2024-10-15 21:51:22,602:INFO:          deepchecks: Not installed
2024-10-15 21:51:22,602:INFO:             xgboost: 2.0.3
2024-10-15 21:51:22,602:INFO:            catboost: 1.2.3
2024-10-15 21:51:22,602:INFO:              kmodes: 0.12.2
2024-10-15 21:51:22,602:INFO:             mlxtend: 0.23.1
2024-10-15 21:51:22,602:INFO:       statsforecast: 1.5.0
2024-10-15 21:51:22,602:INFO:        tune_sklearn: 0.5.0
2024-10-15 21:51:22,602:INFO:                 ray: 2.9.3
2024-10-15 21:51:22,602:INFO:            hyperopt: 0.2.7
2024-10-15 21:51:22,602:INFO:              optuna: 3.5.0
2024-10-15 21:51:22,602:INFO:               skopt: 0.9.0
2024-10-15 21:51:22,602:INFO:              mlflow: 2.11.0
2024-10-15 21:51:22,602:INFO:              gradio: 4.19.2
2024-10-15 21:51:22,603:INFO:             fastapi: 0.110.0
2024-10-15 21:51:22,603:INFO:             uvicorn: 0.27.1
2024-10-15 21:51:22,603:INFO:              m2cgen: 0.10.0
2024-10-15 21:51:22,603:INFO:           evidently: 0.4.16
2024-10-15 21:51:22,603:INFO:               fugue: 0.8.6
2024-10-15 21:51:22,603:INFO:           streamlit: Not installed
2024-10-15 21:51:22,603:INFO:             prophet: Not installed
2024-10-15 21:51:22,603:INFO:None
2024-10-15 21:51:22,603:INFO:Set up data.
2024-10-15 21:51:22,672:INFO:Set up folding strategy.
2024-10-15 21:51:22,672:INFO:Set up train/test split.
2024-10-15 21:51:22,684:INFO:Set up index.
2024-10-15 21:51:22,684:INFO:Assigning column types.
2024-10-15 21:51:22,690:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-10-15 21:51:22,690:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-10-15 21:51:22,696:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-10-15 21:51:22,702:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-10-15 21:51:22,788:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-10-15 21:51:22,844:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-10-15 21:51:22,845:INFO:Soft dependency imported: xgboost: 2.0.3
2024-10-15 21:51:22,849:INFO:Soft dependency imported: catboost: 1.2.3
2024-10-15 21:51:23,499:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-10-15 21:51:23,504:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-10-15 21:51:23,510:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-10-15 21:51:23,590:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-10-15 21:51:23,653:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-10-15 21:51:23,654:INFO:Soft dependency imported: xgboost: 2.0.3
2024-10-15 21:51:23,657:INFO:Soft dependency imported: catboost: 1.2.3
2024-10-15 21:51:23,658:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-10-15 21:51:23,664:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-10-15 21:51:23,669:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-10-15 21:51:23,751:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-10-15 21:51:23,807:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-10-15 21:51:23,807:INFO:Soft dependency imported: xgboost: 2.0.3
2024-10-15 21:51:23,810:INFO:Soft dependency imported: catboost: 1.2.3
2024-10-15 21:51:23,817:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-10-15 21:51:23,823:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-10-15 21:51:23,895:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-10-15 21:51:23,950:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-10-15 21:51:23,950:INFO:Soft dependency imported: xgboost: 2.0.3
2024-10-15 21:51:23,955:INFO:Soft dependency imported: catboost: 1.2.3
2024-10-15 21:51:23,956:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-10-15 21:51:23,967:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-10-15 21:51:24,038:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-10-15 21:51:24,090:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-10-15 21:51:24,091:INFO:Soft dependency imported: xgboost: 2.0.3
2024-10-15 21:51:24,094:INFO:Soft dependency imported: catboost: 1.2.3
2024-10-15 21:51:24,105:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-10-15 21:51:24,173:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-10-15 21:51:24,224:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-10-15 21:51:24,224:INFO:Soft dependency imported: xgboost: 2.0.3
2024-10-15 21:51:24,227:INFO:Soft dependency imported: catboost: 1.2.3
2024-10-15 21:51:24,228:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-10-15 21:51:24,305:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-10-15 21:51:24,358:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-10-15 21:51:24,359:INFO:Soft dependency imported: xgboost: 2.0.3
2024-10-15 21:51:24,362:INFO:Soft dependency imported: catboost: 1.2.3
2024-10-15 21:51:24,440:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-10-15 21:51:24,495:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-10-15 21:51:24,495:INFO:Soft dependency imported: xgboost: 2.0.3
2024-10-15 21:51:24,499:INFO:Soft dependency imported: catboost: 1.2.3
2024-10-15 21:51:24,500:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-10-15 21:51:24,589:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-10-15 21:51:24,646:INFO:Soft dependency imported: xgboost: 2.0.3
2024-10-15 21:51:24,650:INFO:Soft dependency imported: catboost: 1.2.3
2024-10-15 21:51:24,742:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-10-15 21:51:24,802:INFO:Soft dependency imported: xgboost: 2.0.3
2024-10-15 21:51:24,805:INFO:Soft dependency imported: catboost: 1.2.3
2024-10-15 21:51:24,805:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-10-15 21:51:24,945:INFO:Soft dependency imported: xgboost: 2.0.3
2024-10-15 21:51:24,948:INFO:Soft dependency imported: catboost: 1.2.3
2024-10-15 21:51:25,087:INFO:Soft dependency imported: xgboost: 2.0.3
2024-10-15 21:51:25,090:INFO:Soft dependency imported: catboost: 1.2.3
2024-10-15 21:51:25,108:INFO:Preparing preprocessing pipeline...
2024-10-15 21:51:25,108:INFO:Set up simple imputation.
2024-10-15 21:51:25,112:INFO:Set up encoding of categorical features.
2024-10-15 21:51:25,114:INFO:Set up column name cleaning.
2024-10-15 21:51:25,294:INFO:Finished creating preprocessing pipeline.
2024-10-15 21:51:25,308:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\genin\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Area Construida', 'Area Total',
                                             'Habitaciones', 'Baños', 'Patio',
                                             'Deposito 1', 'Piso 2',
                                             'Tipo de comedor sala comedor',
                                             'Depósito o cuarto útil',
                                             'Tipo de casa tradicional',
                                             'Piso 3', 'Tipo de estufa gas',
                                             'Lote vacio',
                                             'Número de Ascensores 1',
                                             'Ti...
                 TransformerWrapper(include=['Edad', 'Estrato', 'date', 'city'],
                                    transformer=OneHotEncoder(cols=['Edad',
                                                                    'Estrato',
                                                                    'date',
                                                                    'city'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['grid_id'],
                                    transformer=TargetEncoder(cols=['grid_id'],
                                                              handle_missing='return_nan'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2024-10-15 21:51:25,309:INFO:Creating final display dataframe.
2024-10-15 21:51:25,791:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            Precio
2                   Target type        Regression
3           Original data shape        (759, 194)
4        Transformed data shape        (759, 213)
5   Transformed train set shape        (531, 213)
6    Transformed test set shape        (228, 213)
7              Numeric features               188
8          Categorical features                 5
9      Rows with missing values            100.0%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              8004
2024-10-15 21:51:25,960:INFO:Soft dependency imported: xgboost: 2.0.3
2024-10-15 21:51:25,965:INFO:Soft dependency imported: catboost: 1.2.3
2024-10-15 21:51:26,111:INFO:Soft dependency imported: xgboost: 2.0.3
2024-10-15 21:51:26,115:INFO:Soft dependency imported: catboost: 1.2.3
2024-10-15 21:51:26,131:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:51: FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.
  warnings.warn(

2024-10-15 21:51:26,131:INFO:setup() successfully completed in 9.03s...............
2024-10-15 21:52:06,683:INFO:Initializing compare_models()
2024-10-15 21:52:06,683:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002232603E4D0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=10, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002232603E4D0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 10, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-10-15 21:52:06,684:INFO:Checking exceptions
2024-10-15 21:52:06,688:INFO:Preparing display monitor
2024-10-15 21:52:06,727:INFO:Initializing Linear Regression
2024-10-15 21:52:06,727:INFO:Total runtime is 0.0 minutes
2024-10-15 21:52:06,732:INFO:SubProcess create_model() called ==================================
2024-10-15 21:52:06,733:INFO:Initializing create_model()
2024-10-15 21:52:06,733:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002232603E4D0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002232603F730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 21:52:06,733:INFO:Checking exceptions
2024-10-15 21:52:06,733:INFO:Importing libraries
2024-10-15 21:52:06,733:INFO:Copying training dataset
2024-10-15 21:52:06,741:INFO:Defining folds
2024-10-15 21:52:06,741:INFO:Declaring metric variables
2024-10-15 21:52:06,745:INFO:Importing untrained model
2024-10-15 21:52:06,751:INFO:Linear Regression Imported successfully
2024-10-15 21:52:06,762:INFO:Starting cross validation
2024-10-15 21:52:06,778:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-15 21:52:20,606:INFO:Calculating mean and std
2024-10-15 21:52:20,608:INFO:Creating metrics dataframe
2024-10-15 21:52:20,614:INFO:Uploading results into container
2024-10-15 21:52:20,615:INFO:Uploading model into container now
2024-10-15 21:52:20,616:INFO:_master_model_container: 1
2024-10-15 21:52:20,616:INFO:_display_container: 2
2024-10-15 21:52:20,617:INFO:LinearRegression(n_jobs=-1)
2024-10-15 21:52:20,617:INFO:create_model() successfully completed......................................
2024-10-15 21:52:20,857:INFO:SubProcess create_model() end ==================================
2024-10-15 21:52:20,858:INFO:Creating metrics dataframe
2024-10-15 21:52:20,868:INFO:Initializing Lasso Regression
2024-10-15 21:52:20,869:INFO:Total runtime is 0.23570650021235148 minutes
2024-10-15 21:52:20,873:INFO:SubProcess create_model() called ==================================
2024-10-15 21:52:20,873:INFO:Initializing create_model()
2024-10-15 21:52:20,873:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002232603E4D0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002232603F730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 21:52:20,874:INFO:Checking exceptions
2024-10-15 21:52:20,874:INFO:Importing libraries
2024-10-15 21:52:20,874:INFO:Copying training dataset
2024-10-15 21:52:20,881:INFO:Defining folds
2024-10-15 21:52:20,881:INFO:Declaring metric variables
2024-10-15 21:52:20,886:INFO:Importing untrained model
2024-10-15 21:52:20,893:INFO:Lasso Regression Imported successfully
2024-10-15 21:52:20,905:INFO:Starting cross validation
2024-10-15 21:52:20,909:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-15 21:52:21,680:INFO:Calculating mean and std
2024-10-15 21:52:21,681:INFO:Creating metrics dataframe
2024-10-15 21:52:21,685:INFO:Uploading results into container
2024-10-15 21:52:21,687:INFO:Uploading model into container now
2024-10-15 21:52:21,687:INFO:_master_model_container: 2
2024-10-15 21:52:21,688:INFO:_display_container: 2
2024-10-15 21:52:21,688:INFO:Lasso(random_state=123)
2024-10-15 21:52:21,689:INFO:create_model() successfully completed......................................
2024-10-15 21:52:21,890:INFO:SubProcess create_model() end ==================================
2024-10-15 21:52:21,890:INFO:Creating metrics dataframe
2024-10-15 21:52:21,907:INFO:Initializing Ridge Regression
2024-10-15 21:52:21,907:INFO:Total runtime is 0.2530011773109436 minutes
2024-10-15 21:52:21,911:INFO:SubProcess create_model() called ==================================
2024-10-15 21:52:21,911:INFO:Initializing create_model()
2024-10-15 21:52:21,911:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002232603E4D0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002232603F730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 21:52:21,912:INFO:Checking exceptions
2024-10-15 21:52:21,912:INFO:Importing libraries
2024-10-15 21:52:21,912:INFO:Copying training dataset
2024-10-15 21:52:21,921:INFO:Defining folds
2024-10-15 21:52:21,921:INFO:Declaring metric variables
2024-10-15 21:52:21,925:INFO:Importing untrained model
2024-10-15 21:52:21,932:INFO:Ridge Regression Imported successfully
2024-10-15 21:52:21,942:INFO:Starting cross validation
2024-10-15 21:52:21,945:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-15 21:52:22,688:INFO:Calculating mean and std
2024-10-15 21:52:22,690:INFO:Creating metrics dataframe
2024-10-15 21:52:22,693:INFO:Uploading results into container
2024-10-15 21:52:22,694:INFO:Uploading model into container now
2024-10-15 21:52:22,694:INFO:_master_model_container: 3
2024-10-15 21:52:22,695:INFO:_display_container: 2
2024-10-15 21:52:22,695:INFO:Ridge(random_state=123)
2024-10-15 21:52:22,695:INFO:create_model() successfully completed......................................
2024-10-15 21:52:22,897:INFO:SubProcess create_model() end ==================================
2024-10-15 21:52:22,897:INFO:Creating metrics dataframe
2024-10-15 21:52:22,917:INFO:Initializing Elastic Net
2024-10-15 21:52:22,917:INFO:Total runtime is 0.2698274532953898 minutes
2024-10-15 21:52:22,922:INFO:SubProcess create_model() called ==================================
2024-10-15 21:52:22,922:INFO:Initializing create_model()
2024-10-15 21:52:22,922:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002232603E4D0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002232603F730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 21:52:22,922:INFO:Checking exceptions
2024-10-15 21:52:22,922:INFO:Importing libraries
2024-10-15 21:52:22,922:INFO:Copying training dataset
2024-10-15 21:52:22,930:INFO:Defining folds
2024-10-15 21:52:22,930:INFO:Declaring metric variables
2024-10-15 21:52:22,937:INFO:Importing untrained model
2024-10-15 21:52:22,961:INFO:Elastic Net Imported successfully
2024-10-15 21:52:22,979:INFO:Starting cross validation
2024-10-15 21:52:22,982:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-15 21:52:23,727:INFO:Calculating mean and std
2024-10-15 21:52:23,728:INFO:Creating metrics dataframe
2024-10-15 21:52:23,733:INFO:Uploading results into container
2024-10-15 21:52:23,734:INFO:Uploading model into container now
2024-10-15 21:52:23,734:INFO:_master_model_container: 4
2024-10-15 21:52:23,734:INFO:_display_container: 2
2024-10-15 21:52:23,735:INFO:ElasticNet(random_state=123)
2024-10-15 21:52:23,735:INFO:create_model() successfully completed......................................
2024-10-15 21:52:24,008:INFO:SubProcess create_model() end ==================================
2024-10-15 21:52:24,008:INFO:Creating metrics dataframe
2024-10-15 21:52:24,020:INFO:Initializing Least Angle Regression
2024-10-15 21:52:24,020:INFO:Total runtime is 0.28821580807367964 minutes
2024-10-15 21:52:24,025:INFO:SubProcess create_model() called ==================================
2024-10-15 21:52:24,026:INFO:Initializing create_model()
2024-10-15 21:52:24,026:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002232603E4D0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002232603F730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 21:52:24,026:INFO:Checking exceptions
2024-10-15 21:52:24,026:INFO:Importing libraries
2024-10-15 21:52:24,026:INFO:Copying training dataset
2024-10-15 21:52:24,036:INFO:Defining folds
2024-10-15 21:52:24,037:INFO:Declaring metric variables
2024-10-15 21:52:24,044:INFO:Importing untrained model
2024-10-15 21:52:24,050:INFO:Least Angle Regression Imported successfully
2024-10-15 21:52:24,060:INFO:Starting cross validation
2024-10-15 21:52:24,063:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-15 21:52:24,523:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=1.548e+00, with an active set of 105 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,524:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=1.761e+00, with an active set of 98 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(


2024-10-15 21:52:24,525:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 152 iterations, i.e. alpha=5.309e-01, with an active set of 140 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,529:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 181 iterations, i.e. alpha=8.264e-01, with an active set of 156 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,530:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 135 iterations, i.e. alpha=1.238e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,541:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=5.156e-01, with an active set of 157 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,542:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 138 iterations, i.e. alpha=1.170e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,550:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 210 iterations, i.e. alpha=2.216e+04, with an active set of 158 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,554:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 220 iterations, i.e. alpha=3.590e+01, with an active set of 177 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,554:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 220 iterations, i.e. alpha=3.459e+01, with an active set of 177 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,557:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 145 iterations, i.e. alpha=1.092e+00, with an active set of 135 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,589:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 216 iterations, i.e. alpha=1.109e+03, with an active set of 153 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,592:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 230 iterations, i.e. alpha=2.741e+01, with an active set of 183 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,594:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 232 iterations, i.e. alpha=2.631e+01, with an active set of 185 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,595:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 232 iterations, i.e. alpha=2.630e+01, with an active set of 185 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,600:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 223 iterations, i.e. alpha=1.576e+05, with an active set of 165 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,601:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 237 iterations, i.e. alpha=2.117e+01, with an active set of 188 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,601:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 256 iterations, i.e. alpha=2.414e+04, with an active set of 185 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,601:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 237 iterations, i.e. alpha=2.101e+01, with an active set of 188 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,602:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 237 iterations, i.e. alpha=2.087e+01, with an active set of 188 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,603:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 229 iterations, i.e. alpha=1.522e+01, with an active set of 182 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,603:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 256 iterations, i.e. alpha=1.161e+05, with an active set of 183 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,604:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 240 iterations, i.e. alpha=1.756e+01, with an active set of 190 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,605:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 240 iterations, i.e. alpha=1.755e+01, with an active set of 190 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,606:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 240 iterations, i.e. alpha=1.537e+01, with an active set of 190 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,606:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=2.303e+04, with an active set of 189 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,608:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 242 iterations, i.e. alpha=5.377e+00, with an active set of 192 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,608:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 264 iterations, i.e. alpha=1.768e+04, with an active set of 190 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,609:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 234 iterations, i.e. alpha=1.247e+01, with an active set of 186 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,609:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 242 iterations, i.e. alpha=5.354e+00, with an active set of 192 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,609:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 242 iterations, i.e. alpha=3.676e+00, with an active set of 192 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,610:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 265 iterations, i.e. alpha=1.385e+04, with an active set of 191 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,610:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 242 iterations, i.e. alpha=3.676e+00, with an active set of 192 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,610:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 265 iterations, i.e. alpha=1.313e+04, with an active set of 191 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,610:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 242 iterations, i.e. alpha=3.546e+00, with an active set of 192 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,611:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 237 iterations, i.e. alpha=8.355e+00, with an active set of 188 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,611:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 266 iterations, i.e. alpha=1.112e+04, with an active set of 192 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,615:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=5.977e+03, with an active set of 194 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,615:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=4.316e+03, with an active set of 194 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,616:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=2.939e+03, with an active set of 194 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,617:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=2.577e+03, with an active set of 194 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,618:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 240 iterations, i.e. alpha=7.144e+00, with an active set of 190 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,618:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 240 iterations, i.e. alpha=6.620e+00, with an active set of 190 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,620:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 257 iterations, i.e. alpha=2.318e+03, with an active set of 178 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,620:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 242 iterations, i.e. alpha=6.766e+00, with an active set of 191 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,621:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 242 iterations, i.e. alpha=5.165e+00, with an active set of 191 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,621:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 258 iterations, i.e. alpha=1.095e+05, with an active set of 185 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,623:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 243 iterations, i.e. alpha=3.663e+00, with an active set of 192 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,623:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 243 iterations, i.e. alpha=2.897e+00, with an active set of 192 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,624:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 243 iterations, i.e. alpha=1.827e+00, with an active set of 192 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,624:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 243 iterations, i.e. alpha=8.703e-01, with an active set of 192 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,625:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 243 iterations, i.e. alpha=5.560e-01, with an active set of 192 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,625:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 263 iterations, i.e. alpha=8.773e+04, with an active set of 187 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,625:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 243 iterations, i.e. alpha=1.173e-01, with an active set of 192 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,626:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 263 iterations, i.e. alpha=8.470e+04, with an active set of 187 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,626:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 263 iterations, i.e. alpha=8.054e+04, with an active set of 187 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,627:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 261 iterations, i.e. alpha=5.500e+05, with an active set of 186 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,628:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 265 iterations, i.e. alpha=7.090e+04, with an active set of 188 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,629:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 266 iterations, i.e. alpha=5.382e+04, with an active set of 189 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,630:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 266 iterations, i.e. alpha=4.870e+04, with an active set of 189 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,630:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 266 iterations, i.e. alpha=4.751e+04, with an active set of 189 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,633:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 265 iterations, i.e. alpha=4.005e+05, with an active set of 189 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,634:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 265 iterations, i.e. alpha=3.864e+05, with an active set of 189 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,634:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 265 iterations, i.e. alpha=3.807e+05, with an active set of 189 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,634:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=4.297e+04, with an active set of 191 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,635:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 265 iterations, i.e. alpha=3.617e+05, with an active set of 189 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,635:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=3.201e+04, with an active set of 191 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,635:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 275 iterations, i.e. alpha=4.483e+04, with an active set of 190 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,635:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=2.328e+04, with an active set of 191 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,636:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=2.150e+04, with an active set of 191 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,636:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 266 iterations, i.e. alpha=1.940e+05, with an active set of 190 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,636:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 276 iterations, i.e. alpha=1.386e+04, with an active set of 191 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,636:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 266 iterations, i.e. alpha=1.831e+05, with an active set of 190 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,636:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=3.515e+03, with an active set of 191 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,637:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 276 iterations, i.e. alpha=1.366e+04, with an active set of 191 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,637:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=3.038e+03, with an active set of 191 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,637:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 276 iterations, i.e. alpha=1.366e+04, with an active set of 191 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,637:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 276 iterations, i.e. alpha=1.333e+04, with an active set of 191 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,638:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 277 iterations, i.e. alpha=1.286e+04, with an active set of 192 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,640:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 279 iterations, i.e. alpha=1.535e+04, with an active set of 193 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,641:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 279 iterations, i.e. alpha=4.478e+03, with an active set of 193 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,641:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 279 iterations, i.e. alpha=4.437e+03, with an active set of 193 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,641:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 279 iterations, i.e. alpha=4.375e+03, with an active set of 193 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,642:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 279 iterations, i.e. alpha=4.361e+03, with an active set of 193 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,642:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 279 iterations, i.e. alpha=4.174e+03, with an active set of 193 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,646:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 268 iterations, i.e. alpha=1.182e+05, with an active set of 191 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,647:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 268 iterations, i.e. alpha=8.432e+04, with an active set of 191 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,647:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=2.152e+06, with an active set of 194 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,647:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=1.937e+06, with an active set of 194 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,648:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=1.423e+06, with an active set of 194 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,648:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=3.627e+05, with an active set of 194 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,649:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=4.157e+04, with an active set of 192 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,649:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=4.139e+04, with an active set of 192 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,650:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=2.401e+04, with an active set of 192 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,650:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=1.780e+04, with an active set of 192 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,651:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=1.672e+04, with an active set of 192 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,651:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=1.659e+04, with an active set of 192 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,645:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 240 iterations, i.e. alpha=7.771e+02, with an active set of 186 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,673:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 243 iterations, i.e. alpha=8.828e+02, with an active set of 187 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,673:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 243 iterations, i.e. alpha=7.690e+02, with an active set of 187 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,675:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 246 iterations, i.e. alpha=6.982e+02, with an active set of 189 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,677:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 247 iterations, i.e. alpha=5.437e+02, with an active set of 190 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,678:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 247 iterations, i.e. alpha=3.802e+02, with an active set of 190 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,679:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 247 iterations, i.e. alpha=3.617e+02, with an active set of 190 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,680:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 248 iterations, i.e. alpha=2.376e+02, with an active set of 191 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,681:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 248 iterations, i.e. alpha=1.127e+02, with an active set of 191 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,682:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 248 iterations, i.e. alpha=8.029e+01, with an active set of 191 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,682:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 248 iterations, i.e. alpha=3.773e+01, with an active set of 191 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,684:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 249 iterations, i.e. alpha=1.203e+01, with an active set of 192 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,685:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 249 iterations, i.e. alpha=5.140e+00, with an active set of 192 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,685:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 249 iterations, i.e. alpha=3.009e+00, with an active set of 192 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:24,686:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 249 iterations, i.e. alpha=2.507e+00, with an active set of 192 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:25,008:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 124 iterations, i.e. alpha=1.673e+00, with an active set of 112 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:25,052:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 243 iterations, i.e. alpha=1.215e+01, with an active set of 185 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:25,052:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 243 iterations, i.e. alpha=1.183e+01, with an active set of 185 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:25,058:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 258 iterations, i.e. alpha=6.361e+01, with an active set of 190 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:25,058:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 258 iterations, i.e. alpha=4.052e+01, with an active set of 190 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:25,058:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 258 iterations, i.e. alpha=3.984e+01, with an active set of 190 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:25,058:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 240 iterations, i.e. alpha=6.861e+02, with an active set of 180 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:25,058:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 258 iterations, i.e. alpha=3.633e+01, with an active set of 190 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:25,059:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 258 iterations, i.e. alpha=3.519e+01, with an active set of 190 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:25,060:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 261 iterations, i.e. alpha=1.606e+01, with an active set of 192 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:25,060:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 261 iterations, i.e. alpha=1.414e+01, with an active set of 192 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:25,060:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 245 iterations, i.e. alpha=6.979e+02, with an active set of 183 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:25,061:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=4.515e+00, with an active set of 193 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:25,061:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=4.118e+00, with an active set of 193 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:25,061:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=3.740e+00, with an active set of 193 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:25,061:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 248 iterations, i.e. alpha=4.871e+02, with an active set of 185 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:25,062:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=5.735e-01, with an active set of 193 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:25,062:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=5.067e-01, with an active set of 193 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:25,064:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 253 iterations, i.e. alpha=3.464e+02, with an active set of 189 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:25,064:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 253 iterations, i.e. alpha=3.157e+02, with an active set of 189 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:25,066:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 255 iterations, i.e. alpha=2.352e+02, with an active set of 191 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:25,066:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 255 iterations, i.e. alpha=2.265e+02, with an active set of 191 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:25,067:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 255 iterations, i.e. alpha=1.397e+02, with an active set of 191 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:25,067:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 255 iterations, i.e. alpha=1.219e+02, with an active set of 191 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:25,068:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 257 iterations, i.e. alpha=6.170e+01, with an active set of 193 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:25,068:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 257 iterations, i.e. alpha=5.522e+01, with an active set of 193 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:25,069:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 257 iterations, i.e. alpha=3.974e+01, with an active set of 193 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:25,069:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 257 iterations, i.e. alpha=7.178e+00, with an active set of 193 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:25,069:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 257 iterations, i.e. alpha=5.895e+00, with an active set of 193 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:25,145:INFO:Calculating mean and std
2024-10-15 21:52:25,148:INFO:Creating metrics dataframe
2024-10-15 21:52:25,153:INFO:Uploading results into container
2024-10-15 21:52:25,154:INFO:Uploading model into container now
2024-10-15 21:52:25,155:INFO:_master_model_container: 5
2024-10-15 21:52:25,156:INFO:_display_container: 2
2024-10-15 21:52:25,156:INFO:Lars(random_state=123)
2024-10-15 21:52:25,156:INFO:create_model() successfully completed......................................
2024-10-15 21:52:25,354:INFO:SubProcess create_model() end ==================================
2024-10-15 21:52:25,354:INFO:Creating metrics dataframe
2024-10-15 21:52:25,365:INFO:Initializing Lasso Least Angle Regression
2024-10-15 21:52:25,365:INFO:Total runtime is 0.3106358488400777 minutes
2024-10-15 21:52:25,369:INFO:SubProcess create_model() called ==================================
2024-10-15 21:52:25,369:INFO:Initializing create_model()
2024-10-15 21:52:25,369:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002232603E4D0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002232603F730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 21:52:25,369:INFO:Checking exceptions
2024-10-15 21:52:25,370:INFO:Importing libraries
2024-10-15 21:52:25,370:INFO:Copying training dataset
2024-10-15 21:52:25,376:INFO:Defining folds
2024-10-15 21:52:25,376:INFO:Declaring metric variables
2024-10-15 21:52:25,380:INFO:Importing untrained model
2024-10-15 21:52:25,387:INFO:Lasso Least Angle Regression Imported successfully
2024-10-15 21:52:25,419:INFO:Starting cross validation
2024-10-15 21:52:25,423:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-15 21:52:25,798:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=2.305e+00, with an active set of 68 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:25,799:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 77 iterations, i.e. alpha=2.302e+00, with an active set of 69 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:25,946:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 119 iterations, i.e. alpha=1.216e+00, with an active set of 105 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:25,947:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=1.214e+00, with an active set of 106 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:52:26,356:INFO:Calculating mean and std
2024-10-15 21:52:26,358:INFO:Creating metrics dataframe
2024-10-15 21:52:26,361:INFO:Uploading results into container
2024-10-15 21:52:26,362:INFO:Uploading model into container now
2024-10-15 21:52:26,362:INFO:_master_model_container: 6
2024-10-15 21:52:26,362:INFO:_display_container: 2
2024-10-15 21:52:26,363:INFO:LassoLars(random_state=123)
2024-10-15 21:52:26,363:INFO:create_model() successfully completed......................................
2024-10-15 21:52:26,578:INFO:SubProcess create_model() end ==================================
2024-10-15 21:52:26,578:INFO:Creating metrics dataframe
2024-10-15 21:52:26,591:INFO:Initializing Orthogonal Matching Pursuit
2024-10-15 21:52:26,591:INFO:Total runtime is 0.3310725887616475 minutes
2024-10-15 21:52:26,597:INFO:SubProcess create_model() called ==================================
2024-10-15 21:52:26,598:INFO:Initializing create_model()
2024-10-15 21:52:26,599:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002232603E4D0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002232603F730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 21:52:26,599:INFO:Checking exceptions
2024-10-15 21:52:26,599:INFO:Importing libraries
2024-10-15 21:52:26,599:INFO:Copying training dataset
2024-10-15 21:52:26,610:INFO:Defining folds
2024-10-15 21:52:26,610:INFO:Declaring metric variables
2024-10-15 21:52:26,616:INFO:Importing untrained model
2024-10-15 21:52:26,623:INFO:Orthogonal Matching Pursuit Imported successfully
2024-10-15 21:52:26,679:INFO:Starting cross validation
2024-10-15 21:52:26,686:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-15 21:52:27,445:INFO:Calculating mean and std
2024-10-15 21:52:27,446:INFO:Creating metrics dataframe
2024-10-15 21:52:27,451:INFO:Uploading results into container
2024-10-15 21:52:27,452:INFO:Uploading model into container now
2024-10-15 21:52:27,452:INFO:_master_model_container: 7
2024-10-15 21:52:27,452:INFO:_display_container: 2
2024-10-15 21:52:27,452:INFO:OrthogonalMatchingPursuit()
2024-10-15 21:52:27,452:INFO:create_model() successfully completed......................................
2024-10-15 21:52:27,640:INFO:SubProcess create_model() end ==================================
2024-10-15 21:52:27,640:INFO:Creating metrics dataframe
2024-10-15 21:52:27,654:INFO:Initializing Bayesian Ridge
2024-10-15 21:52:27,654:INFO:Total runtime is 0.34878862301508584 minutes
2024-10-15 21:52:27,660:INFO:SubProcess create_model() called ==================================
2024-10-15 21:52:27,660:INFO:Initializing create_model()
2024-10-15 21:52:27,660:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002232603E4D0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002232603F730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 21:52:27,660:INFO:Checking exceptions
2024-10-15 21:52:27,660:INFO:Importing libraries
2024-10-15 21:52:27,661:INFO:Copying training dataset
2024-10-15 21:52:27,669:INFO:Defining folds
2024-10-15 21:52:27,670:INFO:Declaring metric variables
2024-10-15 21:52:27,675:INFO:Importing untrained model
2024-10-15 21:52:27,680:INFO:Bayesian Ridge Imported successfully
2024-10-15 21:52:27,695:INFO:Starting cross validation
2024-10-15 21:52:27,701:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-15 21:52:28,548:INFO:Calculating mean and std
2024-10-15 21:52:28,550:INFO:Creating metrics dataframe
2024-10-15 21:52:28,554:INFO:Uploading results into container
2024-10-15 21:52:28,555:INFO:Uploading model into container now
2024-10-15 21:52:28,556:INFO:_master_model_container: 8
2024-10-15 21:52:28,556:INFO:_display_container: 2
2024-10-15 21:52:28,557:INFO:BayesianRidge()
2024-10-15 21:52:28,558:INFO:create_model() successfully completed......................................
2024-10-15 21:52:28,760:INFO:SubProcess create_model() end ==================================
2024-10-15 21:52:28,760:INFO:Creating metrics dataframe
2024-10-15 21:52:28,816:INFO:Initializing Passive Aggressive Regressor
2024-10-15 21:52:28,817:INFO:Total runtime is 0.3681715965270996 minutes
2024-10-15 21:52:28,822:INFO:SubProcess create_model() called ==================================
2024-10-15 21:52:28,822:INFO:Initializing create_model()
2024-10-15 21:52:28,822:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002232603E4D0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002232603F730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 21:52:28,823:INFO:Checking exceptions
2024-10-15 21:52:28,823:INFO:Importing libraries
2024-10-15 21:52:28,823:INFO:Copying training dataset
2024-10-15 21:52:28,836:INFO:Defining folds
2024-10-15 21:52:28,838:INFO:Declaring metric variables
2024-10-15 21:52:28,842:INFO:Importing untrained model
2024-10-15 21:52:28,848:INFO:Passive Aggressive Regressor Imported successfully
2024-10-15 21:52:28,859:INFO:Starting cross validation
2024-10-15 21:52:28,863:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-15 21:52:29,636:INFO:Calculating mean and std
2024-10-15 21:52:29,637:INFO:Creating metrics dataframe
2024-10-15 21:52:29,643:INFO:Uploading results into container
2024-10-15 21:52:29,644:INFO:Uploading model into container now
2024-10-15 21:52:29,645:INFO:_master_model_container: 9
2024-10-15 21:52:29,645:INFO:_display_container: 2
2024-10-15 21:52:29,645:INFO:PassiveAggressiveRegressor(random_state=123)
2024-10-15 21:52:29,645:INFO:create_model() successfully completed......................................
2024-10-15 21:52:29,839:INFO:SubProcess create_model() end ==================================
2024-10-15 21:52:29,839:INFO:Creating metrics dataframe
2024-10-15 21:52:29,853:INFO:Initializing Huber Regressor
2024-10-15 21:52:29,853:INFO:Total runtime is 0.3854417006174723 minutes
2024-10-15 21:52:29,858:INFO:SubProcess create_model() called ==================================
2024-10-15 21:52:29,858:INFO:Initializing create_model()
2024-10-15 21:52:29,858:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002232603E4D0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002232603F730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 21:52:29,858:INFO:Checking exceptions
2024-10-15 21:52:29,858:INFO:Importing libraries
2024-10-15 21:52:29,858:INFO:Copying training dataset
2024-10-15 21:52:29,868:INFO:Defining folds
2024-10-15 21:52:29,868:INFO:Declaring metric variables
2024-10-15 21:52:29,873:INFO:Importing untrained model
2024-10-15 21:52:29,879:INFO:Huber Regressor Imported successfully
2024-10-15 21:52:29,889:INFO:Starting cross validation
2024-10-15 21:52:29,891:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-15 21:52:30,528:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-10-15 21:52:30,551:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-10-15 21:52:30,551:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-10-15 21:52:30,584:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-10-15 21:52:30,591:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-10-15 21:52:30,611:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-10-15 21:52:30,627:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-10-15 21:52:31,108:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-10-15 21:52:31,128:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-10-15 21:52:31,206:INFO:Calculating mean and std
2024-10-15 21:52:31,208:INFO:Creating metrics dataframe
2024-10-15 21:52:31,213:INFO:Uploading results into container
2024-10-15 21:52:31,214:INFO:Uploading model into container now
2024-10-15 21:52:31,215:INFO:_master_model_container: 10
2024-10-15 21:52:31,215:INFO:_display_container: 2
2024-10-15 21:52:31,215:INFO:HuberRegressor()
2024-10-15 21:52:31,215:INFO:create_model() successfully completed......................................
2024-10-15 21:52:31,414:INFO:SubProcess create_model() end ==================================
2024-10-15 21:52:31,414:INFO:Creating metrics dataframe
2024-10-15 21:52:31,427:INFO:Initializing K Neighbors Regressor
2024-10-15 21:52:31,427:INFO:Total runtime is 0.4116658051808675 minutes
2024-10-15 21:52:31,431:INFO:SubProcess create_model() called ==================================
2024-10-15 21:52:31,432:INFO:Initializing create_model()
2024-10-15 21:52:31,433:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002232603E4D0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002232603F730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 21:52:31,433:INFO:Checking exceptions
2024-10-15 21:52:31,433:INFO:Importing libraries
2024-10-15 21:52:31,433:INFO:Copying training dataset
2024-10-15 21:52:31,439:INFO:Defining folds
2024-10-15 21:52:31,439:INFO:Declaring metric variables
2024-10-15 21:52:31,443:INFO:Importing untrained model
2024-10-15 21:52:31,449:INFO:K Neighbors Regressor Imported successfully
2024-10-15 21:52:31,457:INFO:Starting cross validation
2024-10-15 21:52:31,460:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-15 21:52:32,380:INFO:Calculating mean and std
2024-10-15 21:52:32,381:INFO:Creating metrics dataframe
2024-10-15 21:52:32,385:INFO:Uploading results into container
2024-10-15 21:52:32,386:INFO:Uploading model into container now
2024-10-15 21:52:32,386:INFO:_master_model_container: 11
2024-10-15 21:52:32,386:INFO:_display_container: 2
2024-10-15 21:52:32,386:INFO:KNeighborsRegressor(n_jobs=-1)
2024-10-15 21:52:32,387:INFO:create_model() successfully completed......................................
2024-10-15 21:52:32,584:INFO:SubProcess create_model() end ==================================
2024-10-15 21:52:32,584:INFO:Creating metrics dataframe
2024-10-15 21:52:32,598:INFO:Initializing Decision Tree Regressor
2024-10-15 21:52:32,598:INFO:Total runtime is 0.43118869860966996 minutes
2024-10-15 21:52:32,603:INFO:SubProcess create_model() called ==================================
2024-10-15 21:52:32,604:INFO:Initializing create_model()
2024-10-15 21:52:32,604:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002232603E4D0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002232603F730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 21:52:32,604:INFO:Checking exceptions
2024-10-15 21:52:32,604:INFO:Importing libraries
2024-10-15 21:52:32,604:INFO:Copying training dataset
2024-10-15 21:52:32,611:INFO:Defining folds
2024-10-15 21:52:32,611:INFO:Declaring metric variables
2024-10-15 21:52:32,615:INFO:Importing untrained model
2024-10-15 21:52:32,622:INFO:Decision Tree Regressor Imported successfully
2024-10-15 21:52:32,670:INFO:Starting cross validation
2024-10-15 21:52:32,675:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-15 21:52:33,494:INFO:Calculating mean and std
2024-10-15 21:52:33,496:INFO:Creating metrics dataframe
2024-10-15 21:52:33,500:INFO:Uploading results into container
2024-10-15 21:52:33,500:INFO:Uploading model into container now
2024-10-15 21:52:33,501:INFO:_master_model_container: 12
2024-10-15 21:52:33,501:INFO:_display_container: 2
2024-10-15 21:52:33,501:INFO:DecisionTreeRegressor(random_state=123)
2024-10-15 21:52:33,501:INFO:create_model() successfully completed......................................
2024-10-15 21:52:33,700:INFO:SubProcess create_model() end ==================================
2024-10-15 21:52:33,700:INFO:Creating metrics dataframe
2024-10-15 21:52:33,716:INFO:Initializing Random Forest Regressor
2024-10-15 21:52:33,716:INFO:Total runtime is 0.449826431274414 minutes
2024-10-15 21:52:33,721:INFO:SubProcess create_model() called ==================================
2024-10-15 21:52:33,722:INFO:Initializing create_model()
2024-10-15 21:52:33,722:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002232603E4D0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002232603F730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 21:52:33,722:INFO:Checking exceptions
2024-10-15 21:52:33,722:INFO:Importing libraries
2024-10-15 21:52:33,722:INFO:Copying training dataset
2024-10-15 21:52:33,733:INFO:Defining folds
2024-10-15 21:52:33,733:INFO:Declaring metric variables
2024-10-15 21:52:33,740:INFO:Importing untrained model
2024-10-15 21:52:33,747:INFO:Random Forest Regressor Imported successfully
2024-10-15 21:52:33,757:INFO:Starting cross validation
2024-10-15 21:52:33,761:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-15 21:52:38,822:INFO:Calculating mean and std
2024-10-15 21:52:38,825:INFO:Creating metrics dataframe
2024-10-15 21:52:38,831:INFO:Uploading results into container
2024-10-15 21:52:38,832:INFO:Uploading model into container now
2024-10-15 21:52:38,832:INFO:_master_model_container: 13
2024-10-15 21:52:38,832:INFO:_display_container: 2
2024-10-15 21:52:38,833:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-10-15 21:52:38,833:INFO:create_model() successfully completed......................................
2024-10-15 21:52:39,067:INFO:SubProcess create_model() end ==================================
2024-10-15 21:52:39,067:INFO:Creating metrics dataframe
2024-10-15 21:52:39,093:INFO:Initializing Extra Trees Regressor
2024-10-15 21:52:39,093:INFO:Total runtime is 0.5394285917282104 minutes
2024-10-15 21:52:39,100:INFO:SubProcess create_model() called ==================================
2024-10-15 21:52:39,100:INFO:Initializing create_model()
2024-10-15 21:52:39,102:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002232603E4D0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002232603F730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 21:52:39,102:INFO:Checking exceptions
2024-10-15 21:52:39,102:INFO:Importing libraries
2024-10-15 21:52:39,102:INFO:Copying training dataset
2024-10-15 21:52:39,132:INFO:Defining folds
2024-10-15 21:52:39,132:INFO:Declaring metric variables
2024-10-15 21:52:39,141:INFO:Importing untrained model
2024-10-15 21:52:39,150:INFO:Extra Trees Regressor Imported successfully
2024-10-15 21:52:39,163:INFO:Starting cross validation
2024-10-15 21:52:39,166:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-15 21:52:44,766:INFO:Calculating mean and std
2024-10-15 21:52:44,768:INFO:Creating metrics dataframe
2024-10-15 21:52:44,773:INFO:Uploading results into container
2024-10-15 21:52:44,774:INFO:Uploading model into container now
2024-10-15 21:52:44,774:INFO:_master_model_container: 14
2024-10-15 21:52:44,776:INFO:_display_container: 2
2024-10-15 21:52:44,776:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-10-15 21:52:44,777:INFO:create_model() successfully completed......................................
2024-10-15 21:52:44,994:INFO:SubProcess create_model() end ==================================
2024-10-15 21:52:44,994:INFO:Creating metrics dataframe
2024-10-15 21:52:45,010:INFO:Initializing AdaBoost Regressor
2024-10-15 21:52:45,010:INFO:Total runtime is 0.6380601406097413 minutes
2024-10-15 21:52:45,015:INFO:SubProcess create_model() called ==================================
2024-10-15 21:52:45,015:INFO:Initializing create_model()
2024-10-15 21:52:45,015:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002232603E4D0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002232603F730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 21:52:45,015:INFO:Checking exceptions
2024-10-15 21:52:45,015:INFO:Importing libraries
2024-10-15 21:52:45,015:INFO:Copying training dataset
2024-10-15 21:52:45,024:INFO:Defining folds
2024-10-15 21:52:45,025:INFO:Declaring metric variables
2024-10-15 21:52:45,029:INFO:Importing untrained model
2024-10-15 21:52:45,036:INFO:AdaBoost Regressor Imported successfully
2024-10-15 21:52:45,046:INFO:Starting cross validation
2024-10-15 21:52:45,050:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-15 21:52:46,782:INFO:Calculating mean and std
2024-10-15 21:52:46,784:INFO:Creating metrics dataframe
2024-10-15 21:52:46,788:INFO:Uploading results into container
2024-10-15 21:52:46,788:INFO:Uploading model into container now
2024-10-15 21:52:46,789:INFO:_master_model_container: 15
2024-10-15 21:52:46,789:INFO:_display_container: 2
2024-10-15 21:52:46,789:INFO:AdaBoostRegressor(random_state=123)
2024-10-15 21:52:46,789:INFO:create_model() successfully completed......................................
2024-10-15 21:52:46,983:INFO:SubProcess create_model() end ==================================
2024-10-15 21:52:46,983:INFO:Creating metrics dataframe
2024-10-15 21:52:47,000:INFO:Initializing Gradient Boosting Regressor
2024-10-15 21:52:47,000:INFO:Total runtime is 0.6712260683377584 minutes
2024-10-15 21:52:47,006:INFO:SubProcess create_model() called ==================================
2024-10-15 21:52:47,006:INFO:Initializing create_model()
2024-10-15 21:52:47,006:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002232603E4D0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002232603F730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 21:52:47,007:INFO:Checking exceptions
2024-10-15 21:52:47,007:INFO:Importing libraries
2024-10-15 21:52:47,007:INFO:Copying training dataset
2024-10-15 21:52:47,014:INFO:Defining folds
2024-10-15 21:52:47,014:INFO:Declaring metric variables
2024-10-15 21:52:47,019:INFO:Importing untrained model
2024-10-15 21:52:47,024:INFO:Gradient Boosting Regressor Imported successfully
2024-10-15 21:52:47,032:INFO:Starting cross validation
2024-10-15 21:52:47,037:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-15 21:52:48,985:INFO:Calculating mean and std
2024-10-15 21:52:48,987:INFO:Creating metrics dataframe
2024-10-15 21:52:48,992:INFO:Uploading results into container
2024-10-15 21:52:48,992:INFO:Uploading model into container now
2024-10-15 21:52:48,993:INFO:_master_model_container: 16
2024-10-15 21:52:48,993:INFO:_display_container: 2
2024-10-15 21:52:48,993:INFO:GradientBoostingRegressor(random_state=123)
2024-10-15 21:52:48,993:INFO:create_model() successfully completed......................................
2024-10-15 21:52:49,185:INFO:SubProcess create_model() end ==================================
2024-10-15 21:52:49,185:INFO:Creating metrics dataframe
2024-10-15 21:52:49,199:INFO:Initializing Extreme Gradient Boosting
2024-10-15 21:52:49,199:INFO:Total runtime is 0.7078766465187073 minutes
2024-10-15 21:52:49,205:INFO:SubProcess create_model() called ==================================
2024-10-15 21:52:49,205:INFO:Initializing create_model()
2024-10-15 21:52:49,205:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002232603E4D0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002232603F730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 21:52:49,205:INFO:Checking exceptions
2024-10-15 21:52:49,205:INFO:Importing libraries
2024-10-15 21:52:49,205:INFO:Copying training dataset
2024-10-15 21:52:49,213:INFO:Defining folds
2024-10-15 21:52:49,213:INFO:Declaring metric variables
2024-10-15 21:52:49,217:INFO:Importing untrained model
2024-10-15 21:52:49,225:INFO:Extreme Gradient Boosting Imported successfully
2024-10-15 21:52:49,232:INFO:Starting cross validation
2024-10-15 21:52:49,236:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-15 21:52:52,289:INFO:Calculating mean and std
2024-10-15 21:52:52,290:INFO:Creating metrics dataframe
2024-10-15 21:52:52,294:INFO:Uploading results into container
2024-10-15 21:52:52,294:INFO:Uploading model into container now
2024-10-15 21:52:52,295:INFO:_master_model_container: 17
2024-10-15 21:52:52,295:INFO:_display_container: 2
2024-10-15 21:52:52,296:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=123, ...)
2024-10-15 21:52:52,296:INFO:create_model() successfully completed......................................
2024-10-15 21:52:52,488:INFO:SubProcess create_model() end ==================================
2024-10-15 21:52:52,488:INFO:Creating metrics dataframe
2024-10-15 21:52:52,507:INFO:Initializing Light Gradient Boosting Machine
2024-10-15 21:52:52,507:INFO:Total runtime is 0.7629954139391582 minutes
2024-10-15 21:52:52,511:INFO:SubProcess create_model() called ==================================
2024-10-15 21:52:52,511:INFO:Initializing create_model()
2024-10-15 21:52:52,511:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002232603E4D0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002232603F730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 21:52:52,512:INFO:Checking exceptions
2024-10-15 21:52:52,512:INFO:Importing libraries
2024-10-15 21:52:52,512:INFO:Copying training dataset
2024-10-15 21:52:52,520:INFO:Defining folds
2024-10-15 21:52:52,521:INFO:Declaring metric variables
2024-10-15 21:52:52,525:INFO:Importing untrained model
2024-10-15 21:52:52,530:INFO:Light Gradient Boosting Machine Imported successfully
2024-10-15 21:52:52,539:INFO:Starting cross validation
2024-10-15 21:52:52,544:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-15 21:52:54,562:INFO:Calculating mean and std
2024-10-15 21:52:54,565:INFO:Creating metrics dataframe
2024-10-15 21:52:54,572:INFO:Uploading results into container
2024-10-15 21:52:54,573:INFO:Uploading model into container now
2024-10-15 21:52:54,574:INFO:_master_model_container: 18
2024-10-15 21:52:54,575:INFO:_display_container: 2
2024-10-15 21:52:54,575:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-10-15 21:52:54,576:INFO:create_model() successfully completed......................................
2024-10-15 21:52:54,806:INFO:SubProcess create_model() end ==================================
2024-10-15 21:52:54,806:INFO:Creating metrics dataframe
2024-10-15 21:52:54,822:INFO:Initializing CatBoost Regressor
2024-10-15 21:52:54,822:INFO:Total runtime is 0.801593021551768 minutes
2024-10-15 21:52:54,826:INFO:SubProcess create_model() called ==================================
2024-10-15 21:52:54,827:INFO:Initializing create_model()
2024-10-15 21:52:54,827:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002232603E4D0>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002232603F730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 21:52:54,827:INFO:Checking exceptions
2024-10-15 21:52:54,827:INFO:Importing libraries
2024-10-15 21:52:54,827:INFO:Copying training dataset
2024-10-15 21:52:54,835:INFO:Defining folds
2024-10-15 21:52:54,835:INFO:Declaring metric variables
2024-10-15 21:52:54,840:INFO:Importing untrained model
2024-10-15 21:52:54,853:INFO:CatBoost Regressor Imported successfully
2024-10-15 21:52:54,861:INFO:Starting cross validation
2024-10-15 21:52:54,865:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-15 21:53:11,258:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
5 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 276, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\catboost\core.py", line 5807, in fit
    return self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline,
  File "c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\catboost\core.py", line 2396, in _fit
    self._train(
  File "c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\catboost\core.py", line 1776, in _train
    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)
  File "_catboost.pyx", line 4833, in _catboost._CatBoost._train
  File "_catboost.pyx", line 4882, in _catboost._CatBoost._train
_catboost.CatBoostError: C:/Go_Agent/pipelines/BuildMaster/catboost.git/catboost/libs/train_lib/dir_helper.cpp:20: Can't create train working dir: catboost_info

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-10-15 21:53:11,258:INFO:Calculating mean and std
2024-10-15 21:53:11,260:INFO:Creating metrics dataframe
2024-10-15 21:53:11,265:INFO:Uploading results into container
2024-10-15 21:53:11,266:INFO:Uploading model into container now
2024-10-15 21:53:11,267:INFO:_master_model_container: 19
2024-10-15 21:53:11,267:INFO:_display_container: 2
2024-10-15 21:53:11,267:INFO:<catboost.core.CatBoostRegressor object at 0x000002234AEC86A0>
2024-10-15 21:53:11,267:INFO:create_model() successfully completed......................................
2024-10-15 21:53:11,535:WARNING:create_model() for <catboost.core.CatBoostRegressor object at 0x000002234AEC86A0> raised an exception or returned all 0.0, trying without fit_kwargs:
2024-10-15 21:53:11,568:WARNING:Traceback (most recent call last):
  File "c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 796, in compare_models
    assert (
AssertionError

2024-10-15 21:53:11,568:INFO:Initializing create_model()
2024-10-15 21:53:11,569:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002232603E4D0>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002232603F730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 21:53:11,569:INFO:Checking exceptions
2024-10-15 21:53:11,569:INFO:Importing libraries
2024-10-15 21:53:11,569:INFO:Copying training dataset
2024-10-15 21:53:11,576:INFO:Defining folds
2024-10-15 21:53:11,576:INFO:Declaring metric variables
2024-10-15 21:53:11,580:INFO:Importing untrained model
2024-10-15 21:53:11,587:INFO:CatBoost Regressor Imported successfully
2024-10-15 21:53:11,598:INFO:Starting cross validation
2024-10-15 21:53:11,602:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-15 21:53:44,259:INFO:Calculating mean and std
2024-10-15 21:53:44,261:INFO:Creating metrics dataframe
2024-10-15 21:53:44,265:INFO:Uploading results into container
2024-10-15 21:53:44,267:INFO:Uploading model into container now
2024-10-15 21:53:44,267:INFO:_master_model_container: 20
2024-10-15 21:53:44,267:INFO:_display_container: 2
2024-10-15 21:53:44,267:INFO:<catboost.core.CatBoostRegressor object at 0x000002234AEC8910>
2024-10-15 21:53:44,268:INFO:create_model() successfully completed......................................
2024-10-15 21:53:44,508:INFO:SubProcess create_model() end ==================================
2024-10-15 21:53:44,508:INFO:Creating metrics dataframe
2024-10-15 21:53:44,529:INFO:Initializing Dummy Regressor
2024-10-15 21:53:44,529:INFO:Total runtime is 1.6300430377324422 minutes
2024-10-15 21:53:44,533:INFO:SubProcess create_model() called ==================================
2024-10-15 21:53:44,534:INFO:Initializing create_model()
2024-10-15 21:53:44,534:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002232603E4D0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002232603F730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 21:53:44,534:INFO:Checking exceptions
2024-10-15 21:53:44,534:INFO:Importing libraries
2024-10-15 21:53:44,534:INFO:Copying training dataset
2024-10-15 21:53:44,543:INFO:Defining folds
2024-10-15 21:53:44,544:INFO:Declaring metric variables
2024-10-15 21:53:44,548:INFO:Importing untrained model
2024-10-15 21:53:44,554:INFO:Dummy Regressor Imported successfully
2024-10-15 21:53:44,566:INFO:Starting cross validation
2024-10-15 21:53:44,570:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-15 21:53:45,341:INFO:Calculating mean and std
2024-10-15 21:53:45,343:INFO:Creating metrics dataframe
2024-10-15 21:53:45,348:INFO:Uploading results into container
2024-10-15 21:53:45,349:INFO:Uploading model into container now
2024-10-15 21:53:45,350:INFO:_master_model_container: 21
2024-10-15 21:53:45,350:INFO:_display_container: 2
2024-10-15 21:53:45,350:INFO:DummyRegressor()
2024-10-15 21:53:45,351:INFO:create_model() successfully completed......................................
2024-10-15 21:53:45,602:INFO:SubProcess create_model() end ==================================
2024-10-15 21:53:45,602:INFO:Creating metrics dataframe
2024-10-15 21:53:45,753:INFO:Initializing create_model()
2024-10-15 21:53:45,753:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002232603E4D0>, estimator=<catboost.core.CatBoostRegressor object at 0x000002234AEC8910>, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 21:53:45,754:INFO:Checking exceptions
2024-10-15 21:53:45,760:INFO:Importing libraries
2024-10-15 21:53:45,760:INFO:Copying training dataset
2024-10-15 21:53:45,773:INFO:Defining folds
2024-10-15 21:53:45,774:INFO:Declaring metric variables
2024-10-15 21:53:45,774:INFO:Importing untrained model
2024-10-15 21:53:45,774:INFO:Declaring custom model
2024-10-15 21:53:45,775:INFO:CatBoost Regressor Imported successfully
2024-10-15 21:53:45,779:INFO:Cross validation set to False
2024-10-15 21:53:45,780:INFO:Fitting Model
2024-10-15 21:53:51,274:INFO:<catboost.core.CatBoostRegressor object at 0x000002234AECA0B0>
2024-10-15 21:53:51,274:INFO:create_model() successfully completed......................................
2024-10-15 21:53:51,484:INFO:Initializing create_model()
2024-10-15 21:53:51,485:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002232603E4D0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 21:53:51,485:INFO:Checking exceptions
2024-10-15 21:53:51,489:INFO:Importing libraries
2024-10-15 21:53:51,489:INFO:Copying training dataset
2024-10-15 21:53:51,495:INFO:Defining folds
2024-10-15 21:53:51,495:INFO:Declaring metric variables
2024-10-15 21:53:51,495:INFO:Importing untrained model
2024-10-15 21:53:51,495:INFO:Declaring custom model
2024-10-15 21:53:51,496:INFO:Random Forest Regressor Imported successfully
2024-10-15 21:53:51,498:INFO:Cross validation set to False
2024-10-15 21:53:51,498:INFO:Fitting Model
2024-10-15 21:53:52,059:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-10-15 21:53:52,060:INFO:create_model() successfully completed......................................
2024-10-15 21:53:52,269:INFO:Initializing create_model()
2024-10-15 21:53:52,270:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002232603E4D0>, estimator=KNeighborsRegressor(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 21:53:52,270:INFO:Checking exceptions
2024-10-15 21:53:52,273:INFO:Importing libraries
2024-10-15 21:53:52,273:INFO:Copying training dataset
2024-10-15 21:53:52,279:INFO:Defining folds
2024-10-15 21:53:52,279:INFO:Declaring metric variables
2024-10-15 21:53:52,280:INFO:Importing untrained model
2024-10-15 21:53:52,280:INFO:Declaring custom model
2024-10-15 21:53:52,280:INFO:K Neighbors Regressor Imported successfully
2024-10-15 21:53:52,284:INFO:Cross validation set to False
2024-10-15 21:53:52,284:INFO:Fitting Model
2024-10-15 21:53:52,425:INFO:KNeighborsRegressor(n_jobs=-1)
2024-10-15 21:53:52,425:INFO:create_model() successfully completed......................................
2024-10-15 21:53:52,616:INFO:Initializing create_model()
2024-10-15 21:53:52,616:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002232603E4D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 21:53:52,616:INFO:Checking exceptions
2024-10-15 21:53:52,619:INFO:Importing libraries
2024-10-15 21:53:52,619:INFO:Copying training dataset
2024-10-15 21:53:52,625:INFO:Defining folds
2024-10-15 21:53:52,626:INFO:Declaring metric variables
2024-10-15 21:53:52,626:INFO:Importing untrained model
2024-10-15 21:53:52,626:INFO:Declaring custom model
2024-10-15 21:53:52,627:INFO:Light Gradient Boosting Machine Imported successfully
2024-10-15 21:53:52,629:INFO:Cross validation set to False
2024-10-15 21:53:52,629:INFO:Fitting Model
2024-10-15 21:53:52,762:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-10-15 21:53:52,767:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001117 seconds.
2024-10-15 21:53:52,767:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-10-15 21:53:52,767:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-10-15 21:53:52,772:INFO:[LightGBM] [Info] Total Bins 748
2024-10-15 21:53:52,772:INFO:[LightGBM] [Info] Number of data points in the train set: 531, number of used features: 189
2024-10-15 21:53:52,773:INFO:[LightGBM] [Info] Start training from score 449.982630
2024-10-15 21:53:52,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:53:52,857:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-10-15 21:53:52,857:INFO:create_model() successfully completed......................................
2024-10-15 21:53:53,072:INFO:Initializing create_model()
2024-10-15 21:53:53,073:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002232603E4D0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 21:53:53,073:INFO:Checking exceptions
2024-10-15 21:53:53,075:INFO:Importing libraries
2024-10-15 21:53:53,076:INFO:Copying training dataset
2024-10-15 21:53:53,081:INFO:Defining folds
2024-10-15 21:53:53,081:INFO:Declaring metric variables
2024-10-15 21:53:53,081:INFO:Importing untrained model
2024-10-15 21:53:53,081:INFO:Declaring custom model
2024-10-15 21:53:53,082:INFO:Extra Trees Regressor Imported successfully
2024-10-15 21:53:53,085:INFO:Cross validation set to False
2024-10-15 21:53:53,085:INFO:Fitting Model
2024-10-15 21:53:53,731:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-10-15 21:53:53,731:INFO:create_model() successfully completed......................................
2024-10-15 21:53:53,937:INFO:Initializing create_model()
2024-10-15 21:53:53,937:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002232603E4D0>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 21:53:53,937:INFO:Checking exceptions
2024-10-15 21:53:53,940:INFO:Importing libraries
2024-10-15 21:53:53,940:INFO:Copying training dataset
2024-10-15 21:53:53,946:INFO:Defining folds
2024-10-15 21:53:53,946:INFO:Declaring metric variables
2024-10-15 21:53:53,946:INFO:Importing untrained model
2024-10-15 21:53:53,946:INFO:Declaring custom model
2024-10-15 21:53:53,947:INFO:Gradient Boosting Regressor Imported successfully
2024-10-15 21:53:53,951:INFO:Cross validation set to False
2024-10-15 21:53:53,951:INFO:Fitting Model
2024-10-15 21:53:54,435:INFO:GradientBoostingRegressor(random_state=123)
2024-10-15 21:53:54,436:INFO:create_model() successfully completed......................................
2024-10-15 21:53:54,639:INFO:Initializing create_model()
2024-10-15 21:53:54,639:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002232603E4D0>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=123, ...), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 21:53:54,639:INFO:Checking exceptions
2024-10-15 21:53:54,641:INFO:Importing libraries
2024-10-15 21:53:54,641:INFO:Copying training dataset
2024-10-15 21:53:54,647:INFO:Defining folds
2024-10-15 21:53:54,647:INFO:Declaring metric variables
2024-10-15 21:53:54,647:INFO:Importing untrained model
2024-10-15 21:53:54,647:INFO:Declaring custom model
2024-10-15 21:53:54,649:INFO:Extreme Gradient Boosting Imported successfully
2024-10-15 21:53:54,653:INFO:Cross validation set to False
2024-10-15 21:53:54,653:INFO:Fitting Model
2024-10-15 21:53:56,142:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=123, ...)
2024-10-15 21:53:56,143:INFO:create_model() successfully completed......................................
2024-10-15 21:53:56,374:INFO:Initializing create_model()
2024-10-15 21:53:56,374:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002232603E4D0>, estimator=AdaBoostRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 21:53:56,375:INFO:Checking exceptions
2024-10-15 21:53:56,376:INFO:Importing libraries
2024-10-15 21:53:56,377:INFO:Copying training dataset
2024-10-15 21:53:56,384:INFO:Defining folds
2024-10-15 21:53:56,384:INFO:Declaring metric variables
2024-10-15 21:53:56,385:INFO:Importing untrained model
2024-10-15 21:53:56,385:INFO:Declaring custom model
2024-10-15 21:53:56,385:INFO:AdaBoost Regressor Imported successfully
2024-10-15 21:53:56,388:INFO:Cross validation set to False
2024-10-15 21:53:56,388:INFO:Fitting Model
2024-10-15 21:53:56,795:INFO:AdaBoostRegressor(random_state=123)
2024-10-15 21:53:56,795:INFO:create_model() successfully completed......................................
2024-10-15 21:53:56,983:INFO:Initializing create_model()
2024-10-15 21:53:56,983:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002232603E4D0>, estimator=DecisionTreeRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 21:53:56,984:INFO:Checking exceptions
2024-10-15 21:53:56,985:INFO:Importing libraries
2024-10-15 21:53:56,985:INFO:Copying training dataset
2024-10-15 21:53:56,991:INFO:Defining folds
2024-10-15 21:53:56,991:INFO:Declaring metric variables
2024-10-15 21:53:56,991:INFO:Importing untrained model
2024-10-15 21:53:56,991:INFO:Declaring custom model
2024-10-15 21:53:56,992:INFO:Decision Tree Regressor Imported successfully
2024-10-15 21:53:56,994:INFO:Cross validation set to False
2024-10-15 21:53:56,994:INFO:Fitting Model
2024-10-15 21:53:57,126:INFO:DecisionTreeRegressor(random_state=123)
2024-10-15 21:53:57,126:INFO:create_model() successfully completed......................................
2024-10-15 21:53:57,317:INFO:Initializing create_model()
2024-10-15 21:53:57,317:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002232603E4D0>, estimator=DummyRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 21:53:57,318:INFO:Checking exceptions
2024-10-15 21:53:57,319:INFO:Importing libraries
2024-10-15 21:53:57,319:INFO:Copying training dataset
2024-10-15 21:53:57,325:INFO:Defining folds
2024-10-15 21:53:57,325:INFO:Declaring metric variables
2024-10-15 21:53:57,325:INFO:Importing untrained model
2024-10-15 21:53:57,325:INFO:Declaring custom model
2024-10-15 21:53:57,326:INFO:Dummy Regressor Imported successfully
2024-10-15 21:53:57,328:INFO:Cross validation set to False
2024-10-15 21:53:57,328:INFO:Fitting Model
2024-10-15 21:53:57,439:INFO:DummyRegressor()
2024-10-15 21:53:57,439:INFO:create_model() successfully completed......................................
2024-10-15 21:53:57,651:INFO:_master_model_container: 21
2024-10-15 21:53:57,651:INFO:_display_container: 2
2024-10-15 21:53:57,654:INFO:[<catboost.core.CatBoostRegressor object at 0x000002234AECA0B0>, RandomForestRegressor(n_jobs=-1, random_state=123), KNeighborsRegressor(n_jobs=-1), LGBMRegressor(n_jobs=-1, random_state=123), ExtraTreesRegressor(n_jobs=-1, random_state=123), GradientBoostingRegressor(random_state=123), XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=123, ...), AdaBoostRegressor(random_state=123), DecisionTreeRegressor(random_state=123), DummyRegressor()]
2024-10-15 21:53:57,654:INFO:compare_models() successfully completed......................................
2024-10-15 21:54:31,735:INFO:Initializing plot_model()
2024-10-15 21:54:31,735:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=<catboost.core.CatBoostRegressor object at 0x000002234AECA0B0>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=4, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002232603E4D0>, system=True)
2024-10-15 21:54:31,735:INFO:Checking exceptions
2024-10-15 21:54:31,739:INFO:Preloading libraries
2024-10-15 21:54:31,742:INFO:Copying training dataset
2024-10-15 21:54:31,742:INFO:Plot type: error
2024-10-15 21:54:32,291:INFO:Fitting Model
2024-10-15 21:54:32,303:INFO:Scoring test/hold-out set
2024-10-15 21:54:33,116:INFO:Visual Rendered Successfully
2024-10-15 21:54:33,331:INFO:plot_model() successfully completed......................................
2024-10-15 21:54:57,514:INFO:Initializing plot_model()
2024-10-15 21:54:57,514:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=4, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002232603E4D0>, system=True)
2024-10-15 21:54:57,514:INFO:Checking exceptions
2024-10-15 21:54:57,545:INFO:Preloading libraries
2024-10-15 21:54:57,556:INFO:Copying training dataset
2024-10-15 21:54:57,556:INFO:Plot type: error
2024-10-15 21:54:57,903:INFO:Fitting Model
2024-10-15 21:54:57,919:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-10-15 21:54:57,920:INFO:Scoring test/hold-out set
2024-10-15 21:54:58,157:INFO:Visual Rendered Successfully
2024-10-15 21:54:58,331:INFO:plot_model() successfully completed......................................
2024-10-15 21:55:06,603:INFO:Initializing plot_model()
2024-10-15 21:55:06,603:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=KNeighborsRegressor(n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=4, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002232603E4D0>, system=True)
2024-10-15 21:55:06,605:INFO:Checking exceptions
2024-10-15 21:55:06,610:INFO:Preloading libraries
2024-10-15 21:55:06,610:INFO:Copying training dataset
2024-10-15 21:55:06,610:INFO:Plot type: error
2024-10-15 21:55:06,998:INFO:Fitting Model
2024-10-15 21:55:06,998:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names
  warnings.warn(

2024-10-15 21:55:06,999:INFO:Scoring test/hold-out set
2024-10-15 21:55:07,454:INFO:Visual Rendered Successfully
2024-10-15 21:55:07,631:INFO:plot_model() successfully completed......................................
2024-10-15 21:55:13,638:INFO:Initializing plot_model()
2024-10-15 21:55:13,638:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=4, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002232603E4D0>, system=True)
2024-10-15 21:55:13,639:INFO:Checking exceptions
2024-10-15 21:55:13,647:INFO:Preloading libraries
2024-10-15 21:55:13,657:INFO:Copying training dataset
2024-10-15 21:55:13,657:INFO:Plot type: error
2024-10-15 21:55:14,048:INFO:Fitting Model
2024-10-15 21:55:14,048:INFO:Scoring test/hold-out set
2024-10-15 21:55:14,281:INFO:Visual Rendered Successfully
2024-10-15 21:55:14,459:INFO:plot_model() successfully completed......................................
2024-10-15 21:55:21,014:INFO:Initializing plot_model()
2024-10-15 21:55:21,014:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=4, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002232603E4D0>, system=True)
2024-10-15 21:55:21,015:INFO:Checking exceptions
2024-10-15 21:55:21,043:INFO:Preloading libraries
2024-10-15 21:55:21,053:INFO:Copying training dataset
2024-10-15 21:55:21,053:INFO:Plot type: error
2024-10-15 21:55:21,285:INFO:Fitting Model
2024-10-15 21:55:21,285:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-10-15 21:55:21,285:INFO:Scoring test/hold-out set
2024-10-15 21:55:21,502:INFO:Visual Rendered Successfully
2024-10-15 21:55:21,675:INFO:plot_model() successfully completed......................................
2024-10-15 21:55:28,366:INFO:Initializing plot_model()
2024-10-15 21:55:28,366:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=4, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002232603E4D0>, system=True)
2024-10-15 21:55:28,366:INFO:Checking exceptions
2024-10-15 21:55:28,397:INFO:Preloading libraries
2024-10-15 21:55:28,408:INFO:Copying training dataset
2024-10-15 21:55:28,408:INFO:Plot type: error
2024-10-15 21:55:28,636:INFO:Fitting Model
2024-10-15 21:55:28,637:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-10-15 21:55:28,637:INFO:Scoring test/hold-out set
2024-10-15 21:55:28,866:INFO:Visual Rendered Successfully
2024-10-15 21:55:29,040:INFO:plot_model() successfully completed......................................
2024-10-15 21:56:06,599:INFO:Initializing plot_model()
2024-10-15 21:56:06,599:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=<catboost.core.CatBoostRegressor object at 0x000002234AECA0B0>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002232603E4D0>, system=True)
2024-10-15 21:56:06,599:INFO:Checking exceptions
2024-10-15 21:56:06,604:INFO:Preloading libraries
2024-10-15 21:56:06,608:INFO:Copying training dataset
2024-10-15 21:56:06,608:INFO:Plot type: feature
2024-10-15 21:56:06,608:WARNING:No coef_ found. Trying feature_importances_
2024-10-15 21:56:06,740:INFO:Visual Rendered Successfully
2024-10-15 21:56:06,916:INFO:plot_model() successfully completed......................................
2024-10-15 21:56:59,392:INFO:Initializing interpret_model()
2024-10-15 21:56:59,392:INFO:interpret_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=123), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002232603E4D0>)
2024-10-15 21:56:59,392:INFO:Checking exceptions
2024-10-15 21:56:59,392:INFO:Soft dependency imported: shap: 0.44.1
2024-10-15 21:57:00,831:INFO:plot type: summary
2024-10-15 21:57:00,831:INFO:Creating TreeExplainer
2024-10-15 21:57:00,834:INFO:Compiling shap values
2024-10-15 21:57:03,182:INFO:Visual Rendered Successfully
2024-10-15 21:57:03,182:INFO:interpret_model() successfully completed......................................
2024-10-15 21:58:29,206:WARNING:The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.

2024-10-15 21:58:29,225:WARNING:The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.

2024-10-15 21:58:29,277:WARNING:Geometry column does not contain geometry.

2024-10-15 21:58:31,821:INFO:PyCaret RegressionExperiment
2024-10-15 21:58:31,821:INFO:Logging name: reg-default-name
2024-10-15 21:58:31,821:INFO:ML Usecase: MLUsecase.REGRESSION
2024-10-15 21:58:31,821:INFO:version 3.3.0
2024-10-15 21:58:31,821:INFO:Initializing setup()
2024-10-15 21:58:31,821:INFO:self.USI: a1bb
2024-10-15 21:58:31,821:INFO:self._variable_keys: {'fold_groups_param', 'X_train', 'fold_generator', 'idx', 'USI', '_available_plots', '_ml_usecase', 'n_jobs_param', 'transform_target_param', 'html_param', 'y', 'target_param', 'y_test', 'gpu_n_jobs_param', 'memory', 'exp_name_log', 'log_plots_param', 'fold_shuffle_param', 'seed', 'X', 'gpu_param', 'logging_param', 'exp_id', 'data', 'pipeline', 'y_train', 'X_test'}
2024-10-15 21:58:31,821:INFO:Checking environment
2024-10-15 21:58:31,821:INFO:python_version: 3.10.4
2024-10-15 21:58:31,821:INFO:python_build: ('tags/v3.10.4:9d38120', 'Mar 23 2022 23:13:41')
2024-10-15 21:58:31,822:INFO:machine: AMD64
2024-10-15 21:58:31,822:INFO:platform: Windows-10-10.0.22631-SP0
2024-10-15 21:58:31,822:INFO:Memory: svmem(total=16954937344, available=2054598656, percent=87.9, used=14900338688, free=2054598656)
2024-10-15 21:58:31,822:INFO:Physical Core: 4
2024-10-15 21:58:31,822:INFO:Logical Core: 8
2024-10-15 21:58:31,822:INFO:Checking libraries
2024-10-15 21:58:31,822:INFO:System:
2024-10-15 21:58:31,822:INFO:    python: 3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]
2024-10-15 21:58:31,822:INFO:executable: c:\Users\genin\AppData\Local\Programs\Python\Python310\python.exe
2024-10-15 21:58:31,822:INFO:   machine: Windows-10-10.0.22631-SP0
2024-10-15 21:58:31,822:INFO:PyCaret required dependencies:
2024-10-15 21:58:31,823:INFO:                 pip: 23.1
2024-10-15 21:58:31,823:INFO:          setuptools: 67.7.1
2024-10-15 21:58:31,823:INFO:             pycaret: 3.3.0
2024-10-15 21:58:31,823:INFO:             IPython: 8.3.0
2024-10-15 21:58:31,823:INFO:          ipywidgets: 8.1.2
2024-10-15 21:58:31,823:INFO:                tqdm: 4.66.2
2024-10-15 21:58:31,823:INFO:               numpy: 1.22.4
2024-10-15 21:58:31,823:INFO:              pandas: 1.4.2
2024-10-15 21:58:31,823:INFO:              jinja2: 3.1.2
2024-10-15 21:58:31,823:INFO:               scipy: 1.10.1
2024-10-15 21:58:31,823:INFO:              joblib: 1.2.0
2024-10-15 21:58:31,823:INFO:             sklearn: 1.4.1.post1
2024-10-15 21:58:31,823:INFO:                pyod: 1.1.3
2024-10-15 21:58:31,824:INFO:            imblearn: 0.12.0
2024-10-15 21:58:31,824:INFO:   category_encoders: 2.6.3
2024-10-15 21:58:31,824:INFO:            lightgbm: 4.3.0
2024-10-15 21:58:31,824:INFO:               numba: 0.58.1
2024-10-15 21:58:31,824:INFO:            requests: 2.27.1
2024-10-15 21:58:31,824:INFO:          matplotlib: 3.5.2
2024-10-15 21:58:31,824:INFO:          scikitplot: 0.3.7
2024-10-15 21:58:31,824:INFO:         yellowbrick: 1.5
2024-10-15 21:58:31,824:INFO:              plotly: 5.19.0
2024-10-15 21:58:31,824:INFO:    plotly-resampler: Not installed
2024-10-15 21:58:31,824:INFO:             kaleido: 0.2.1
2024-10-15 21:58:31,824:INFO:           schemdraw: 0.15
2024-10-15 21:58:31,824:INFO:         statsmodels: 0.14.1
2024-10-15 21:58:31,825:INFO:              sktime: 0.26.0
2024-10-15 21:58:31,825:INFO:               tbats: 1.1.3
2024-10-15 21:58:31,825:INFO:            pmdarima: 2.0.4
2024-10-15 21:58:31,825:INFO:              psutil: 5.9.0
2024-10-15 21:58:31,825:INFO:          markupsafe: 2.1.1
2024-10-15 21:58:31,825:INFO:             pickle5: Not installed
2024-10-15 21:58:31,825:INFO:         cloudpickle: 3.0.0
2024-10-15 21:58:31,825:INFO:         deprecation: 2.1.0
2024-10-15 21:58:31,825:INFO:              xxhash: 3.4.1
2024-10-15 21:58:31,825:INFO:           wurlitzer: Not installed
2024-10-15 21:58:31,825:INFO:PyCaret optional dependencies:
2024-10-15 21:58:31,825:INFO:                shap: 0.44.1
2024-10-15 21:58:31,825:INFO:           interpret: 0.5.1
2024-10-15 21:58:31,825:INFO:                umap: 0.5.5
2024-10-15 21:58:31,825:INFO:     ydata_profiling: 4.6.5
2024-10-15 21:58:31,825:INFO:  explainerdashboard: 0.4.5
2024-10-15 21:58:31,825:INFO:             autoviz: Not installed
2024-10-15 21:58:31,826:INFO:           fairlearn: 0.7.0
2024-10-15 21:58:31,826:INFO:          deepchecks: Not installed
2024-10-15 21:58:31,826:INFO:             xgboost: 2.0.3
2024-10-15 21:58:31,826:INFO:            catboost: 1.2.3
2024-10-15 21:58:31,826:INFO:              kmodes: 0.12.2
2024-10-15 21:58:31,826:INFO:             mlxtend: 0.23.1
2024-10-15 21:58:31,826:INFO:       statsforecast: 1.5.0
2024-10-15 21:58:31,826:INFO:        tune_sklearn: 0.5.0
2024-10-15 21:58:31,826:INFO:                 ray: 2.9.3
2024-10-15 21:58:31,826:INFO:            hyperopt: 0.2.7
2024-10-15 21:58:31,826:INFO:              optuna: 3.5.0
2024-10-15 21:58:31,826:INFO:               skopt: 0.9.0
2024-10-15 21:58:31,827:INFO:              mlflow: 2.11.0
2024-10-15 21:58:31,827:INFO:              gradio: 4.19.2
2024-10-15 21:58:31,827:INFO:             fastapi: 0.110.0
2024-10-15 21:58:31,827:INFO:             uvicorn: 0.27.1
2024-10-15 21:58:31,827:INFO:              m2cgen: 0.10.0
2024-10-15 21:58:31,827:INFO:           evidently: 0.4.16
2024-10-15 21:58:31,827:INFO:               fugue: 0.8.6
2024-10-15 21:58:31,827:INFO:           streamlit: Not installed
2024-10-15 21:58:31,827:INFO:             prophet: Not installed
2024-10-15 21:58:31,827:INFO:None
2024-10-15 21:58:31,827:INFO:Set up data.
2024-10-15 21:58:31,886:INFO:Set up folding strategy.
2024-10-15 21:58:31,886:INFO:Set up train/test split.
2024-10-15 21:58:31,895:INFO:Set up index.
2024-10-15 21:58:31,895:INFO:Assigning column types.
2024-10-15 21:58:31,900:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-10-15 21:58:31,901:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-10-15 21:58:31,905:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-10-15 21:58:31,909:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-10-15 21:58:31,968:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-10-15 21:58:32,025:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-10-15 21:58:32,026:INFO:Soft dependency imported: xgboost: 2.0.3
2024-10-15 21:58:32,029:INFO:Soft dependency imported: catboost: 1.2.3
2024-10-15 21:58:32,030:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-10-15 21:58:32,035:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-10-15 21:58:32,039:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-10-15 21:58:32,106:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-10-15 21:58:32,146:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-10-15 21:58:32,147:INFO:Soft dependency imported: xgboost: 2.0.3
2024-10-15 21:58:32,152:INFO:Soft dependency imported: catboost: 1.2.3
2024-10-15 21:58:32,153:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-10-15 21:58:32,159:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-10-15 21:58:32,164:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-10-15 21:58:32,225:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-10-15 21:58:32,266:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-10-15 21:58:32,267:INFO:Soft dependency imported: xgboost: 2.0.3
2024-10-15 21:58:32,269:INFO:Soft dependency imported: catboost: 1.2.3
2024-10-15 21:58:32,274:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-10-15 21:58:32,278:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-10-15 21:58:32,331:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-10-15 21:58:32,370:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-10-15 21:58:32,370:INFO:Soft dependency imported: xgboost: 2.0.3
2024-10-15 21:58:32,372:INFO:Soft dependency imported: catboost: 1.2.3
2024-10-15 21:58:32,373:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-10-15 21:58:32,381:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-10-15 21:58:32,428:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-10-15 21:58:32,466:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-10-15 21:58:32,466:INFO:Soft dependency imported: xgboost: 2.0.3
2024-10-15 21:58:32,469:INFO:Soft dependency imported: catboost: 1.2.3
2024-10-15 21:58:32,476:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-10-15 21:58:32,523:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-10-15 21:58:32,568:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-10-15 21:58:32,568:INFO:Soft dependency imported: xgboost: 2.0.3
2024-10-15 21:58:32,570:INFO:Soft dependency imported: catboost: 1.2.3
2024-10-15 21:58:32,571:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-10-15 21:58:32,637:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-10-15 21:58:32,676:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-10-15 21:58:32,677:INFO:Soft dependency imported: xgboost: 2.0.3
2024-10-15 21:58:32,679:INFO:Soft dependency imported: catboost: 1.2.3
2024-10-15 21:58:32,740:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-10-15 21:58:32,779:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-10-15 21:58:32,780:INFO:Soft dependency imported: xgboost: 2.0.3
2024-10-15 21:58:32,783:INFO:Soft dependency imported: catboost: 1.2.3
2024-10-15 21:58:32,783:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-10-15 21:58:32,843:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-10-15 21:58:32,939:INFO:Soft dependency imported: xgboost: 2.0.3
2024-10-15 21:58:32,941:INFO:Soft dependency imported: catboost: 1.2.3
2024-10-15 21:58:33,005:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-10-15 21:58:33,045:INFO:Soft dependency imported: xgboost: 2.0.3
2024-10-15 21:58:33,047:INFO:Soft dependency imported: catboost: 1.2.3
2024-10-15 21:58:33,048:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-10-15 21:58:33,156:INFO:Soft dependency imported: xgboost: 2.0.3
2024-10-15 21:58:33,161:INFO:Soft dependency imported: catboost: 1.2.3
2024-10-15 21:58:33,264:INFO:Soft dependency imported: xgboost: 2.0.3
2024-10-15 21:58:33,266:INFO:Soft dependency imported: catboost: 1.2.3
2024-10-15 21:58:33,267:INFO:Preparing preprocessing pipeline...
2024-10-15 21:58:33,267:INFO:Set up simple imputation.
2024-10-15 21:58:33,270:INFO:Set up encoding of categorical features.
2024-10-15 21:58:33,270:INFO:Set up column name cleaning.
2024-10-15 21:58:33,400:INFO:Finished creating preprocessing pipeline.
2024-10-15 21:58:33,409:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\genin\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Area Construida', 'Area Total',
                                             'Habitaciones', 'Baños', 'Patio',
                                             'Deposito 1', 'Piso 2',
                                             'Tipo de comedor sala comedor',
                                             'Depósito o cuarto útil',
                                             'Tipo de casa tradicional',
                                             'Piso 3', 'Tipo de estufa gas',
                                             'Lote vacio',
                                             'Número de Ascensores 1',
                                             'Ti...
                 TransformerWrapper(include=['Edad', 'Estrato', 'date', 'city'],
                                    transformer=OneHotEncoder(cols=['Edad',
                                                                    'Estrato',
                                                                    'date',
                                                                    'city'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['grid_id'],
                                    transformer=TargetEncoder(cols=['grid_id'],
                                                              handle_missing='return_nan'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2024-10-15 21:58:33,410:INFO:Creating final display dataframe.
2024-10-15 21:58:33,740:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            Precio
2                   Target type        Regression
3           Original data shape        (715, 194)
4        Transformed data shape        (715, 212)
5   Transformed train set shape        (500, 212)
6    Transformed test set shape        (215, 212)
7              Numeric features               188
8          Categorical features                 5
9      Rows with missing values            100.0%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              a1bb
2024-10-15 21:58:33,878:INFO:Soft dependency imported: xgboost: 2.0.3
2024-10-15 21:58:33,880:INFO:Soft dependency imported: catboost: 1.2.3
2024-10-15 21:58:33,983:INFO:Soft dependency imported: xgboost: 2.0.3
2024-10-15 21:58:33,986:INFO:Soft dependency imported: catboost: 1.2.3
2024-10-15 21:58:33,986:WARNING:The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.

2024-10-15 21:58:33,986:INFO:setup() successfully completed in 2.17s...............
2024-10-15 21:58:36,726:INFO:Initializing compare_models()
2024-10-15 21:58:36,726:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002234970B6D0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=10, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002234970B6D0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 10, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-10-15 21:58:36,726:INFO:Checking exceptions
2024-10-15 21:58:36,729:INFO:Preparing display monitor
2024-10-15 21:58:36,764:INFO:Initializing Linear Regression
2024-10-15 21:58:36,765:INFO:Total runtime is 1.652240753173828e-05 minutes
2024-10-15 21:58:36,770:INFO:SubProcess create_model() called ==================================
2024-10-15 21:58:36,770:INFO:Initializing create_model()
2024-10-15 21:58:36,770:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002234970B6D0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022343A933A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 21:58:36,770:INFO:Checking exceptions
2024-10-15 21:58:36,771:INFO:Importing libraries
2024-10-15 21:58:36,771:INFO:Copying training dataset
2024-10-15 21:58:36,780:INFO:Defining folds
2024-10-15 21:58:36,780:INFO:Declaring metric variables
2024-10-15 21:58:36,783:INFO:Importing untrained model
2024-10-15 21:58:36,789:INFO:Linear Regression Imported successfully
2024-10-15 21:58:36,800:INFO:Starting cross validation
2024-10-15 21:58:36,804:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-15 21:58:37,438:INFO:Calculating mean and std
2024-10-15 21:58:37,439:INFO:Creating metrics dataframe
2024-10-15 21:58:37,441:INFO:Uploading results into container
2024-10-15 21:58:37,442:INFO:Uploading model into container now
2024-10-15 21:58:37,443:INFO:_master_model_container: 1
2024-10-15 21:58:37,443:INFO:_display_container: 2
2024-10-15 21:58:37,443:INFO:LinearRegression(n_jobs=-1)
2024-10-15 21:58:37,443:INFO:create_model() successfully completed......................................
2024-10-15 21:58:37,626:INFO:SubProcess create_model() end ==================================
2024-10-15 21:58:37,626:INFO:Creating metrics dataframe
2024-10-15 21:58:37,634:INFO:Initializing Lasso Regression
2024-10-15 21:58:37,634:INFO:Total runtime is 0.014500975608825684 minutes
2024-10-15 21:58:37,637:INFO:SubProcess create_model() called ==================================
2024-10-15 21:58:37,637:INFO:Initializing create_model()
2024-10-15 21:58:37,637:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002234970B6D0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022343A933A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 21:58:37,637:INFO:Checking exceptions
2024-10-15 21:58:37,637:INFO:Importing libraries
2024-10-15 21:58:37,637:INFO:Copying training dataset
2024-10-15 21:58:37,641:INFO:Defining folds
2024-10-15 21:58:37,641:INFO:Declaring metric variables
2024-10-15 21:58:37,645:INFO:Importing untrained model
2024-10-15 21:58:37,648:INFO:Lasso Regression Imported successfully
2024-10-15 21:58:37,654:INFO:Starting cross validation
2024-10-15 21:58:37,656:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-15 21:58:38,302:INFO:Calculating mean and std
2024-10-15 21:58:38,303:INFO:Creating metrics dataframe
2024-10-15 21:58:38,305:INFO:Uploading results into container
2024-10-15 21:58:38,306:INFO:Uploading model into container now
2024-10-15 21:58:38,306:INFO:_master_model_container: 2
2024-10-15 21:58:38,306:INFO:_display_container: 2
2024-10-15 21:58:38,307:INFO:Lasso(random_state=123)
2024-10-15 21:58:38,307:INFO:create_model() successfully completed......................................
2024-10-15 21:58:38,483:INFO:SubProcess create_model() end ==================================
2024-10-15 21:58:38,483:INFO:Creating metrics dataframe
2024-10-15 21:58:38,492:INFO:Initializing Ridge Regression
2024-10-15 21:58:38,492:INFO:Total runtime is 0.02880310614903768 minutes
2024-10-15 21:58:38,496:INFO:SubProcess create_model() called ==================================
2024-10-15 21:58:38,496:INFO:Initializing create_model()
2024-10-15 21:58:38,497:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002234970B6D0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022343A933A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 21:58:38,497:INFO:Checking exceptions
2024-10-15 21:58:38,497:INFO:Importing libraries
2024-10-15 21:58:38,497:INFO:Copying training dataset
2024-10-15 21:58:38,501:INFO:Defining folds
2024-10-15 21:58:38,502:INFO:Declaring metric variables
2024-10-15 21:58:38,505:INFO:Importing untrained model
2024-10-15 21:58:38,509:INFO:Ridge Regression Imported successfully
2024-10-15 21:58:38,551:INFO:Starting cross validation
2024-10-15 21:58:38,553:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-15 21:58:39,107:INFO:Calculating mean and std
2024-10-15 21:58:39,109:INFO:Creating metrics dataframe
2024-10-15 21:58:39,111:INFO:Uploading results into container
2024-10-15 21:58:39,112:INFO:Uploading model into container now
2024-10-15 21:58:39,112:INFO:_master_model_container: 3
2024-10-15 21:58:39,112:INFO:_display_container: 2
2024-10-15 21:58:39,113:INFO:Ridge(random_state=123)
2024-10-15 21:58:39,113:INFO:create_model() successfully completed......................................
2024-10-15 21:58:39,285:INFO:SubProcess create_model() end ==================================
2024-10-15 21:58:39,286:INFO:Creating metrics dataframe
2024-10-15 21:58:39,293:INFO:Initializing Elastic Net
2024-10-15 21:58:39,293:INFO:Total runtime is 0.042155949274698894 minutes
2024-10-15 21:58:39,296:INFO:SubProcess create_model() called ==================================
2024-10-15 21:58:39,296:INFO:Initializing create_model()
2024-10-15 21:58:39,296:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002234970B6D0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022343A933A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 21:58:39,296:INFO:Checking exceptions
2024-10-15 21:58:39,296:INFO:Importing libraries
2024-10-15 21:58:39,297:INFO:Copying training dataset
2024-10-15 21:58:39,302:INFO:Defining folds
2024-10-15 21:58:39,302:INFO:Declaring metric variables
2024-10-15 21:58:39,306:INFO:Importing untrained model
2024-10-15 21:58:39,311:INFO:Elastic Net Imported successfully
2024-10-15 21:58:39,317:INFO:Starting cross validation
2024-10-15 21:58:39,319:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-15 21:58:39,957:INFO:Calculating mean and std
2024-10-15 21:58:39,958:INFO:Creating metrics dataframe
2024-10-15 21:58:39,962:INFO:Uploading results into container
2024-10-15 21:58:39,963:INFO:Uploading model into container now
2024-10-15 21:58:39,963:INFO:_master_model_container: 4
2024-10-15 21:58:39,964:INFO:_display_container: 2
2024-10-15 21:58:39,964:INFO:ElasticNet(random_state=123)
2024-10-15 21:58:39,964:INFO:create_model() successfully completed......................................
2024-10-15 21:58:40,170:INFO:SubProcess create_model() end ==================================
2024-10-15 21:58:40,171:INFO:Creating metrics dataframe
2024-10-15 21:58:40,185:INFO:Initializing Least Angle Regression
2024-10-15 21:58:40,185:INFO:Total runtime is 0.05701669454574585 minutes
2024-10-15 21:58:40,192:INFO:SubProcess create_model() called ==================================
2024-10-15 21:58:40,192:INFO:Initializing create_model()
2024-10-15 21:58:40,193:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002234970B6D0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022343A933A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 21:58:40,193:INFO:Checking exceptions
2024-10-15 21:58:40,193:INFO:Importing libraries
2024-10-15 21:58:40,193:INFO:Copying training dataset
2024-10-15 21:58:40,203:INFO:Defining folds
2024-10-15 21:58:40,203:INFO:Declaring metric variables
2024-10-15 21:58:40,209:INFO:Importing untrained model
2024-10-15 21:58:40,214:INFO:Least Angle Regression Imported successfully
2024-10-15 21:58:40,223:INFO:Starting cross validation
2024-10-15 21:58:40,226:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-15 21:58:40,560:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 106 iterations, i.e. alpha=4.251e-01, with an active set of 103 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,590:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 94 iterations, i.e. alpha=4.485e-01, with an active set of 92 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,599:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 144 iterations, i.e. alpha=4.689e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,601:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=3.356e-01, with an active set of 148 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,601:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 88 iterations, i.e. alpha=5.315e-01, with an active set of 85 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,603:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 172 iterations, i.e. alpha=3.186e-01, with an active set of 150 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,604:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 153 iterations, i.e. alpha=4.507e-01, with an active set of 134 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,606:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 153 iterations, i.e. alpha=4.199e-01, with an active set of 134 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,608:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 153 iterations, i.e. alpha=4.199e-01, with an active set of 134 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,632:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 208 iterations, i.e. alpha=1.200e+02, with an active set of 165 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,635:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 236 iterations, i.e. alpha=8.062e+00, with an active set of 185 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,635:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 236 iterations, i.e. alpha=8.019e+00, with an active set of 185 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,637:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=6.646e-01, with an active set of 147 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,637:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 239 iterations, i.e. alpha=6.405e+00, with an active set of 187 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,638:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 219 iterations, i.e. alpha=3.024e-01, with an active set of 185 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,638:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 219 iterations, i.e. alpha=2.893e-01, with an active set of 185 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,639:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=6.721e-01, with an active set of 148 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,639:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 219 iterations, i.e. alpha=2.762e-01, with an active set of 185 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,648:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 248 iterations, i.e. alpha=1.382e+02, with an active set of 192 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,648:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 227 iterations, i.e. alpha=1.216e-01, with an active set of 189 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,648:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 248 iterations, i.e. alpha=1.204e+02, with an active set of 192 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,648:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 248 iterations, i.e. alpha=9.371e+01, with an active set of 192 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,649:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 143 iterations, i.e. alpha=5.458e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,649:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 228 iterations, i.e. alpha=1.101e-01, with an active set of 190 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,650:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 228 iterations, i.e. alpha=9.606e-02, with an active set of 190 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,655:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 231 iterations, i.e. alpha=1.243e+02, with an active set of 179 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,660:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 242 iterations, i.e. alpha=1.548e-01, with an active set of 191 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,661:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 242 iterations, i.e. alpha=1.370e-01, with an active set of 191 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,661:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 242 iterations, i.e. alpha=1.000e-01, with an active set of 191 regressors, and the smallest cholesky pivot element being 9.306e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,662:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 158 iterations, i.e. alpha=4.670e-01, with an active set of 140 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,662:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 239 iterations, i.e. alpha=8.458e+01, with an active set of 184 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,666:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 245 iterations, i.e. alpha=6.580e+01, with an active set of 187 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,667:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 245 iterations, i.e. alpha=6.577e+01, with an active set of 187 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,668:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 245 iterations, i.e. alpha=5.190e+01, with an active set of 187 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,668:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 245 iterations, i.e. alpha=4.270e+01, with an active set of 187 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,673:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 248 iterations, i.e. alpha=2.804e+01, with an active set of 189 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,677:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 250 iterations, i.e. alpha=1.684e+01, with an active set of 190 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,677:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 250 iterations, i.e. alpha=1.643e+01, with an active set of 190 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,678:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 250 iterations, i.e. alpha=1.620e+01, with an active set of 190 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,679:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 250 iterations, i.e. alpha=9.867e+00, with an active set of 190 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,698:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 273 iterations, i.e. alpha=2.443e+04, with an active set of 192 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,700:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 273 iterations, i.e. alpha=2.441e+04, with an active set of 192 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,700:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 273 iterations, i.e. alpha=2.397e+04, with an active set of 192 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,700:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 211 iterations, i.e. alpha=7.467e+00, with an active set of 165 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,701:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 273 iterations, i.e. alpha=2.249e+04, with an active set of 192 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,701:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 273 iterations, i.e. alpha=2.211e+04, with an active set of 192 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,742:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 266 iterations, i.e. alpha=3.443e+04, with an active set of 193 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,743:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 266 iterations, i.e. alpha=3.102e+04, with an active set of 193 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,743:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 266 iterations, i.e. alpha=3.073e+04, with an active set of 193 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,766:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 249 iterations, i.e. alpha=1.149e+03, with an active set of 182 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,768:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 250 iterations, i.e. alpha=9.357e+02, with an active set of 183 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,769:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 250 iterations, i.e. alpha=9.265e+02, with an active set of 183 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,770:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 250 iterations, i.e. alpha=9.249e+02, with an active set of 183 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,776:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 206 iterations, i.e. alpha=1.269e+03, with an active set of 155 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,779:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 256 iterations, i.e. alpha=4.956e+02, with an active set of 187 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,781:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 257 iterations, i.e. alpha=3.342e+02, with an active set of 188 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,781:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 257 iterations, i.e. alpha=3.327e+02, with an active set of 188 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,782:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 257 iterations, i.e. alpha=3.318e+02, with an active set of 188 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,782:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 257 iterations, i.e. alpha=2.360e+02, with an active set of 188 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,785:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 259 iterations, i.e. alpha=7.199e+01, with an active set of 189 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,787:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 261 iterations, i.e. alpha=4.965e+01, with an active set of 190 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,787:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 261 iterations, i.e. alpha=4.908e+01, with an active set of 190 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,788:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 261 iterations, i.e. alpha=4.323e+01, with an active set of 190 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,788:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 261 iterations, i.e. alpha=3.965e+01, with an active set of 190 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,799:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 266 iterations, i.e. alpha=4.641e+04, with an active set of 193 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,800:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 266 iterations, i.e. alpha=4.622e+04, with an active set of 193 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,800:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 266 iterations, i.e. alpha=3.842e+04, with an active set of 193 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,824:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=6.484e+00, with an active set of 191 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,825:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=2.956e+00, with an active set of 191 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,826:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=2.887e+00, with an active set of 191 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,826:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=2.858e+00, with an active set of 191 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,827:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=2.825e+00, with an active set of 191 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,885:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 298 iterations, i.e. alpha=2.371e+09, with an active set of 189 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,886:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 298 iterations, i.e. alpha=2.293e+09, with an active set of 189 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,886:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 298 iterations, i.e. alpha=2.284e+09, with an active set of 189 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,887:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 298 iterations, i.e. alpha=2.250e+09, with an active set of 189 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,888:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 300 iterations, i.e. alpha=1.129e+09, with an active set of 190 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,889:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 300 iterations, i.e. alpha=1.109e+09, with an active set of 190 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,889:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 300 iterations, i.e. alpha=1.087e+09, with an active set of 190 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,890:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 300 iterations, i.e. alpha=1.076e+09, with an active set of 190 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,890:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 300 iterations, i.e. alpha=1.018e+09, with an active set of 190 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,892:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 302 iterations, i.e. alpha=3.768e+08, with an active set of 191 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,893:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 302 iterations, i.e. alpha=3.704e+08, with an active set of 191 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,893:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 302 iterations, i.e. alpha=3.647e+08, with an active set of 191 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:40,894:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 302 iterations, i.e. alpha=3.336e+08, with an active set of 191 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:41,158:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=2.768e+04, with an active set of 191 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:41,160:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=2.554e+04, with an active set of 193 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:41,160:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=5.086e+03, with an active set of 193 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:41,161:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=4.381e+03, with an active set of 193 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:41,184:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 257 iterations, i.e. alpha=1.971e+03, with an active set of 190 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:41,184:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 257 iterations, i.e. alpha=1.382e+03, with an active set of 190 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:41,186:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 261 iterations, i.e. alpha=2.508e+03, with an active set of 192 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:41,186:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 261 iterations, i.e. alpha=1.509e+03, with an active set of 192 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:41,187:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 261 iterations, i.e. alpha=9.460e+02, with an active set of 192 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 21:58:41,266:INFO:Calculating mean and std
2024-10-15 21:58:41,267:INFO:Creating metrics dataframe
2024-10-15 21:58:41,271:INFO:Uploading results into container
2024-10-15 21:58:41,272:INFO:Uploading model into container now
2024-10-15 21:58:41,272:INFO:_master_model_container: 5
2024-10-15 21:58:41,272:INFO:_display_container: 2
2024-10-15 21:58:41,273:INFO:Lars(random_state=123)
2024-10-15 21:58:41,273:INFO:create_model() successfully completed......................................
2024-10-15 21:58:41,547:INFO:SubProcess create_model() end ==================================
2024-10-15 21:58:41,547:INFO:Creating metrics dataframe
2024-10-15 21:58:41,560:INFO:Initializing Lasso Least Angle Regression
2024-10-15 21:58:41,560:INFO:Total runtime is 0.07993354002634684 minutes
2024-10-15 21:58:41,564:INFO:SubProcess create_model() called ==================================
2024-10-15 21:58:41,565:INFO:Initializing create_model()
2024-10-15 21:58:41,565:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002234970B6D0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022343A933A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 21:58:41,565:INFO:Checking exceptions
2024-10-15 21:58:41,565:INFO:Importing libraries
2024-10-15 21:58:41,565:INFO:Copying training dataset
2024-10-15 21:58:41,573:INFO:Defining folds
2024-10-15 21:58:41,574:INFO:Declaring metric variables
2024-10-15 21:58:41,580:INFO:Importing untrained model
2024-10-15 21:58:41,585:INFO:Lasso Least Angle Regression Imported successfully
2024-10-15 21:58:41,598:INFO:Starting cross validation
2024-10-15 21:58:41,602:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-15 21:58:42,528:INFO:Calculating mean and std
2024-10-15 21:58:42,530:INFO:Creating metrics dataframe
2024-10-15 21:58:42,535:INFO:Uploading results into container
2024-10-15 21:58:42,536:INFO:Uploading model into container now
2024-10-15 21:58:42,537:INFO:_master_model_container: 6
2024-10-15 21:58:42,537:INFO:_display_container: 2
2024-10-15 21:58:42,537:INFO:LassoLars(random_state=123)
2024-10-15 21:58:42,537:INFO:create_model() successfully completed......................................
2024-10-15 21:58:42,777:INFO:SubProcess create_model() end ==================================
2024-10-15 21:58:42,777:INFO:Creating metrics dataframe
2024-10-15 21:58:42,788:INFO:Initializing Orthogonal Matching Pursuit
2024-10-15 21:58:42,788:INFO:Total runtime is 0.1004037578900655 minutes
2024-10-15 21:58:42,793:INFO:SubProcess create_model() called ==================================
2024-10-15 21:58:42,793:INFO:Initializing create_model()
2024-10-15 21:58:42,793:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002234970B6D0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022343A933A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 21:58:42,793:INFO:Checking exceptions
2024-10-15 21:58:42,794:INFO:Importing libraries
2024-10-15 21:58:42,794:INFO:Copying training dataset
2024-10-15 21:58:42,801:INFO:Defining folds
2024-10-15 21:58:42,801:INFO:Declaring metric variables
2024-10-15 21:58:42,806:INFO:Importing untrained model
2024-10-15 21:58:42,812:INFO:Orthogonal Matching Pursuit Imported successfully
2024-10-15 21:58:42,820:INFO:Starting cross validation
2024-10-15 21:58:42,824:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-15 21:58:43,647:INFO:Calculating mean and std
2024-10-15 21:58:43,648:INFO:Creating metrics dataframe
2024-10-15 21:58:43,652:INFO:Uploading results into container
2024-10-15 21:58:43,653:INFO:Uploading model into container now
2024-10-15 21:58:43,653:INFO:_master_model_container: 7
2024-10-15 21:58:43,654:INFO:_display_container: 2
2024-10-15 21:58:43,654:INFO:OrthogonalMatchingPursuit()
2024-10-15 21:58:43,654:INFO:create_model() successfully completed......................................
2024-10-15 21:58:43,849:INFO:SubProcess create_model() end ==================================
2024-10-15 21:58:43,849:INFO:Creating metrics dataframe
2024-10-15 21:58:43,865:INFO:Initializing Bayesian Ridge
2024-10-15 21:58:43,865:INFO:Total runtime is 0.11835573911666869 minutes
2024-10-15 21:58:43,872:INFO:SubProcess create_model() called ==================================
2024-10-15 21:58:43,872:INFO:Initializing create_model()
2024-10-15 21:58:43,872:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002234970B6D0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022343A933A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 21:58:43,873:INFO:Checking exceptions
2024-10-15 21:58:43,873:INFO:Importing libraries
2024-10-15 21:58:43,873:INFO:Copying training dataset
2024-10-15 21:58:43,924:INFO:Defining folds
2024-10-15 21:58:43,924:INFO:Declaring metric variables
2024-10-15 21:58:43,959:INFO:Importing untrained model
2024-10-15 21:58:43,965:INFO:Bayesian Ridge Imported successfully
2024-10-15 21:58:43,982:INFO:Starting cross validation
2024-10-15 21:58:43,985:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-15 21:58:44,831:INFO:Calculating mean and std
2024-10-15 21:58:44,833:INFO:Creating metrics dataframe
2024-10-15 21:58:44,840:INFO:Uploading results into container
2024-10-15 21:58:44,841:INFO:Uploading model into container now
2024-10-15 21:58:44,841:INFO:_master_model_container: 8
2024-10-15 21:58:44,842:INFO:_display_container: 2
2024-10-15 21:58:44,842:INFO:BayesianRidge()
2024-10-15 21:58:44,843:INFO:create_model() successfully completed......................................
2024-10-15 21:58:45,058:INFO:SubProcess create_model() end ==================================
2024-10-15 21:58:45,059:INFO:Creating metrics dataframe
2024-10-15 21:58:45,071:INFO:Initializing Passive Aggressive Regressor
2024-10-15 21:58:45,072:INFO:Total runtime is 0.1384697993596395 minutes
2024-10-15 21:58:45,076:INFO:SubProcess create_model() called ==================================
2024-10-15 21:58:45,076:INFO:Initializing create_model()
2024-10-15 21:58:45,077:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002234970B6D0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022343A933A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 21:58:45,077:INFO:Checking exceptions
2024-10-15 21:58:45,077:INFO:Importing libraries
2024-10-15 21:58:45,077:INFO:Copying training dataset
2024-10-15 21:58:45,083:INFO:Defining folds
2024-10-15 21:58:45,083:INFO:Declaring metric variables
2024-10-15 21:58:45,088:INFO:Importing untrained model
2024-10-15 21:58:45,129:INFO:Passive Aggressive Regressor Imported successfully
2024-10-15 21:58:45,151:INFO:Starting cross validation
2024-10-15 21:58:45,155:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-15 21:58:46,067:INFO:Calculating mean and std
2024-10-15 21:58:46,068:INFO:Creating metrics dataframe
2024-10-15 21:58:46,074:INFO:Uploading results into container
2024-10-15 21:58:46,075:INFO:Uploading model into container now
2024-10-15 21:58:46,076:INFO:_master_model_container: 9
2024-10-15 21:58:46,076:INFO:_display_container: 2
2024-10-15 21:58:46,076:INFO:PassiveAggressiveRegressor(random_state=123)
2024-10-15 21:58:46,076:INFO:create_model() successfully completed......................................
2024-10-15 21:58:46,342:INFO:SubProcess create_model() end ==================================
2024-10-15 21:58:46,342:INFO:Creating metrics dataframe
2024-10-15 21:58:46,356:INFO:Initializing Huber Regressor
2024-10-15 21:58:46,356:INFO:Total runtime is 0.15987759431203208 minutes
2024-10-15 21:58:46,361:INFO:SubProcess create_model() called ==================================
2024-10-15 21:58:46,361:INFO:Initializing create_model()
2024-10-15 21:58:46,362:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002234970B6D0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022343A933A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 21:58:46,362:INFO:Checking exceptions
2024-10-15 21:58:46,362:INFO:Importing libraries
2024-10-15 21:58:46,362:INFO:Copying training dataset
2024-10-15 21:58:46,369:INFO:Defining folds
2024-10-15 21:58:46,369:INFO:Declaring metric variables
2024-10-15 21:58:46,376:INFO:Importing untrained model
2024-10-15 21:58:46,380:INFO:Huber Regressor Imported successfully
2024-10-15 21:58:46,392:INFO:Starting cross validation
2024-10-15 21:58:46,397:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-15 21:58:46,948:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-10-15 21:58:46,989:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-10-15 21:58:47,019:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-10-15 21:58:47,034:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-10-15 21:58:47,046:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-10-15 21:58:47,059:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-10-15 21:58:47,081:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-10-15 21:58:47,147:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-10-15 21:58:47,550:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-10-15 21:58:47,629:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-10-15 21:58:47,700:INFO:Calculating mean and std
2024-10-15 21:58:47,702:INFO:Creating metrics dataframe
2024-10-15 21:58:47,707:INFO:Uploading results into container
2024-10-15 21:58:47,707:INFO:Uploading model into container now
2024-10-15 21:58:47,708:INFO:_master_model_container: 10
2024-10-15 21:58:47,708:INFO:_display_container: 2
2024-10-15 21:58:47,708:INFO:HuberRegressor()
2024-10-15 21:58:47,708:INFO:create_model() successfully completed......................................
2024-10-15 21:58:47,907:INFO:SubProcess create_model() end ==================================
2024-10-15 21:58:47,907:INFO:Creating metrics dataframe
2024-10-15 21:58:47,921:INFO:Initializing K Neighbors Regressor
2024-10-15 21:58:47,921:INFO:Total runtime is 0.1859551509221395 minutes
2024-10-15 21:58:47,925:INFO:SubProcess create_model() called ==================================
2024-10-15 21:58:47,925:INFO:Initializing create_model()
2024-10-15 21:58:47,926:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002234970B6D0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022343A933A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 21:58:47,926:INFO:Checking exceptions
2024-10-15 21:58:47,926:INFO:Importing libraries
2024-10-15 21:58:47,926:INFO:Copying training dataset
2024-10-15 21:58:47,935:INFO:Defining folds
2024-10-15 21:58:47,935:INFO:Declaring metric variables
2024-10-15 21:58:47,940:INFO:Importing untrained model
2024-10-15 21:58:47,944:INFO:K Neighbors Regressor Imported successfully
2024-10-15 21:58:47,952:INFO:Starting cross validation
2024-10-15 21:58:47,955:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-15 21:58:48,693:INFO:Calculating mean and std
2024-10-15 21:58:48,694:INFO:Creating metrics dataframe
2024-10-15 21:58:48,698:INFO:Uploading results into container
2024-10-15 21:58:48,699:INFO:Uploading model into container now
2024-10-15 21:58:48,699:INFO:_master_model_container: 11
2024-10-15 21:58:48,699:INFO:_display_container: 2
2024-10-15 21:58:48,700:INFO:KNeighborsRegressor(n_jobs=-1)
2024-10-15 21:58:48,700:INFO:create_model() successfully completed......................................
2024-10-15 21:58:48,900:INFO:SubProcess create_model() end ==================================
2024-10-15 21:58:48,901:INFO:Creating metrics dataframe
2024-10-15 21:58:48,915:INFO:Initializing Decision Tree Regressor
2024-10-15 21:58:48,915:INFO:Total runtime is 0.20252116521199545 minutes
2024-10-15 21:58:48,919:INFO:SubProcess create_model() called ==================================
2024-10-15 21:58:48,920:INFO:Initializing create_model()
2024-10-15 21:58:48,920:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002234970B6D0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022343A933A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 21:58:48,920:INFO:Checking exceptions
2024-10-15 21:58:48,921:INFO:Importing libraries
2024-10-15 21:58:48,921:INFO:Copying training dataset
2024-10-15 21:58:48,931:INFO:Defining folds
2024-10-15 21:58:48,931:INFO:Declaring metric variables
2024-10-15 21:58:48,935:INFO:Importing untrained model
2024-10-15 21:58:48,943:INFO:Decision Tree Regressor Imported successfully
2024-10-15 21:58:48,952:INFO:Starting cross validation
2024-10-15 21:58:48,956:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-15 21:58:49,775:INFO:Calculating mean and std
2024-10-15 21:58:49,776:INFO:Creating metrics dataframe
2024-10-15 21:58:49,780:INFO:Uploading results into container
2024-10-15 21:58:49,781:INFO:Uploading model into container now
2024-10-15 21:58:49,781:INFO:_master_model_container: 12
2024-10-15 21:58:49,781:INFO:_display_container: 2
2024-10-15 21:58:49,781:INFO:DecisionTreeRegressor(random_state=123)
2024-10-15 21:58:49,781:INFO:create_model() successfully completed......................................
2024-10-15 21:58:49,982:INFO:SubProcess create_model() end ==================================
2024-10-15 21:58:49,983:INFO:Creating metrics dataframe
2024-10-15 21:58:49,998:INFO:Initializing Random Forest Regressor
2024-10-15 21:58:49,998:INFO:Total runtime is 0.22057502269744875 minutes
2024-10-15 21:58:50,004:INFO:SubProcess create_model() called ==================================
2024-10-15 21:58:50,004:INFO:Initializing create_model()
2024-10-15 21:58:50,004:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002234970B6D0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022343A933A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 21:58:50,005:INFO:Checking exceptions
2024-10-15 21:58:50,005:INFO:Importing libraries
2024-10-15 21:58:50,005:INFO:Copying training dataset
2024-10-15 21:58:50,015:INFO:Defining folds
2024-10-15 21:58:50,015:INFO:Declaring metric variables
2024-10-15 21:58:50,021:INFO:Importing untrained model
2024-10-15 21:58:50,027:INFO:Random Forest Regressor Imported successfully
2024-10-15 21:58:50,078:INFO:Starting cross validation
2024-10-15 21:58:50,083:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-15 21:58:54,753:INFO:Calculating mean and std
2024-10-15 21:58:54,755:INFO:Creating metrics dataframe
2024-10-15 21:58:54,760:INFO:Uploading results into container
2024-10-15 21:58:54,761:INFO:Uploading model into container now
2024-10-15 21:58:54,761:INFO:_master_model_container: 13
2024-10-15 21:58:54,761:INFO:_display_container: 2
2024-10-15 21:58:54,762:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-10-15 21:58:54,762:INFO:create_model() successfully completed......................................
2024-10-15 21:58:55,005:INFO:SubProcess create_model() end ==================================
2024-10-15 21:58:55,005:INFO:Creating metrics dataframe
2024-10-15 21:58:55,021:INFO:Initializing Extra Trees Regressor
2024-10-15 21:58:55,021:INFO:Total runtime is 0.304282275835673 minutes
2024-10-15 21:58:55,026:INFO:SubProcess create_model() called ==================================
2024-10-15 21:58:55,027:INFO:Initializing create_model()
2024-10-15 21:58:55,027:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002234970B6D0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022343A933A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 21:58:55,027:INFO:Checking exceptions
2024-10-15 21:58:55,027:INFO:Importing libraries
2024-10-15 21:58:55,027:INFO:Copying training dataset
2024-10-15 21:58:55,034:INFO:Defining folds
2024-10-15 21:58:55,034:INFO:Declaring metric variables
2024-10-15 21:58:55,039:INFO:Importing untrained model
2024-10-15 21:58:55,044:INFO:Extra Trees Regressor Imported successfully
2024-10-15 21:58:55,052:INFO:Starting cross validation
2024-10-15 21:58:55,056:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-15 21:59:00,453:INFO:Calculating mean and std
2024-10-15 21:59:00,455:INFO:Creating metrics dataframe
2024-10-15 21:59:00,460:INFO:Uploading results into container
2024-10-15 21:59:00,461:INFO:Uploading model into container now
2024-10-15 21:59:00,461:INFO:_master_model_container: 14
2024-10-15 21:59:00,461:INFO:_display_container: 2
2024-10-15 21:59:00,462:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-10-15 21:59:00,463:INFO:create_model() successfully completed......................................
2024-10-15 21:59:00,688:INFO:SubProcess create_model() end ==================================
2024-10-15 21:59:00,688:INFO:Creating metrics dataframe
2024-10-15 21:59:00,703:INFO:Initializing AdaBoost Regressor
2024-10-15 21:59:00,703:INFO:Total runtime is 0.3989819288253784 minutes
2024-10-15 21:59:00,708:INFO:SubProcess create_model() called ==================================
2024-10-15 21:59:00,708:INFO:Initializing create_model()
2024-10-15 21:59:00,708:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002234970B6D0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022343A933A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 21:59:00,708:INFO:Checking exceptions
2024-10-15 21:59:00,708:INFO:Importing libraries
2024-10-15 21:59:00,708:INFO:Copying training dataset
2024-10-15 21:59:00,716:INFO:Defining folds
2024-10-15 21:59:00,716:INFO:Declaring metric variables
2024-10-15 21:59:00,721:INFO:Importing untrained model
2024-10-15 21:59:00,727:INFO:AdaBoost Regressor Imported successfully
2024-10-15 21:59:00,736:INFO:Starting cross validation
2024-10-15 21:59:00,739:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-15 21:59:02,412:INFO:Calculating mean and std
2024-10-15 21:59:02,414:INFO:Creating metrics dataframe
2024-10-15 21:59:02,417:INFO:Uploading results into container
2024-10-15 21:59:02,418:INFO:Uploading model into container now
2024-10-15 21:59:02,419:INFO:_master_model_container: 15
2024-10-15 21:59:02,419:INFO:_display_container: 2
2024-10-15 21:59:02,419:INFO:AdaBoostRegressor(random_state=123)
2024-10-15 21:59:02,419:INFO:create_model() successfully completed......................................
2024-10-15 21:59:02,629:INFO:SubProcess create_model() end ==================================
2024-10-15 21:59:02,629:INFO:Creating metrics dataframe
2024-10-15 21:59:02,654:INFO:Initializing Gradient Boosting Regressor
2024-10-15 21:59:02,654:INFO:Total runtime is 0.431501309076945 minutes
2024-10-15 21:59:02,660:INFO:SubProcess create_model() called ==================================
2024-10-15 21:59:02,661:INFO:Initializing create_model()
2024-10-15 21:59:02,662:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002234970B6D0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022343A933A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 21:59:02,662:INFO:Checking exceptions
2024-10-15 21:59:02,662:INFO:Importing libraries
2024-10-15 21:59:02,662:INFO:Copying training dataset
2024-10-15 21:59:02,673:INFO:Defining folds
2024-10-15 21:59:02,674:INFO:Declaring metric variables
2024-10-15 21:59:02,680:INFO:Importing untrained model
2024-10-15 21:59:02,691:INFO:Gradient Boosting Regressor Imported successfully
2024-10-15 21:59:02,701:INFO:Starting cross validation
2024-10-15 21:59:02,705:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-15 21:59:04,572:INFO:Calculating mean and std
2024-10-15 21:59:04,573:INFO:Creating metrics dataframe
2024-10-15 21:59:04,577:INFO:Uploading results into container
2024-10-15 21:59:04,579:INFO:Uploading model into container now
2024-10-15 21:59:04,579:INFO:_master_model_container: 16
2024-10-15 21:59:04,579:INFO:_display_container: 2
2024-10-15 21:59:04,580:INFO:GradientBoostingRegressor(random_state=123)
2024-10-15 21:59:04,580:INFO:create_model() successfully completed......................................
2024-10-15 21:59:04,781:INFO:SubProcess create_model() end ==================================
2024-10-15 21:59:04,781:INFO:Creating metrics dataframe
2024-10-15 21:59:04,799:INFO:Initializing Extreme Gradient Boosting
2024-10-15 21:59:04,800:INFO:Total runtime is 0.4672688841819763 minutes
2024-10-15 21:59:04,804:INFO:SubProcess create_model() called ==================================
2024-10-15 21:59:04,804:INFO:Initializing create_model()
2024-10-15 21:59:04,804:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002234970B6D0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022343A933A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 21:59:04,804:INFO:Checking exceptions
2024-10-15 21:59:04,805:INFO:Importing libraries
2024-10-15 21:59:04,805:INFO:Copying training dataset
2024-10-15 21:59:04,813:INFO:Defining folds
2024-10-15 21:59:04,813:INFO:Declaring metric variables
2024-10-15 21:59:04,819:INFO:Importing untrained model
2024-10-15 21:59:04,824:INFO:Extreme Gradient Boosting Imported successfully
2024-10-15 21:59:04,836:INFO:Starting cross validation
2024-10-15 21:59:04,840:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-15 21:59:06,788:INFO:Calculating mean and std
2024-10-15 21:59:06,790:INFO:Creating metrics dataframe
2024-10-15 21:59:06,795:INFO:Uploading results into container
2024-10-15 21:59:06,796:INFO:Uploading model into container now
2024-10-15 21:59:06,797:INFO:_master_model_container: 17
2024-10-15 21:59:06,797:INFO:_display_container: 2
2024-10-15 21:59:06,798:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=123, ...)
2024-10-15 21:59:06,798:INFO:create_model() successfully completed......................................
2024-10-15 21:59:06,994:INFO:SubProcess create_model() end ==================================
2024-10-15 21:59:06,995:INFO:Creating metrics dataframe
2024-10-15 21:59:07,011:INFO:Initializing Light Gradient Boosting Machine
2024-10-15 21:59:07,011:INFO:Total runtime is 0.5041146000226339 minutes
2024-10-15 21:59:07,016:INFO:SubProcess create_model() called ==================================
2024-10-15 21:59:07,016:INFO:Initializing create_model()
2024-10-15 21:59:07,016:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002234970B6D0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022343A933A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 21:59:07,016:INFO:Checking exceptions
2024-10-15 21:59:07,016:INFO:Importing libraries
2024-10-15 21:59:07,016:INFO:Copying training dataset
2024-10-15 21:59:07,024:INFO:Defining folds
2024-10-15 21:59:07,024:INFO:Declaring metric variables
2024-10-15 21:59:07,030:INFO:Importing untrained model
2024-10-15 21:59:07,035:INFO:Light Gradient Boosting Machine Imported successfully
2024-10-15 21:59:07,056:INFO:Starting cross validation
2024-10-15 21:59:07,067:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-15 21:59:08,843:INFO:Calculating mean and std
2024-10-15 21:59:08,845:INFO:Creating metrics dataframe
2024-10-15 21:59:08,851:INFO:Uploading results into container
2024-10-15 21:59:08,852:INFO:Uploading model into container now
2024-10-15 21:59:08,853:INFO:_master_model_container: 18
2024-10-15 21:59:08,853:INFO:_display_container: 2
2024-10-15 21:59:08,854:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-10-15 21:59:08,854:INFO:create_model() successfully completed......................................
2024-10-15 21:59:09,092:INFO:SubProcess create_model() end ==================================
2024-10-15 21:59:09,093:INFO:Creating metrics dataframe
2024-10-15 21:59:09,108:INFO:Initializing CatBoost Regressor
2024-10-15 21:59:09,108:INFO:Total runtime is 0.5390772819519043 minutes
2024-10-15 21:59:09,112:INFO:SubProcess create_model() called ==================================
2024-10-15 21:59:09,112:INFO:Initializing create_model()
2024-10-15 21:59:09,112:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002234970B6D0>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022343A933A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 21:59:09,113:INFO:Checking exceptions
2024-10-15 21:59:09,113:INFO:Importing libraries
2024-10-15 21:59:09,113:INFO:Copying training dataset
2024-10-15 21:59:09,120:INFO:Defining folds
2024-10-15 21:59:09,120:INFO:Declaring metric variables
2024-10-15 21:59:09,125:INFO:Importing untrained model
2024-10-15 21:59:09,130:INFO:CatBoost Regressor Imported successfully
2024-10-15 21:59:09,139:INFO:Starting cross validation
2024-10-15 21:59:09,142:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-15 21:59:41,925:INFO:Calculating mean and std
2024-10-15 21:59:41,928:INFO:Creating metrics dataframe
2024-10-15 21:59:41,933:INFO:Uploading results into container
2024-10-15 21:59:41,933:INFO:Uploading model into container now
2024-10-15 21:59:41,935:INFO:_master_model_container: 19
2024-10-15 21:59:41,935:INFO:_display_container: 2
2024-10-15 21:59:41,935:INFO:<catboost.core.CatBoostRegressor object at 0x000002235BF6B880>
2024-10-15 21:59:41,935:INFO:create_model() successfully completed......................................
2024-10-15 21:59:42,170:INFO:SubProcess create_model() end ==================================
2024-10-15 21:59:42,170:INFO:Creating metrics dataframe
2024-10-15 21:59:42,186:INFO:Initializing Dummy Regressor
2024-10-15 21:59:42,186:INFO:Total runtime is 1.0903719544410706 minutes
2024-10-15 21:59:42,190:INFO:SubProcess create_model() called ==================================
2024-10-15 21:59:42,191:INFO:Initializing create_model()
2024-10-15 21:59:42,191:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002234970B6D0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022343A933A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 21:59:42,191:INFO:Checking exceptions
2024-10-15 21:59:42,192:INFO:Importing libraries
2024-10-15 21:59:42,192:INFO:Copying training dataset
2024-10-15 21:59:42,200:INFO:Defining folds
2024-10-15 21:59:42,200:INFO:Declaring metric variables
2024-10-15 21:59:42,204:INFO:Importing untrained model
2024-10-15 21:59:42,211:INFO:Dummy Regressor Imported successfully
2024-10-15 21:59:42,221:INFO:Starting cross validation
2024-10-15 21:59:42,225:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-15 21:59:42,995:INFO:Calculating mean and std
2024-10-15 21:59:42,996:INFO:Creating metrics dataframe
2024-10-15 21:59:43,000:INFO:Uploading results into container
2024-10-15 21:59:43,001:INFO:Uploading model into container now
2024-10-15 21:59:43,001:INFO:_master_model_container: 20
2024-10-15 21:59:43,001:INFO:_display_container: 2
2024-10-15 21:59:43,002:INFO:DummyRegressor()
2024-10-15 21:59:43,002:INFO:create_model() successfully completed......................................
2024-10-15 21:59:43,216:INFO:SubProcess create_model() end ==================================
2024-10-15 21:59:43,216:INFO:Creating metrics dataframe
2024-10-15 21:59:43,249:INFO:Initializing create_model()
2024-10-15 21:59:43,249:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002234970B6D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 21:59:43,249:INFO:Checking exceptions
2024-10-15 21:59:43,252:INFO:Importing libraries
2024-10-15 21:59:43,252:INFO:Copying training dataset
2024-10-15 21:59:43,262:INFO:Defining folds
2024-10-15 21:59:43,262:INFO:Declaring metric variables
2024-10-15 21:59:43,262:INFO:Importing untrained model
2024-10-15 21:59:43,262:INFO:Declaring custom model
2024-10-15 21:59:43,264:INFO:Light Gradient Boosting Machine Imported successfully
2024-10-15 21:59:43,268:INFO:Cross validation set to False
2024-10-15 21:59:43,268:INFO:Fitting Model
2024-10-15 21:59:43,483:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-10-15 21:59:43,487:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001691 seconds.
2024-10-15 21:59:43,488:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-10-15 21:59:43,488:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-10-15 21:59:43,488:INFO:[LightGBM] [Info] Total Bins 733
2024-10-15 21:59:43,488:INFO:[LightGBM] [Info] Number of data points in the train set: 500, number of used features: 189
2024-10-15 21:59:43,489:INFO:[LightGBM] [Info] Start training from score 345.334727
2024-10-15 21:59:43,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 21:59:43,596:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-10-15 21:59:43,596:INFO:create_model() successfully completed......................................
2024-10-15 21:59:43,825:INFO:Initializing create_model()
2024-10-15 21:59:43,825:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002234970B6D0>, estimator=<catboost.core.CatBoostRegressor object at 0x000002235BF6B880>, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 21:59:43,826:INFO:Checking exceptions
2024-10-15 21:59:43,829:INFO:Importing libraries
2024-10-15 21:59:43,829:INFO:Copying training dataset
2024-10-15 21:59:43,834:INFO:Defining folds
2024-10-15 21:59:43,834:INFO:Declaring metric variables
2024-10-15 21:59:43,834:INFO:Importing untrained model
2024-10-15 21:59:43,834:INFO:Declaring custom model
2024-10-15 21:59:43,835:INFO:CatBoost Regressor Imported successfully
2024-10-15 21:59:43,837:INFO:Cross validation set to False
2024-10-15 21:59:43,837:INFO:Fitting Model
2024-10-15 21:59:48,836:INFO:<catboost.core.CatBoostRegressor object at 0x000002235BF6A5C0>
2024-10-15 21:59:48,836:INFO:create_model() successfully completed......................................
2024-10-15 21:59:49,048:INFO:Initializing create_model()
2024-10-15 21:59:49,048:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002234970B6D0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 21:59:49,048:INFO:Checking exceptions
2024-10-15 21:59:49,051:INFO:Importing libraries
2024-10-15 21:59:49,051:INFO:Copying training dataset
2024-10-15 21:59:49,058:INFO:Defining folds
2024-10-15 21:59:49,058:INFO:Declaring metric variables
2024-10-15 21:59:49,058:INFO:Importing untrained model
2024-10-15 21:59:49,058:INFO:Declaring custom model
2024-10-15 21:59:49,059:INFO:Extra Trees Regressor Imported successfully
2024-10-15 21:59:49,062:INFO:Cross validation set to False
2024-10-15 21:59:49,062:INFO:Fitting Model
2024-10-15 21:59:49,650:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-10-15 21:59:49,651:INFO:create_model() successfully completed......................................
2024-10-15 21:59:49,868:INFO:Initializing create_model()
2024-10-15 21:59:49,869:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002234970B6D0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 21:59:49,869:INFO:Checking exceptions
2024-10-15 21:59:49,872:INFO:Importing libraries
2024-10-15 21:59:49,872:INFO:Copying training dataset
2024-10-15 21:59:49,878:INFO:Defining folds
2024-10-15 21:59:49,879:INFO:Declaring metric variables
2024-10-15 21:59:49,879:INFO:Importing untrained model
2024-10-15 21:59:49,879:INFO:Declaring custom model
2024-10-15 21:59:49,880:INFO:Random Forest Regressor Imported successfully
2024-10-15 21:59:49,882:INFO:Cross validation set to False
2024-10-15 21:59:49,882:INFO:Fitting Model
2024-10-15 21:59:50,382:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-10-15 21:59:50,382:INFO:create_model() successfully completed......................................
2024-10-15 21:59:50,608:INFO:Initializing create_model()
2024-10-15 21:59:50,608:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002234970B6D0>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 21:59:50,608:INFO:Checking exceptions
2024-10-15 21:59:50,611:INFO:Importing libraries
2024-10-15 21:59:50,611:INFO:Copying training dataset
2024-10-15 21:59:50,617:INFO:Defining folds
2024-10-15 21:59:50,617:INFO:Declaring metric variables
2024-10-15 21:59:50,617:INFO:Importing untrained model
2024-10-15 21:59:50,617:INFO:Declaring custom model
2024-10-15 21:59:50,617:INFO:Gradient Boosting Regressor Imported successfully
2024-10-15 21:59:50,622:INFO:Cross validation set to False
2024-10-15 21:59:50,622:INFO:Fitting Model
2024-10-15 21:59:51,066:INFO:GradientBoostingRegressor(random_state=123)
2024-10-15 21:59:51,066:INFO:create_model() successfully completed......................................
2024-10-15 21:59:51,260:INFO:Initializing create_model()
2024-10-15 21:59:51,260:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002234970B6D0>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=123, ...), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 21:59:51,260:INFO:Checking exceptions
2024-10-15 21:59:51,263:INFO:Importing libraries
2024-10-15 21:59:51,263:INFO:Copying training dataset
2024-10-15 21:59:51,267:INFO:Defining folds
2024-10-15 21:59:51,267:INFO:Declaring metric variables
2024-10-15 21:59:51,268:INFO:Importing untrained model
2024-10-15 21:59:51,268:INFO:Declaring custom model
2024-10-15 21:59:51,269:INFO:Extreme Gradient Boosting Imported successfully
2024-10-15 21:59:51,272:INFO:Cross validation set to False
2024-10-15 21:59:51,272:INFO:Fitting Model
2024-10-15 21:59:51,688:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=123, ...)
2024-10-15 21:59:51,688:INFO:create_model() successfully completed......................................
2024-10-15 21:59:51,922:INFO:Initializing create_model()
2024-10-15 21:59:51,922:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002234970B6D0>, estimator=DecisionTreeRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 21:59:51,922:INFO:Checking exceptions
2024-10-15 21:59:51,926:INFO:Importing libraries
2024-10-15 21:59:51,926:INFO:Copying training dataset
2024-10-15 21:59:51,931:INFO:Defining folds
2024-10-15 21:59:51,931:INFO:Declaring metric variables
2024-10-15 21:59:51,932:INFO:Importing untrained model
2024-10-15 21:59:51,932:INFO:Declaring custom model
2024-10-15 21:59:51,933:INFO:Decision Tree Regressor Imported successfully
2024-10-15 21:59:51,936:INFO:Cross validation set to False
2024-10-15 21:59:51,936:INFO:Fitting Model
2024-10-15 21:59:52,071:INFO:DecisionTreeRegressor(random_state=123)
2024-10-15 21:59:52,072:INFO:create_model() successfully completed......................................
2024-10-15 21:59:52,274:INFO:Initializing create_model()
2024-10-15 21:59:52,274:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002234970B6D0>, estimator=AdaBoostRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 21:59:52,275:INFO:Checking exceptions
2024-10-15 21:59:52,277:INFO:Importing libraries
2024-10-15 21:59:52,277:INFO:Copying training dataset
2024-10-15 21:59:52,283:INFO:Defining folds
2024-10-15 21:59:52,283:INFO:Declaring metric variables
2024-10-15 21:59:52,284:INFO:Importing untrained model
2024-10-15 21:59:52,284:INFO:Declaring custom model
2024-10-15 21:59:52,284:INFO:AdaBoost Regressor Imported successfully
2024-10-15 21:59:52,289:INFO:Cross validation set to False
2024-10-15 21:59:52,289:INFO:Fitting Model
2024-10-15 21:59:52,659:INFO:AdaBoostRegressor(random_state=123)
2024-10-15 21:59:52,660:INFO:create_model() successfully completed......................................
2024-10-15 21:59:52,867:INFO:Initializing create_model()
2024-10-15 21:59:52,868:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002234970B6D0>, estimator=KNeighborsRegressor(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 21:59:52,868:INFO:Checking exceptions
2024-10-15 21:59:52,871:INFO:Importing libraries
2024-10-15 21:59:52,871:INFO:Copying training dataset
2024-10-15 21:59:52,876:INFO:Defining folds
2024-10-15 21:59:52,876:INFO:Declaring metric variables
2024-10-15 21:59:52,876:INFO:Importing untrained model
2024-10-15 21:59:52,876:INFO:Declaring custom model
2024-10-15 21:59:52,876:INFO:K Neighbors Regressor Imported successfully
2024-10-15 21:59:52,879:INFO:Cross validation set to False
2024-10-15 21:59:52,879:INFO:Fitting Model
2024-10-15 21:59:52,987:INFO:KNeighborsRegressor(n_jobs=-1)
2024-10-15 21:59:52,987:INFO:create_model() successfully completed......................................
2024-10-15 21:59:53,189:INFO:Initializing create_model()
2024-10-15 21:59:53,189:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002234970B6D0>, estimator=DummyRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 21:59:53,189:INFO:Checking exceptions
2024-10-15 21:59:53,192:INFO:Importing libraries
2024-10-15 21:59:53,192:INFO:Copying training dataset
2024-10-15 21:59:53,197:INFO:Defining folds
2024-10-15 21:59:53,197:INFO:Declaring metric variables
2024-10-15 21:59:53,197:INFO:Importing untrained model
2024-10-15 21:59:53,197:INFO:Declaring custom model
2024-10-15 21:59:53,198:INFO:Dummy Regressor Imported successfully
2024-10-15 21:59:53,200:INFO:Cross validation set to False
2024-10-15 21:59:53,200:INFO:Fitting Model
2024-10-15 21:59:53,306:INFO:DummyRegressor()
2024-10-15 21:59:53,306:INFO:create_model() successfully completed......................................
2024-10-15 21:59:53,525:INFO:_master_model_container: 20
2024-10-15 21:59:53,525:INFO:_display_container: 2
2024-10-15 21:59:53,528:INFO:[LGBMRegressor(n_jobs=-1, random_state=123), <catboost.core.CatBoostRegressor object at 0x000002235BF6A5C0>, ExtraTreesRegressor(n_jobs=-1, random_state=123), RandomForestRegressor(n_jobs=-1, random_state=123), GradientBoostingRegressor(random_state=123), XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=123, ...), DecisionTreeRegressor(random_state=123), AdaBoostRegressor(random_state=123), KNeighborsRegressor(n_jobs=-1), DummyRegressor()]
2024-10-15 21:59:53,528:INFO:compare_models() successfully completed......................................
2024-10-15 22:00:06,589:INFO:Initializing plot_model()
2024-10-15 22:00:06,590:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=4, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002234970B6D0>, system=True)
2024-10-15 22:00:06,590:INFO:Checking exceptions
2024-10-15 22:00:06,597:INFO:Preloading libraries
2024-10-15 22:00:06,605:INFO:Copying training dataset
2024-10-15 22:00:06,605:INFO:Plot type: error
2024-10-15 22:00:07,152:INFO:Fitting Model
2024-10-15 22:00:07,152:INFO:Scoring test/hold-out set
2024-10-15 22:00:07,486:INFO:Visual Rendered Successfully
2024-10-15 22:00:07,701:INFO:plot_model() successfully completed......................................
2024-10-15 22:00:25,829:INFO:Initializing plot_model()
2024-10-15 22:00:25,829:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=5, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002234970B6D0>, system=True)
2024-10-15 22:00:25,829:INFO:Checking exceptions
2024-10-15 22:00:25,835:INFO:Preloading libraries
2024-10-15 22:00:25,846:INFO:Copying training dataset
2024-10-15 22:00:25,846:INFO:Plot type: error
2024-10-15 22:00:26,014:INFO:Fitting Model
2024-10-15 22:00:26,015:INFO:Scoring test/hold-out set
2024-10-15 22:00:26,449:INFO:Visual Rendered Successfully
2024-10-15 22:00:26,653:INFO:plot_model() successfully completed......................................
2024-10-15 22:00:32,973:INFO:Initializing plot_model()
2024-10-15 22:00:32,974:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=3, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002234970B6D0>, system=True)
2024-10-15 22:00:32,974:INFO:Checking exceptions
2024-10-15 22:00:32,981:INFO:Preloading libraries
2024-10-15 22:00:32,992:INFO:Copying training dataset
2024-10-15 22:00:32,992:INFO:Plot type: error
2024-10-15 22:00:33,167:INFO:Fitting Model
2024-10-15 22:00:33,168:INFO:Scoring test/hold-out set
2024-10-15 22:00:33,501:INFO:Visual Rendered Successfully
2024-10-15 22:00:33,701:INFO:plot_model() successfully completed......................................
2024-10-15 22:00:43,694:INFO:Initializing plot_model()
2024-10-15 22:00:43,694:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=3, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002234970B6D0>, system=True)
2024-10-15 22:00:43,694:INFO:Checking exceptions
2024-10-15 22:00:43,702:INFO:Preloading libraries
2024-10-15 22:00:43,710:INFO:Copying training dataset
2024-10-15 22:00:43,711:INFO:Plot type: error
2024-10-15 22:00:43,860:INFO:Fitting Model
2024-10-15 22:00:43,860:INFO:Scoring test/hold-out set
2024-10-15 22:00:44,187:INFO:Visual Rendered Successfully
2024-10-15 22:00:44,409:INFO:plot_model() successfully completed......................................
2024-10-15 22:00:44,410:INFO:Initializing plot_model()
2024-10-15 22:00:44,410:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=<catboost.core.CatBoostRegressor object at 0x000002235BF6A5C0>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=3, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002234970B6D0>, system=True)
2024-10-15 22:00:44,410:INFO:Checking exceptions
2024-10-15 22:00:44,415:INFO:Preloading libraries
2024-10-15 22:00:44,419:INFO:Copying training dataset
2024-10-15 22:00:44,419:INFO:Plot type: error
2024-10-15 22:00:44,542:INFO:Fitting Model
2024-10-15 22:00:44,543:INFO:Scoring test/hold-out set
2024-10-15 22:00:44,841:INFO:Visual Rendered Successfully
2024-10-15 22:00:45,040:INFO:plot_model() successfully completed......................................
2024-10-15 22:01:23,672:INFO:Initializing plot_model()
2024-10-15 22:01:23,673:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=<catboost.core.CatBoostRegressor object at 0x000002235BF6A5C0>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=3, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002234970B6D0>, system=True)
2024-10-15 22:01:23,673:INFO:Checking exceptions
2024-10-15 22:01:23,680:INFO:Preloading libraries
2024-10-15 22:01:23,685:INFO:Copying training dataset
2024-10-15 22:01:23,685:INFO:Plot type: error
2024-10-15 22:01:23,831:INFO:Fitting Model
2024-10-15 22:01:23,832:INFO:Scoring test/hold-out set
2024-10-15 22:01:24,124:INFO:Visual Rendered Successfully
2024-10-15 22:01:24,378:INFO:plot_model() successfully completed......................................
2024-10-15 22:01:24,379:INFO:Initializing plot_model()
2024-10-15 22:01:24,379:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=3, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002234970B6D0>, system=True)
2024-10-15 22:01:24,379:INFO:Checking exceptions
2024-10-15 22:01:24,404:INFO:Preloading libraries
2024-10-15 22:01:24,421:INFO:Copying training dataset
2024-10-15 22:01:24,422:INFO:Plot type: error
2024-10-15 22:01:24,563:INFO:Fitting Model
2024-10-15 22:01:24,563:WARNING:X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names

2024-10-15 22:01:24,564:INFO:Scoring test/hold-out set
2024-10-15 22:01:24,893:INFO:Visual Rendered Successfully
2024-10-15 22:01:25,114:INFO:plot_model() successfully completed......................................
2024-10-15 22:01:32,352:INFO:Initializing plot_model()
2024-10-15 22:01:32,352:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=<catboost.core.CatBoostRegressor object at 0x000002235BF6A5C0>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=3, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002234970B6D0>, system=True)
2024-10-15 22:01:32,353:INFO:Checking exceptions
2024-10-15 22:01:32,361:INFO:Preloading libraries
2024-10-15 22:01:32,366:INFO:Copying training dataset
2024-10-15 22:01:32,366:INFO:Plot type: error
2024-10-15 22:01:32,535:INFO:Fitting Model
2024-10-15 22:01:32,536:INFO:Scoring test/hold-out set
2024-10-15 22:01:32,826:INFO:Visual Rendered Successfully
2024-10-15 22:01:33,026:INFO:plot_model() successfully completed......................................
2024-10-15 22:01:33,027:INFO:Initializing plot_model()
2024-10-15 22:01:33,027:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=3, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002234970B6D0>, system=True)
2024-10-15 22:01:33,027:INFO:Checking exceptions
2024-10-15 22:01:33,051:INFO:Preloading libraries
2024-10-15 22:01:33,062:INFO:Copying training dataset
2024-10-15 22:01:33,063:INFO:Plot type: error
2024-10-15 22:01:33,202:INFO:Fitting Model
2024-10-15 22:01:33,202:WARNING:X does not have valid feature names, but RandomForestRegressor was fitted with feature names

2024-10-15 22:01:33,202:INFO:Scoring test/hold-out set
2024-10-15 22:01:33,608:INFO:Visual Rendered Successfully
2024-10-15 22:01:33,830:INFO:plot_model() successfully completed......................................
2024-10-15 22:01:51,305:INFO:Initializing plot_model()
2024-10-15 22:01:51,305:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=3, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002234970B6D0>, system=True)
2024-10-15 22:01:51,305:INFO:Checking exceptions
2024-10-15 22:01:51,312:INFO:Preloading libraries
2024-10-15 22:01:51,322:INFO:Copying training dataset
2024-10-15 22:01:51,322:INFO:Plot type: error
2024-10-15 22:01:51,496:INFO:Fitting Model
2024-10-15 22:01:51,496:INFO:Scoring test/hold-out set
2024-10-15 22:01:51,819:INFO:Visual Rendered Successfully
2024-10-15 22:01:52,039:INFO:plot_model() successfully completed......................................
2024-10-15 22:01:52,040:INFO:Initializing plot_model()
2024-10-15 22:01:52,040:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=<catboost.core.CatBoostRegressor object at 0x000002235BF6A5C0>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=3, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002234970B6D0>, system=True)
2024-10-15 22:01:52,040:INFO:Checking exceptions
2024-10-15 22:01:52,045:INFO:Preloading libraries
2024-10-15 22:01:52,049:INFO:Copying training dataset
2024-10-15 22:01:52,049:INFO:Plot type: error
2024-10-15 22:01:52,171:INFO:Fitting Model
2024-10-15 22:01:52,171:INFO:Scoring test/hold-out set
2024-10-15 22:01:52,444:INFO:Visual Rendered Successfully
2024-10-15 22:01:52,661:INFO:plot_model() successfully completed......................................
2024-10-15 22:03:43,141:INFO:Initializing plot_model()
2024-10-15 22:03:43,141:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=<catboost.core.CatBoostRegressor object at 0x000002235BF6A5C0>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002234970B6D0>, system=True)
2024-10-15 22:03:43,141:INFO:Checking exceptions
2024-10-15 22:03:43,145:INFO:Preloading libraries
2024-10-15 22:03:43,150:INFO:Copying training dataset
2024-10-15 22:03:43,150:INFO:Plot type: feature
2024-10-15 22:03:43,151:WARNING:No coef_ found. Trying feature_importances_
2024-10-15 22:03:43,277:INFO:Visual Rendered Successfully
2024-10-15 22:03:43,468:INFO:plot_model() successfully completed......................................
2024-10-15 22:03:53,060:INFO:Initializing interpret_model()
2024-10-15 22:03:53,060:INFO:interpret_model(estimator=<catboost.core.CatBoostRegressor object at 0x000002235BF6A5C0>, use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002234970B6D0>)
2024-10-15 22:03:53,060:INFO:Checking exceptions
2024-10-15 22:03:53,060:INFO:Soft dependency imported: shap: 0.44.1
2024-10-15 22:03:53,093:INFO:plot type: summary
2024-10-15 22:03:53,093:INFO:Creating TreeExplainer
2024-10-15 22:03:53,184:INFO:Compiling shap values
2024-10-15 22:03:54,214:INFO:Visual Rendered Successfully
2024-10-15 22:03:54,214:INFO:interpret_model() successfully completed......................................
2024-10-15 22:05:56,500:INFO:Initializing predict_model()
2024-10-15 22:05:56,500:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002234970B6D0>, estimator=<catboost.core.CatBoostRegressor object at 0x000002235BF6A5C0>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002234B4FF9A0>)
2024-10-15 22:05:56,500:INFO:Checking exceptions
2024-10-15 22:05:56,500:INFO:Preloading libraries
2024-10-15 22:05:56,502:INFO:Set up data.
2024-10-15 22:05:56,569:INFO:Set up index.
2024-10-15 22:05:56,672:WARNING:'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.

2024-10-15 22:07:02,630:INFO:Initializing predict_model()
2024-10-15 22:07:02,631:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002234970B6D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002233A6E9EA0>)
2024-10-15 22:07:02,631:INFO:Checking exceptions
2024-10-15 22:07:02,631:INFO:Preloading libraries
2024-10-15 22:07:02,633:INFO:Set up data.
2024-10-15 22:07:02,702:INFO:Set up index.
2024-10-15 22:07:02,796:WARNING:'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.

2024-10-15 22:07:09,648:INFO:Initializing predict_model()
2024-10-15 22:07:09,648:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002234970B6D0>, estimator=<catboost.core.CatBoostRegressor object at 0x000002235BF6A5C0>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002234B139870>)
2024-10-15 22:07:09,648:INFO:Checking exceptions
2024-10-15 22:07:09,648:INFO:Preloading libraries
2024-10-15 22:07:09,651:INFO:Set up data.
2024-10-15 22:07:09,706:INFO:Set up index.
2024-10-15 22:07:09,805:WARNING:'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.

2024-10-15 22:07:13,841:INFO:Initializing predict_model()
2024-10-15 22:07:13,841:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002234970B6D0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022338372F80>)
2024-10-15 22:07:13,841:INFO:Checking exceptions
2024-10-15 22:07:13,842:INFO:Preloading libraries
2024-10-15 22:07:13,844:INFO:Set up data.
2024-10-15 22:07:13,903:INFO:Set up index.
2024-10-15 22:07:14,016:WARNING:'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.

2024-10-15 22:07:18,914:INFO:Initializing predict_model()
2024-10-15 22:07:18,914:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002234970B6D0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002234AE1C4C0>)
2024-10-15 22:07:18,914:INFO:Checking exceptions
2024-10-15 22:07:18,914:INFO:Preloading libraries
2024-10-15 22:07:18,917:INFO:Set up data.
2024-10-15 22:07:18,970:INFO:Set up index.
2024-10-15 22:07:19,081:WARNING:'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.

2024-10-15 22:07:23,174:INFO:Initializing predict_model()
2024-10-15 22:07:23,174:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002234970B6D0>, estimator=GradientBoostingRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002233B749A20>)
2024-10-15 22:07:23,174:INFO:Checking exceptions
2024-10-15 22:07:23,174:INFO:Preloading libraries
2024-10-15 22:07:23,177:INFO:Set up data.
2024-10-15 22:07:23,235:INFO:Set up index.
2024-10-15 22:07:23,351:WARNING:'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.

2024-10-15 22:07:27,460:INFO:Initializing predict_model()
2024-10-15 22:07:27,460:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002234970B6D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002233A6EAC20>)
2024-10-15 22:07:27,460:INFO:Checking exceptions
2024-10-15 22:07:27,460:INFO:Preloading libraries
2024-10-15 22:07:27,462:INFO:Set up data.
2024-10-15 22:07:27,518:INFO:Set up index.
2024-10-15 22:07:27,624:WARNING:'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.

2024-10-15 22:07:31,880:INFO:Initializing predict_model()
2024-10-15 22:07:31,880:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002234970B6D0>, estimator=<catboost.core.CatBoostRegressor object at 0x000002235BF6A5C0>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002233A6EA200>)
2024-10-15 22:07:31,880:INFO:Checking exceptions
2024-10-15 22:07:31,880:INFO:Preloading libraries
2024-10-15 22:07:31,882:INFO:Set up data.
2024-10-15 22:07:31,952:INFO:Set up index.
2024-10-15 22:07:32,060:WARNING:'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.

2024-10-15 22:07:36,142:INFO:Initializing predict_model()
2024-10-15 22:07:36,142:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002234970B6D0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002233C1E7E20>)
2024-10-15 22:07:36,143:INFO:Checking exceptions
2024-10-15 22:07:36,143:INFO:Preloading libraries
2024-10-15 22:07:36,145:INFO:Set up data.
2024-10-15 22:07:36,207:INFO:Set up index.
2024-10-15 22:07:36,326:WARNING:'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.

2024-10-15 22:07:40,694:INFO:Initializing predict_model()
2024-10-15 22:07:40,694:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002234970B6D0>, estimator=<catboost.core.CatBoostRegressor object at 0x000002235BF6A5C0>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002234B139870>)
2024-10-15 22:07:40,694:INFO:Checking exceptions
2024-10-15 22:07:40,694:INFO:Preloading libraries
2024-10-15 22:07:40,696:INFO:Set up data.
2024-10-15 22:07:40,752:INFO:Set up index.
2024-10-15 22:07:40,861:WARNING:'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.

2024-10-15 22:07:44,617:INFO:Initializing predict_model()
2024-10-15 22:07:44,617:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002234970B6D0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000223383720E0>)
2024-10-15 22:07:44,617:INFO:Checking exceptions
2024-10-15 22:07:44,617:INFO:Preloading libraries
2024-10-15 22:07:44,620:INFO:Set up data.
2024-10-15 22:07:44,692:INFO:Set up index.
2024-10-15 22:07:44,823:WARNING:'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.

2024-10-15 22:07:49,044:INFO:Initializing predict_model()
2024-10-15 22:07:49,044:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002234970B6D0>, estimator=<catboost.core.CatBoostRegressor object at 0x000002235BF6A5C0>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022343AC7E20>)
2024-10-15 22:07:49,044:INFO:Checking exceptions
2024-10-15 22:07:49,044:INFO:Preloading libraries
2024-10-15 22:07:49,047:INFO:Set up data.
2024-10-15 22:07:49,105:INFO:Set up index.
2024-10-15 22:07:49,202:WARNING:'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.

2024-10-15 22:10:16,499:WARNING:The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.

2024-10-15 22:10:16,518:WARNING:The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.

2024-10-15 22:10:16,575:WARNING:Geometry column does not contain geometry.

2024-10-15 22:10:18,684:INFO:PyCaret RegressionExperiment
2024-10-15 22:10:18,685:INFO:Logging name: reg-default-name
2024-10-15 22:10:18,685:INFO:ML Usecase: MLUsecase.REGRESSION
2024-10-15 22:10:18,685:INFO:version 3.3.0
2024-10-15 22:10:18,685:INFO:Initializing setup()
2024-10-15 22:10:18,685:INFO:self.USI: ea72
2024-10-15 22:10:18,685:INFO:self._variable_keys: {'fold_groups_param', 'X_train', 'fold_generator', 'idx', 'USI', '_available_plots', '_ml_usecase', 'n_jobs_param', 'transform_target_param', 'html_param', 'y', 'target_param', 'y_test', 'gpu_n_jobs_param', 'memory', 'exp_name_log', 'log_plots_param', 'fold_shuffle_param', 'seed', 'X', 'gpu_param', 'logging_param', 'exp_id', 'data', 'pipeline', 'y_train', 'X_test'}
2024-10-15 22:10:18,685:INFO:Checking environment
2024-10-15 22:10:18,685:INFO:python_version: 3.10.4
2024-10-15 22:10:18,685:INFO:python_build: ('tags/v3.10.4:9d38120', 'Mar 23 2022 23:13:41')
2024-10-15 22:10:18,686:INFO:machine: AMD64
2024-10-15 22:10:18,686:INFO:platform: Windows-10-10.0.22631-SP0
2024-10-15 22:10:18,686:INFO:Memory: svmem(total=16954937344, available=3703943168, percent=78.2, used=13250994176, free=3703943168)
2024-10-15 22:10:18,686:INFO:Physical Core: 4
2024-10-15 22:10:18,686:INFO:Logical Core: 8
2024-10-15 22:10:18,686:INFO:Checking libraries
2024-10-15 22:10:18,686:INFO:System:
2024-10-15 22:10:18,686:INFO:    python: 3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]
2024-10-15 22:10:18,687:INFO:executable: c:\Users\genin\AppData\Local\Programs\Python\Python310\python.exe
2024-10-15 22:10:18,687:INFO:   machine: Windows-10-10.0.22631-SP0
2024-10-15 22:10:18,687:INFO:PyCaret required dependencies:
2024-10-15 22:10:18,687:INFO:                 pip: 23.1
2024-10-15 22:10:18,687:INFO:          setuptools: 67.7.1
2024-10-15 22:10:18,687:INFO:             pycaret: 3.3.0
2024-10-15 22:10:18,687:INFO:             IPython: 8.3.0
2024-10-15 22:10:18,687:INFO:          ipywidgets: 8.1.2
2024-10-15 22:10:18,687:INFO:                tqdm: 4.66.2
2024-10-15 22:10:18,687:INFO:               numpy: 1.22.4
2024-10-15 22:10:18,687:INFO:              pandas: 1.4.2
2024-10-15 22:10:18,688:INFO:              jinja2: 3.1.2
2024-10-15 22:10:18,688:INFO:               scipy: 1.10.1
2024-10-15 22:10:18,688:INFO:              joblib: 1.2.0
2024-10-15 22:10:18,688:INFO:             sklearn: 1.4.1.post1
2024-10-15 22:10:18,688:INFO:                pyod: 1.1.3
2024-10-15 22:10:18,688:INFO:            imblearn: 0.12.0
2024-10-15 22:10:18,688:INFO:   category_encoders: 2.6.3
2024-10-15 22:10:18,688:INFO:            lightgbm: 4.3.0
2024-10-15 22:10:18,688:INFO:               numba: 0.58.1
2024-10-15 22:10:18,688:INFO:            requests: 2.27.1
2024-10-15 22:10:18,688:INFO:          matplotlib: 3.5.2
2024-10-15 22:10:18,688:INFO:          scikitplot: 0.3.7
2024-10-15 22:10:18,688:INFO:         yellowbrick: 1.5
2024-10-15 22:10:18,689:INFO:              plotly: 5.19.0
2024-10-15 22:10:18,689:INFO:    plotly-resampler: Not installed
2024-10-15 22:10:18,689:INFO:             kaleido: 0.2.1
2024-10-15 22:10:18,689:INFO:           schemdraw: 0.15
2024-10-15 22:10:18,689:INFO:         statsmodels: 0.14.1
2024-10-15 22:10:18,689:INFO:              sktime: 0.26.0
2024-10-15 22:10:18,689:INFO:               tbats: 1.1.3
2024-10-15 22:10:18,689:INFO:            pmdarima: 2.0.4
2024-10-15 22:10:18,690:INFO:              psutil: 5.9.0
2024-10-15 22:10:18,690:INFO:          markupsafe: 2.1.1
2024-10-15 22:10:18,690:INFO:             pickle5: Not installed
2024-10-15 22:10:18,690:INFO:         cloudpickle: 3.0.0
2024-10-15 22:10:18,690:INFO:         deprecation: 2.1.0
2024-10-15 22:10:18,690:INFO:              xxhash: 3.4.1
2024-10-15 22:10:18,690:INFO:           wurlitzer: Not installed
2024-10-15 22:10:18,690:INFO:PyCaret optional dependencies:
2024-10-15 22:10:18,690:INFO:                shap: 0.44.1
2024-10-15 22:10:18,690:INFO:           interpret: 0.5.1
2024-10-15 22:10:18,690:INFO:                umap: 0.5.5
2024-10-15 22:10:18,690:INFO:     ydata_profiling: 4.6.5
2024-10-15 22:10:18,691:INFO:  explainerdashboard: 0.4.5
2024-10-15 22:10:18,691:INFO:             autoviz: Not installed
2024-10-15 22:10:18,691:INFO:           fairlearn: 0.7.0
2024-10-15 22:10:18,691:INFO:          deepchecks: Not installed
2024-10-15 22:10:18,691:INFO:             xgboost: 2.0.3
2024-10-15 22:10:18,691:INFO:            catboost: 1.2.3
2024-10-15 22:10:18,691:INFO:              kmodes: 0.12.2
2024-10-15 22:10:18,691:INFO:             mlxtend: 0.23.1
2024-10-15 22:10:18,691:INFO:       statsforecast: 1.5.0
2024-10-15 22:10:18,691:INFO:        tune_sklearn: 0.5.0
2024-10-15 22:10:18,691:INFO:                 ray: 2.9.3
2024-10-15 22:10:18,692:INFO:            hyperopt: 0.2.7
2024-10-15 22:10:18,692:INFO:              optuna: 3.5.0
2024-10-15 22:10:18,692:INFO:               skopt: 0.9.0
2024-10-15 22:10:18,692:INFO:              mlflow: 2.11.0
2024-10-15 22:10:18,692:INFO:              gradio: 4.19.2
2024-10-15 22:10:18,692:INFO:             fastapi: 0.110.0
2024-10-15 22:10:18,692:INFO:             uvicorn: 0.27.1
2024-10-15 22:10:18,692:INFO:              m2cgen: 0.10.0
2024-10-15 22:10:18,692:INFO:           evidently: 0.4.16
2024-10-15 22:10:18,692:INFO:               fugue: 0.8.6
2024-10-15 22:10:18,692:INFO:           streamlit: Not installed
2024-10-15 22:10:18,692:INFO:             prophet: Not installed
2024-10-15 22:10:18,693:INFO:None
2024-10-15 22:10:18,693:INFO:Set up data.
2024-10-15 22:10:18,750:INFO:Set up folding strategy.
2024-10-15 22:10:18,750:INFO:Set up train/test split.
2024-10-15 22:10:18,762:INFO:Set up index.
2024-10-15 22:10:18,762:INFO:Assigning column types.
2024-10-15 22:10:18,766:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-10-15 22:10:18,766:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-10-15 22:10:18,771:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-10-15 22:10:18,776:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-10-15 22:10:18,842:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-10-15 22:10:18,882:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-10-15 22:10:18,882:INFO:Soft dependency imported: xgboost: 2.0.3
2024-10-15 22:10:18,885:INFO:Soft dependency imported: catboost: 1.2.3
2024-10-15 22:10:18,886:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-10-15 22:10:18,890:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-10-15 22:10:18,894:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-10-15 22:10:18,959:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-10-15 22:10:19,009:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-10-15 22:10:19,010:INFO:Soft dependency imported: xgboost: 2.0.3
2024-10-15 22:10:19,015:INFO:Soft dependency imported: catboost: 1.2.3
2024-10-15 22:10:19,016:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-10-15 22:10:19,024:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-10-15 22:10:19,028:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-10-15 22:10:19,089:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-10-15 22:10:19,126:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-10-15 22:10:19,127:INFO:Soft dependency imported: xgboost: 2.0.3
2024-10-15 22:10:19,129:INFO:Soft dependency imported: catboost: 1.2.3
2024-10-15 22:10:19,134:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-10-15 22:10:19,138:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-10-15 22:10:19,188:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-10-15 22:10:19,226:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-10-15 22:10:19,226:INFO:Soft dependency imported: xgboost: 2.0.3
2024-10-15 22:10:19,229:INFO:Soft dependency imported: catboost: 1.2.3
2024-10-15 22:10:19,229:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-10-15 22:10:19,237:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-10-15 22:10:19,289:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-10-15 22:10:19,328:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-10-15 22:10:19,328:INFO:Soft dependency imported: xgboost: 2.0.3
2024-10-15 22:10:19,331:INFO:Soft dependency imported: catboost: 1.2.3
2024-10-15 22:10:19,342:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-10-15 22:10:19,398:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-10-15 22:10:19,446:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-10-15 22:10:19,446:INFO:Soft dependency imported: xgboost: 2.0.3
2024-10-15 22:10:19,449:INFO:Soft dependency imported: catboost: 1.2.3
2024-10-15 22:10:19,450:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-10-15 22:10:19,519:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-10-15 22:10:19,559:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-10-15 22:10:19,560:INFO:Soft dependency imported: xgboost: 2.0.3
2024-10-15 22:10:19,562:INFO:Soft dependency imported: catboost: 1.2.3
2024-10-15 22:10:19,640:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-10-15 22:10:19,686:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-10-15 22:10:19,687:INFO:Soft dependency imported: xgboost: 2.0.3
2024-10-15 22:10:19,689:INFO:Soft dependency imported: catboost: 1.2.3
2024-10-15 22:10:19,690:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-10-15 22:10:19,754:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-10-15 22:10:19,805:INFO:Soft dependency imported: xgboost: 2.0.3
2024-10-15 22:10:19,808:INFO:Soft dependency imported: catboost: 1.2.3
2024-10-15 22:10:19,873:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-10-15 22:10:19,941:INFO:Soft dependency imported: xgboost: 2.0.3
2024-10-15 22:10:19,944:INFO:Soft dependency imported: catboost: 1.2.3
2024-10-15 22:10:19,945:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-10-15 22:10:20,118:INFO:Soft dependency imported: xgboost: 2.0.3
2024-10-15 22:10:20,121:INFO:Soft dependency imported: catboost: 1.2.3
2024-10-15 22:10:20,220:INFO:Soft dependency imported: xgboost: 2.0.3
2024-10-15 22:10:20,223:INFO:Soft dependency imported: catboost: 1.2.3
2024-10-15 22:10:20,224:INFO:Preparing preprocessing pipeline...
2024-10-15 22:10:20,224:INFO:Set up simple imputation.
2024-10-15 22:10:20,227:INFO:Set up encoding of categorical features.
2024-10-15 22:10:20,227:INFO:Set up column name cleaning.
2024-10-15 22:10:20,368:INFO:Finished creating preprocessing pipeline.
2024-10-15 22:10:20,379:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\genin\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Area Construida', 'Area Total',
                                             'Habitaciones', 'Baños', 'Patio',
                                             'Deposito 1', 'Piso 2',
                                             'Tipo de comedor sala comedor',
                                             'Depósito o cuarto útil',
                                             'Tipo de casa tradicional',
                                             'Piso 3', 'Tipo de estufa gas',
                                             'Lote vacio',
                                             'Número de Ascensores 1',
                                             'Ti...
                 TransformerWrapper(include=['Edad', 'Estrato', 'date', 'city'],
                                    transformer=OneHotEncoder(cols=['Edad',
                                                                    'Estrato',
                                                                    'date',
                                                                    'city'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['grid_id'],
                                    transformer=TargetEncoder(cols=['grid_id'],
                                                              handle_missing='return_nan'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2024-10-15 22:10:20,379:INFO:Creating final display dataframe.
2024-10-15 22:10:20,739:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            Precio
2                   Target type        Regression
3           Original data shape        (677, 194)
4        Transformed data shape        (677, 210)
5   Transformed train set shape        (473, 210)
6    Transformed test set shape        (204, 210)
7              Numeric features               188
8          Categorical features                 5
9      Rows with missing values            100.0%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              ea72
2024-10-15 22:10:20,855:INFO:Soft dependency imported: xgboost: 2.0.3
2024-10-15 22:10:20,857:INFO:Soft dependency imported: catboost: 1.2.3
2024-10-15 22:10:20,970:INFO:Soft dependency imported: xgboost: 2.0.3
2024-10-15 22:10:20,972:INFO:Soft dependency imported: catboost: 1.2.3
2024-10-15 22:10:20,972:WARNING:The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.

2024-10-15 22:10:20,973:INFO:setup() successfully completed in 2.29s...............
2024-10-15 22:10:22,592:INFO:Initializing compare_models()
2024-10-15 22:10:22,592:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022349787610>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=10, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000022349787610>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 10, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-10-15 22:10:22,592:INFO:Checking exceptions
2024-10-15 22:10:22,596:INFO:Preparing display monitor
2024-10-15 22:10:22,643:INFO:Initializing Linear Regression
2024-10-15 22:10:22,643:INFO:Total runtime is 1.7599264780680338e-05 minutes
2024-10-15 22:10:22,647:INFO:SubProcess create_model() called ==================================
2024-10-15 22:10:22,647:INFO:Initializing create_model()
2024-10-15 22:10:22,647:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022349787610>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002233A5C7A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 22:10:22,647:INFO:Checking exceptions
2024-10-15 22:10:22,647:INFO:Importing libraries
2024-10-15 22:10:22,647:INFO:Copying training dataset
2024-10-15 22:10:22,654:INFO:Defining folds
2024-10-15 22:10:22,654:INFO:Declaring metric variables
2024-10-15 22:10:22,658:INFO:Importing untrained model
2024-10-15 22:10:22,664:INFO:Linear Regression Imported successfully
2024-10-15 22:10:22,673:INFO:Starting cross validation
2024-10-15 22:10:22,675:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-15 22:10:34,309:INFO:Calculating mean and std
2024-10-15 22:10:34,312:INFO:Creating metrics dataframe
2024-10-15 22:10:34,317:INFO:Uploading results into container
2024-10-15 22:10:34,317:INFO:Uploading model into container now
2024-10-15 22:10:34,318:INFO:_master_model_container: 1
2024-10-15 22:10:34,318:INFO:_display_container: 2
2024-10-15 22:10:34,318:INFO:LinearRegression(n_jobs=-1)
2024-10-15 22:10:34,318:INFO:create_model() successfully completed......................................
2024-10-15 22:10:34,537:INFO:SubProcess create_model() end ==================================
2024-10-15 22:10:34,537:INFO:Creating metrics dataframe
2024-10-15 22:10:34,548:INFO:Initializing Lasso Regression
2024-10-15 22:10:34,548:INFO:Total runtime is 0.19843589067459105 minutes
2024-10-15 22:10:34,552:INFO:SubProcess create_model() called ==================================
2024-10-15 22:10:34,553:INFO:Initializing create_model()
2024-10-15 22:10:34,553:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022349787610>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002233A5C7A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 22:10:34,553:INFO:Checking exceptions
2024-10-15 22:10:34,553:INFO:Importing libraries
2024-10-15 22:10:34,553:INFO:Copying training dataset
2024-10-15 22:10:34,560:INFO:Defining folds
2024-10-15 22:10:34,561:INFO:Declaring metric variables
2024-10-15 22:10:34,567:INFO:Importing untrained model
2024-10-15 22:10:34,571:INFO:Lasso Regression Imported successfully
2024-10-15 22:10:34,581:INFO:Starting cross validation
2024-10-15 22:10:34,584:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-15 22:10:35,060:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.538e+06, tolerance: 8.935e+02
  model = cd_fast.enet_coordinate_descent(

2024-10-15 22:10:35,339:INFO:Calculating mean and std
2024-10-15 22:10:35,341:INFO:Creating metrics dataframe
2024-10-15 22:10:35,345:INFO:Uploading results into container
2024-10-15 22:10:35,346:INFO:Uploading model into container now
2024-10-15 22:10:35,346:INFO:_master_model_container: 2
2024-10-15 22:10:35,347:INFO:_display_container: 2
2024-10-15 22:10:35,347:INFO:Lasso(random_state=123)
2024-10-15 22:10:35,347:INFO:create_model() successfully completed......................................
2024-10-15 22:10:35,555:INFO:SubProcess create_model() end ==================================
2024-10-15 22:10:35,555:INFO:Creating metrics dataframe
2024-10-15 22:10:35,567:INFO:Initializing Ridge Regression
2024-10-15 22:10:35,567:INFO:Total runtime is 0.21541736125946043 minutes
2024-10-15 22:10:35,570:INFO:SubProcess create_model() called ==================================
2024-10-15 22:10:35,570:INFO:Initializing create_model()
2024-10-15 22:10:35,570:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022349787610>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002233A5C7A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 22:10:35,571:INFO:Checking exceptions
2024-10-15 22:10:35,571:INFO:Importing libraries
2024-10-15 22:10:35,571:INFO:Copying training dataset
2024-10-15 22:10:35,578:INFO:Defining folds
2024-10-15 22:10:35,579:INFO:Declaring metric variables
2024-10-15 22:10:35,582:INFO:Importing untrained model
2024-10-15 22:10:35,586:INFO:Ridge Regression Imported successfully
2024-10-15 22:10:35,593:INFO:Starting cross validation
2024-10-15 22:10:35,596:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-15 22:10:36,394:INFO:Calculating mean and std
2024-10-15 22:10:36,395:INFO:Creating metrics dataframe
2024-10-15 22:10:36,399:INFO:Uploading results into container
2024-10-15 22:10:36,400:INFO:Uploading model into container now
2024-10-15 22:10:36,400:INFO:_master_model_container: 3
2024-10-15 22:10:36,400:INFO:_display_container: 2
2024-10-15 22:10:36,401:INFO:Ridge(random_state=123)
2024-10-15 22:10:36,401:INFO:create_model() successfully completed......................................
2024-10-15 22:10:36,601:INFO:SubProcess create_model() end ==================================
2024-10-15 22:10:36,601:INFO:Creating metrics dataframe
2024-10-15 22:10:36,613:INFO:Initializing Elastic Net
2024-10-15 22:10:36,613:INFO:Total runtime is 0.23284236590067542 minutes
2024-10-15 22:10:36,617:INFO:SubProcess create_model() called ==================================
2024-10-15 22:10:36,618:INFO:Initializing create_model()
2024-10-15 22:10:36,618:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022349787610>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002233A5C7A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 22:10:36,618:INFO:Checking exceptions
2024-10-15 22:10:36,618:INFO:Importing libraries
2024-10-15 22:10:36,618:INFO:Copying training dataset
2024-10-15 22:10:36,625:INFO:Defining folds
2024-10-15 22:10:36,625:INFO:Declaring metric variables
2024-10-15 22:10:36,630:INFO:Importing untrained model
2024-10-15 22:10:36,633:INFO:Elastic Net Imported successfully
2024-10-15 22:10:36,647:INFO:Starting cross validation
2024-10-15 22:10:36,651:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-15 22:10:37,216:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.645e+05, tolerance: 8.935e+02
  model = cd_fast.enet_coordinate_descent(

2024-10-15 22:10:37,495:INFO:Calculating mean and std
2024-10-15 22:10:37,496:INFO:Creating metrics dataframe
2024-10-15 22:10:37,500:INFO:Uploading results into container
2024-10-15 22:10:37,501:INFO:Uploading model into container now
2024-10-15 22:10:37,501:INFO:_master_model_container: 4
2024-10-15 22:10:37,501:INFO:_display_container: 2
2024-10-15 22:10:37,501:INFO:ElasticNet(random_state=123)
2024-10-15 22:10:37,502:INFO:create_model() successfully completed......................................
2024-10-15 22:10:37,758:INFO:SubProcess create_model() end ==================================
2024-10-15 22:10:37,759:INFO:Creating metrics dataframe
2024-10-15 22:10:37,779:INFO:Initializing Least Angle Regression
2024-10-15 22:10:37,779:INFO:Total runtime is 0.2522802591323852 minutes
2024-10-15 22:10:37,784:INFO:SubProcess create_model() called ==================================
2024-10-15 22:10:37,784:INFO:Initializing create_model()
2024-10-15 22:10:37,785:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022349787610>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002233A5C7A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 22:10:37,785:INFO:Checking exceptions
2024-10-15 22:10:37,785:INFO:Importing libraries
2024-10-15 22:10:37,785:INFO:Copying training dataset
2024-10-15 22:10:37,813:INFO:Defining folds
2024-10-15 22:10:37,813:INFO:Declaring metric variables
2024-10-15 22:10:37,820:INFO:Importing untrained model
2024-10-15 22:10:37,827:INFO:Least Angle Regression Imported successfully
2024-10-15 22:10:37,841:INFO:Starting cross validation
2024-10-15 22:10:37,845:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-15 22:10:38,215:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=4.350e+00, with an active set of 148 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,244:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 218 iterations, i.e. alpha=1.311e+00, with an active set of 183 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,247:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 222 iterations, i.e. alpha=1.353e+00, with an active set of 185 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,257:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 148 iterations, i.e. alpha=1.063e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,256:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 236 iterations, i.e. alpha=1.624e+01, with an active set of 188 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,260:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 236 iterations, i.e. alpha=1.579e+01, with an active set of 188 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,261:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 236 iterations, i.e. alpha=1.564e+01, with an active set of 188 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,261:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 236 iterations, i.e. alpha=1.561e+01, with an active set of 188 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,262:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 236 iterations, i.e. alpha=1.543e+01, with an active set of 188 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,264:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 237 iterations, i.e. alpha=1.548e+00, with an active set of 189 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,265:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 237 iterations, i.e. alpha=1.530e+00, with an active set of 189 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,266:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 237 iterations, i.e. alpha=1.506e+00, with an active set of 189 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,266:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 237 iterations, i.e. alpha=1.464e+00, with an active set of 189 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,311:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 154 iterations, i.e. alpha=5.754e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,318:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 215 iterations, i.e. alpha=5.388e+02, with an active set of 164 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,319:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 215 iterations, i.e. alpha=5.331e+02, with an active set of 164 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,330:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 213 iterations, i.e. alpha=3.761e+01, with an active set of 161 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,332:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 215 iterations, i.e. alpha=2.963e+01, with an active set of 162 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,335:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 218 iterations, i.e. alpha=2.631e+01, with an active set of 164 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,337:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 220 iterations, i.e. alpha=2.447e+01, with an active set of 166 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,343:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 223 iterations, i.e. alpha=2.369e+01, with an active set of 168 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,344:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 223 iterations, i.e. alpha=2.336e+01, with an active set of 168 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,345:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 224 iterations, i.e. alpha=2.229e+01, with an active set of 169 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,347:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 265 iterations, i.e. alpha=1.315e+03, with an active set of 189 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,348:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 265 iterations, i.e. alpha=1.305e+03, with an active set of 189 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,349:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 265 iterations, i.e. alpha=1.261e+03, with an active set of 189 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,349:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 241 iterations, i.e. alpha=1.160e+05, with an active set of 174 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,350:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 241 iterations, i.e. alpha=1.160e+05, with an active set of 174 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,350:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 241 iterations, i.e. alpha=1.160e+05, with an active set of 174 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,351:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=6.384e+02, with an active set of 190 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,351:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=6.140e+02, with an active set of 190 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,352:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=5.970e+02, with an active set of 190 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,352:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=5.846e+02, with an active set of 190 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,353:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 186 iterations, i.e. alpha=6.354e-01, with an active set of 149 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,353:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=3.517e+05, with an active set of 190 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,354:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 263 iterations, i.e. alpha=2.231e+05, with an active set of 191 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,355:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 263 iterations, i.e. alpha=1.762e+05, with an active set of 191 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,355:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 263 iterations, i.e. alpha=1.691e+04, with an active set of 191 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,359:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 242 iterations, i.e. alpha=1.631e+02, with an active set of 177 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,368:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 256 iterations, i.e. alpha=1.326e+04, with an active set of 183 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,368:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 235 iterations, i.e. alpha=4.518e+01, with an active set of 172 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,371:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 259 iterations, i.e. alpha=4.370e+03, with an active set of 185 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,371:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 259 iterations, i.e. alpha=4.107e+03, with an active set of 185 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,371:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 259 iterations, i.e. alpha=4.023e+03, with an active set of 185 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,372:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 276 iterations, i.e. alpha=2.169e+05, with an active set of 189 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,372:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 259 iterations, i.e. alpha=3.871e+03, with an active set of 185 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,373:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 259 iterations, i.e. alpha=3.867e+03, with an active set of 185 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,374:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 260 iterations, i.e. alpha=8.638e+02, with an active set of 186 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,373:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 276 iterations, i.e. alpha=2.145e+05, with an active set of 189 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,376:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 261 iterations, i.e. alpha=1.586e+02, with an active set of 187 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,377:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 261 iterations, i.e. alpha=1.515e+02, with an active set of 187 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,377:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 261 iterations, i.e. alpha=1.368e+02, with an active set of 187 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,378:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 247 iterations, i.e. alpha=9.116e+01, with an active set of 178 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,378:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 261 iterations, i.e. alpha=6.139e+01, with an active set of 187 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,375:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 276 iterations, i.e. alpha=1.830e+05, with an active set of 189 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,380:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 249 iterations, i.e. alpha=7.877e+01, with an active set of 180 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,380:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 276 iterations, i.e. alpha=1.079e+03, with an active set of 189 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,381:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 276 iterations, i.e. alpha=6.249e+02, with an active set of 189 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,384:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 255 iterations, i.e. alpha=7.339e+01, with an active set of 184 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,385:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 255 iterations, i.e. alpha=6.646e+01, with an active set of 184 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,385:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 255 iterations, i.e. alpha=4.489e+01, with an active set of 184 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,385:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 237 iterations, i.e. alpha=6.995e+02, with an active set of 167 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,385:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 255 iterations, i.e. alpha=4.446e+01, with an active set of 184 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,386:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 255 iterations, i.e. alpha=4.397e+01, with an active set of 184 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,389:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 260 iterations, i.e. alpha=3.495e+01, with an active set of 186 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,396:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 249 iterations, i.e. alpha=7.264e+02, with an active set of 174 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,398:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 251 iterations, i.e. alpha=5.961e+02, with an active set of 176 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,400:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 254 iterations, i.e. alpha=4.746e+02, with an active set of 178 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,405:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 263 iterations, i.e. alpha=3.816e+02, with an active set of 184 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,406:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 263 iterations, i.e. alpha=3.524e+02, with an active set of 184 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,408:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 265 iterations, i.e. alpha=2.470e+02, with an active set of 185 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,411:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=2.170e+02, with an active set of 187 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,414:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=4.853e+02, with an active set of 188 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,415:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=3.335e+02, with an active set of 188 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,415:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=3.014e+02, with an active set of 188 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,416:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=3.013e+02, with an active set of 188 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,717:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 205 iterations, i.e. alpha=2.162e+01, with an active set of 166 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,729:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 244 iterations, i.e. alpha=4.941e+02, with an active set of 186 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,731:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 247 iterations, i.e. alpha=8.197e+02, with an active set of 187 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,731:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 247 iterations, i.e. alpha=6.369e+02, with an active set of 187 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,732:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 249 iterations, i.e. alpha=1.753e+02, with an active set of 189 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,732:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 249 iterations, i.e. alpha=1.520e+02, with an active set of 189 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,733:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 249 iterations, i.e. alpha=9.086e+01, with an active set of 189 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,782:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 247 iterations, i.e. alpha=6.197e+03, with an active set of 182 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,783:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 248 iterations, i.e. alpha=2.918e+03, with an active set of 183 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,783:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 248 iterations, i.e. alpha=2.598e+03, with an active set of 183 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,783:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 248 iterations, i.e. alpha=2.474e+03, with an active set of 183 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,784:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 248 iterations, i.e. alpha=2.106e+03, with an active set of 183 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,784:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 249 iterations, i.e. alpha=1.156e+03, with an active set of 184 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,785:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 250 iterations, i.e. alpha=7.564e+02, with an active set of 185 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,785:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 250 iterations, i.e. alpha=5.814e+02, with an active set of 185 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,785:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 250 iterations, i.e. alpha=5.625e+02, with an active set of 185 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,786:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 250 iterations, i.e. alpha=5.432e+02, with an active set of 185 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,786:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 251 iterations, i.e. alpha=2.834e+01, with an active set of 186 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,786:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 251 iterations, i.e. alpha=9.084e+00, with an active set of 186 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,787:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 251 iterations, i.e. alpha=8.139e+00, with an active set of 186 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,787:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 251 iterations, i.e. alpha=8.028e+00, with an active set of 186 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-10-15 22:10:38,873:INFO:Calculating mean and std
2024-10-15 22:10:38,873:WARNING:overflow encountered in multiply

2024-10-15 22:10:38,875:INFO:Creating metrics dataframe
2024-10-15 22:10:38,882:INFO:Uploading results into container
2024-10-15 22:10:38,883:INFO:Uploading model into container now
2024-10-15 22:10:38,884:INFO:_master_model_container: 5
2024-10-15 22:10:38,884:INFO:_display_container: 2
2024-10-15 22:10:38,884:INFO:Lars(random_state=123)
2024-10-15 22:10:38,885:INFO:create_model() successfully completed......................................
2024-10-15 22:10:39,192:INFO:SubProcess create_model() end ==================================
2024-10-15 22:10:39,192:INFO:Creating metrics dataframe
2024-10-15 22:10:39,204:INFO:Initializing Lasso Least Angle Regression
2024-10-15 22:10:39,204:INFO:Total runtime is 0.27603373130162556 minutes
2024-10-15 22:10:39,210:INFO:SubProcess create_model() called ==================================
2024-10-15 22:10:39,211:INFO:Initializing create_model()
2024-10-15 22:10:39,211:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022349787610>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002233A5C7A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 22:10:39,212:INFO:Checking exceptions
2024-10-15 22:10:39,212:INFO:Importing libraries
2024-10-15 22:10:39,212:INFO:Copying training dataset
2024-10-15 22:10:39,218:INFO:Defining folds
2024-10-15 22:10:39,219:INFO:Declaring metric variables
2024-10-15 22:10:39,223:INFO:Importing untrained model
2024-10-15 22:10:39,230:INFO:Lasso Least Angle Regression Imported successfully
2024-10-15 22:10:39,239:INFO:Starting cross validation
2024-10-15 22:10:39,244:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-15 22:10:39,986:INFO:Calculating mean and std
2024-10-15 22:10:39,988:INFO:Creating metrics dataframe
2024-10-15 22:10:39,995:INFO:Uploading results into container
2024-10-15 22:10:39,997:INFO:Uploading model into container now
2024-10-15 22:10:39,997:INFO:_master_model_container: 6
2024-10-15 22:10:39,997:INFO:_display_container: 2
2024-10-15 22:10:39,998:INFO:LassoLars(random_state=123)
2024-10-15 22:10:39,998:INFO:create_model() successfully completed......................................
2024-10-15 22:10:40,210:INFO:SubProcess create_model() end ==================================
2024-10-15 22:10:40,210:INFO:Creating metrics dataframe
2024-10-15 22:10:40,223:INFO:Initializing Orthogonal Matching Pursuit
2024-10-15 22:10:40,223:INFO:Total runtime is 0.29301747083663937 minutes
2024-10-15 22:10:40,228:INFO:SubProcess create_model() called ==================================
2024-10-15 22:10:40,228:INFO:Initializing create_model()
2024-10-15 22:10:40,228:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022349787610>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002233A5C7A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 22:10:40,229:INFO:Checking exceptions
2024-10-15 22:10:40,229:INFO:Importing libraries
2024-10-15 22:10:40,229:INFO:Copying training dataset
2024-10-15 22:10:40,237:INFO:Defining folds
2024-10-15 22:10:40,237:INFO:Declaring metric variables
2024-10-15 22:10:40,243:INFO:Importing untrained model
2024-10-15 22:10:40,247:INFO:Orthogonal Matching Pursuit Imported successfully
2024-10-15 22:10:40,256:INFO:Starting cross validation
2024-10-15 22:10:40,260:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-15 22:10:41,077:INFO:Calculating mean and std
2024-10-15 22:10:41,078:INFO:Creating metrics dataframe
2024-10-15 22:10:41,082:INFO:Uploading results into container
2024-10-15 22:10:41,083:INFO:Uploading model into container now
2024-10-15 22:10:41,084:INFO:_master_model_container: 7
2024-10-15 22:10:41,084:INFO:_display_container: 2
2024-10-15 22:10:41,084:INFO:OrthogonalMatchingPursuit()
2024-10-15 22:10:41,085:INFO:create_model() successfully completed......................................
2024-10-15 22:10:41,311:INFO:SubProcess create_model() end ==================================
2024-10-15 22:10:41,311:INFO:Creating metrics dataframe
2024-10-15 22:10:41,328:INFO:Initializing Bayesian Ridge
2024-10-15 22:10:41,328:INFO:Total runtime is 0.31142784754435215 minutes
2024-10-15 22:10:41,332:INFO:SubProcess create_model() called ==================================
2024-10-15 22:10:41,332:INFO:Initializing create_model()
2024-10-15 22:10:41,332:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022349787610>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002233A5C7A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 22:10:41,333:INFO:Checking exceptions
2024-10-15 22:10:41,333:INFO:Importing libraries
2024-10-15 22:10:41,333:INFO:Copying training dataset
2024-10-15 22:10:41,343:INFO:Defining folds
2024-10-15 22:10:41,343:INFO:Declaring metric variables
2024-10-15 22:10:41,349:INFO:Importing untrained model
2024-10-15 22:10:41,354:INFO:Bayesian Ridge Imported successfully
2024-10-15 22:10:41,368:INFO:Starting cross validation
2024-10-15 22:10:41,376:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-15 22:10:42,312:INFO:Calculating mean and std
2024-10-15 22:10:42,313:INFO:Creating metrics dataframe
2024-10-15 22:10:42,317:INFO:Uploading results into container
2024-10-15 22:10:42,318:INFO:Uploading model into container now
2024-10-15 22:10:42,318:INFO:_master_model_container: 8
2024-10-15 22:10:42,319:INFO:_display_container: 2
2024-10-15 22:10:42,319:INFO:BayesianRidge()
2024-10-15 22:10:42,319:INFO:create_model() successfully completed......................................
2024-10-15 22:10:42,599:INFO:SubProcess create_model() end ==================================
2024-10-15 22:10:42,599:INFO:Creating metrics dataframe
2024-10-15 22:10:42,612:INFO:Initializing Passive Aggressive Regressor
2024-10-15 22:10:42,612:INFO:Total runtime is 0.3328370094299316 minutes
2024-10-15 22:10:42,617:INFO:SubProcess create_model() called ==================================
2024-10-15 22:10:42,617:INFO:Initializing create_model()
2024-10-15 22:10:42,617:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022349787610>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002233A5C7A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 22:10:42,617:INFO:Checking exceptions
2024-10-15 22:10:42,618:INFO:Importing libraries
2024-10-15 22:10:42,618:INFO:Copying training dataset
2024-10-15 22:10:42,625:INFO:Defining folds
2024-10-15 22:10:42,625:INFO:Declaring metric variables
2024-10-15 22:10:42,630:INFO:Importing untrained model
2024-10-15 22:10:42,635:INFO:Passive Aggressive Regressor Imported successfully
2024-10-15 22:10:42,645:INFO:Starting cross validation
2024-10-15 22:10:42,648:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-15 22:10:43,444:INFO:Calculating mean and std
2024-10-15 22:10:43,446:INFO:Creating metrics dataframe
2024-10-15 22:10:43,451:INFO:Uploading results into container
2024-10-15 22:10:43,451:INFO:Uploading model into container now
2024-10-15 22:10:43,452:INFO:_master_model_container: 9
2024-10-15 22:10:43,452:INFO:_display_container: 2
2024-10-15 22:10:43,452:INFO:PassiveAggressiveRegressor(random_state=123)
2024-10-15 22:10:43,452:INFO:create_model() successfully completed......................................
2024-10-15 22:10:43,662:INFO:SubProcess create_model() end ==================================
2024-10-15 22:10:43,662:INFO:Creating metrics dataframe
2024-10-15 22:10:43,708:INFO:Initializing Huber Regressor
2024-10-15 22:10:43,708:INFO:Total runtime is 0.35109916528066 minutes
2024-10-15 22:10:43,718:INFO:SubProcess create_model() called ==================================
2024-10-15 22:10:43,718:INFO:Initializing create_model()
2024-10-15 22:10:43,718:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022349787610>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002233A5C7A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 22:10:43,719:INFO:Checking exceptions
2024-10-15 22:10:43,719:INFO:Importing libraries
2024-10-15 22:10:43,719:INFO:Copying training dataset
2024-10-15 22:10:43,736:INFO:Defining folds
2024-10-15 22:10:43,737:INFO:Declaring metric variables
2024-10-15 22:10:43,782:INFO:Importing untrained model
2024-10-15 22:10:43,793:INFO:Huber Regressor Imported successfully
2024-10-15 22:10:43,820:INFO:Starting cross validation
2024-10-15 22:10:43,827:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-15 22:10:44,434:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-10-15 22:10:44,447:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-10-15 22:10:44,449:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-10-15 22:10:44,611:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-10-15 22:10:44,611:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-10-15 22:10:44,632:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-10-15 22:10:44,638:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-10-15 22:10:44,638:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-10-15 22:10:45,023:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-10-15 22:10:45,027:WARNING:c:\Users\genin\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-10-15 22:10:45,104:INFO:Calculating mean and std
2024-10-15 22:10:45,106:INFO:Creating metrics dataframe
2024-10-15 22:10:45,111:INFO:Uploading results into container
2024-10-15 22:10:45,111:INFO:Uploading model into container now
2024-10-15 22:10:45,112:INFO:_master_model_container: 10
2024-10-15 22:10:45,112:INFO:_display_container: 2
2024-10-15 22:10:45,112:INFO:HuberRegressor()
2024-10-15 22:10:45,112:INFO:create_model() successfully completed......................................
2024-10-15 22:10:45,319:INFO:SubProcess create_model() end ==================================
2024-10-15 22:10:45,319:INFO:Creating metrics dataframe
2024-10-15 22:10:45,340:INFO:Initializing K Neighbors Regressor
2024-10-15 22:10:45,340:INFO:Total runtime is 0.3782899220784505 minutes
2024-10-15 22:10:45,345:INFO:SubProcess create_model() called ==================================
2024-10-15 22:10:45,345:INFO:Initializing create_model()
2024-10-15 22:10:45,345:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022349787610>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002233A5C7A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 22:10:45,346:INFO:Checking exceptions
2024-10-15 22:10:45,346:INFO:Importing libraries
2024-10-15 22:10:45,346:INFO:Copying training dataset
2024-10-15 22:10:45,352:INFO:Defining folds
2024-10-15 22:10:45,352:INFO:Declaring metric variables
2024-10-15 22:10:45,360:INFO:Importing untrained model
2024-10-15 22:10:45,366:INFO:K Neighbors Regressor Imported successfully
2024-10-15 22:10:45,378:INFO:Starting cross validation
2024-10-15 22:10:45,380:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-15 22:10:46,290:INFO:Calculating mean and std
2024-10-15 22:10:46,292:INFO:Creating metrics dataframe
2024-10-15 22:10:46,297:INFO:Uploading results into container
2024-10-15 22:10:46,298:INFO:Uploading model into container now
2024-10-15 22:10:46,298:INFO:_master_model_container: 11
2024-10-15 22:10:46,298:INFO:_display_container: 2
2024-10-15 22:10:46,299:INFO:KNeighborsRegressor(n_jobs=-1)
2024-10-15 22:10:46,299:INFO:create_model() successfully completed......................................
2024-10-15 22:10:46,544:INFO:SubProcess create_model() end ==================================
2024-10-15 22:10:46,544:INFO:Creating metrics dataframe
2024-10-15 22:10:46,566:INFO:Initializing Decision Tree Regressor
2024-10-15 22:10:46,566:INFO:Total runtime is 0.39873002767562865 minutes
2024-10-15 22:10:46,574:INFO:SubProcess create_model() called ==================================
2024-10-15 22:10:46,575:INFO:Initializing create_model()
2024-10-15 22:10:46,575:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022349787610>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002233A5C7A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 22:10:46,575:INFO:Checking exceptions
2024-10-15 22:10:46,575:INFO:Importing libraries
2024-10-15 22:10:46,575:INFO:Copying training dataset
2024-10-15 22:10:46,583:INFO:Defining folds
2024-10-15 22:10:46,583:INFO:Declaring metric variables
2024-10-15 22:10:46,590:INFO:Importing untrained model
2024-10-15 22:10:46,596:INFO:Decision Tree Regressor Imported successfully
2024-10-15 22:10:46,614:INFO:Starting cross validation
2024-10-15 22:10:46,622:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-15 22:10:47,473:INFO:Calculating mean and std
2024-10-15 22:10:47,475:INFO:Creating metrics dataframe
2024-10-15 22:10:47,479:INFO:Uploading results into container
2024-10-15 22:10:47,480:INFO:Uploading model into container now
2024-10-15 22:10:47,480:INFO:_master_model_container: 12
2024-10-15 22:10:47,480:INFO:_display_container: 2
2024-10-15 22:10:47,481:INFO:DecisionTreeRegressor(random_state=123)
2024-10-15 22:10:47,481:INFO:create_model() successfully completed......................................
2024-10-15 22:10:47,762:INFO:SubProcess create_model() end ==================================
2024-10-15 22:10:47,762:INFO:Creating metrics dataframe
2024-10-15 22:10:47,786:INFO:Initializing Random Forest Regressor
2024-10-15 22:10:47,787:INFO:Total runtime is 0.4190853238105774 minutes
2024-10-15 22:10:47,793:INFO:SubProcess create_model() called ==================================
2024-10-15 22:10:47,794:INFO:Initializing create_model()
2024-10-15 22:10:47,794:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022349787610>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002233A5C7A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 22:10:47,794:INFO:Checking exceptions
2024-10-15 22:10:47,794:INFO:Importing libraries
2024-10-15 22:10:47,794:INFO:Copying training dataset
2024-10-15 22:10:47,803:INFO:Defining folds
2024-10-15 22:10:47,804:INFO:Declaring metric variables
2024-10-15 22:10:47,810:INFO:Importing untrained model
2024-10-15 22:10:47,816:INFO:Random Forest Regressor Imported successfully
2024-10-15 22:10:47,830:INFO:Starting cross validation
2024-10-15 22:10:47,834:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-15 22:10:52,225:INFO:Calculating mean and std
2024-10-15 22:10:52,227:INFO:Creating metrics dataframe
2024-10-15 22:10:52,231:INFO:Uploading results into container
2024-10-15 22:10:52,232:INFO:Uploading model into container now
2024-10-15 22:10:52,234:INFO:_master_model_container: 13
2024-10-15 22:10:52,234:INFO:_display_container: 2
2024-10-15 22:10:52,236:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-10-15 22:10:52,236:INFO:create_model() successfully completed......................................
2024-10-15 22:10:52,507:INFO:SubProcess create_model() end ==================================
2024-10-15 22:10:52,507:INFO:Creating metrics dataframe
2024-10-15 22:10:52,525:INFO:Initializing Extra Trees Regressor
2024-10-15 22:10:52,525:INFO:Total runtime is 0.49804792801539105 minutes
2024-10-15 22:10:52,529:INFO:SubProcess create_model() called ==================================
2024-10-15 22:10:52,530:INFO:Initializing create_model()
2024-10-15 22:10:52,530:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022349787610>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002233A5C7A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 22:10:52,530:INFO:Checking exceptions
2024-10-15 22:10:52,530:INFO:Importing libraries
2024-10-15 22:10:52,530:INFO:Copying training dataset
2024-10-15 22:10:52,541:INFO:Defining folds
2024-10-15 22:10:52,541:INFO:Declaring metric variables
2024-10-15 22:10:52,546:INFO:Importing untrained model
2024-10-15 22:10:52,552:INFO:Extra Trees Regressor Imported successfully
2024-10-15 22:10:52,564:INFO:Starting cross validation
2024-10-15 22:10:52,568:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-15 22:10:57,663:INFO:Calculating mean and std
2024-10-15 22:10:57,665:INFO:Creating metrics dataframe
2024-10-15 22:10:57,669:INFO:Uploading results into container
2024-10-15 22:10:57,670:INFO:Uploading model into container now
2024-10-15 22:10:57,670:INFO:_master_model_container: 14
2024-10-15 22:10:57,670:INFO:_display_container: 2
2024-10-15 22:10:57,671:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-10-15 22:10:57,671:INFO:create_model() successfully completed......................................
2024-10-15 22:10:57,921:INFO:SubProcess create_model() end ==================================
2024-10-15 22:10:57,922:INFO:Creating metrics dataframe
2024-10-15 22:10:57,938:INFO:Initializing AdaBoost Regressor
2024-10-15 22:10:57,938:INFO:Total runtime is 0.5882587671279907 minutes
2024-10-15 22:10:57,942:INFO:SubProcess create_model() called ==================================
2024-10-15 22:10:57,943:INFO:Initializing create_model()
2024-10-15 22:10:57,943:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022349787610>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002233A5C7A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 22:10:57,943:INFO:Checking exceptions
2024-10-15 22:10:57,943:INFO:Importing libraries
2024-10-15 22:10:57,943:INFO:Copying training dataset
2024-10-15 22:10:57,952:INFO:Defining folds
2024-10-15 22:10:57,952:INFO:Declaring metric variables
2024-10-15 22:10:57,957:INFO:Importing untrained model
2024-10-15 22:10:57,962:INFO:AdaBoost Regressor Imported successfully
2024-10-15 22:10:57,971:INFO:Starting cross validation
2024-10-15 22:10:57,975:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-15 22:10:59,898:INFO:Calculating mean and std
2024-10-15 22:10:59,900:INFO:Creating metrics dataframe
2024-10-15 22:10:59,904:INFO:Uploading results into container
2024-10-15 22:10:59,905:INFO:Uploading model into container now
2024-10-15 22:10:59,905:INFO:_master_model_container: 15
2024-10-15 22:10:59,905:INFO:_display_container: 2
2024-10-15 22:10:59,906:INFO:AdaBoostRegressor(random_state=123)
2024-10-15 22:10:59,906:INFO:create_model() successfully completed......................................
2024-10-15 22:11:00,188:INFO:SubProcess create_model() end ==================================
2024-10-15 22:11:00,188:INFO:Creating metrics dataframe
2024-10-15 22:11:00,218:INFO:Initializing Gradient Boosting Regressor
2024-10-15 22:11:00,218:INFO:Total runtime is 0.6262685736020406 minutes
2024-10-15 22:11:00,224:INFO:SubProcess create_model() called ==================================
2024-10-15 22:11:00,226:INFO:Initializing create_model()
2024-10-15 22:11:00,226:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022349787610>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002233A5C7A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 22:11:00,226:INFO:Checking exceptions
2024-10-15 22:11:00,226:INFO:Importing libraries
2024-10-15 22:11:00,227:INFO:Copying training dataset
2024-10-15 22:11:00,238:INFO:Defining folds
2024-10-15 22:11:00,238:INFO:Declaring metric variables
2024-10-15 22:11:00,246:INFO:Importing untrained model
2024-10-15 22:11:00,255:INFO:Gradient Boosting Regressor Imported successfully
2024-10-15 22:11:00,271:INFO:Starting cross validation
2024-10-15 22:11:00,277:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-15 22:11:02,530:INFO:Calculating mean and std
2024-10-15 22:11:02,532:INFO:Creating metrics dataframe
2024-10-15 22:11:02,539:INFO:Uploading results into container
2024-10-15 22:11:02,540:INFO:Uploading model into container now
2024-10-15 22:11:02,540:INFO:_master_model_container: 16
2024-10-15 22:11:02,542:INFO:_display_container: 2
2024-10-15 22:11:02,542:INFO:GradientBoostingRegressor(random_state=123)
2024-10-15 22:11:02,543:INFO:create_model() successfully completed......................................
2024-10-15 22:11:02,794:INFO:SubProcess create_model() end ==================================
2024-10-15 22:11:02,794:INFO:Creating metrics dataframe
2024-10-15 22:11:02,811:INFO:Initializing Extreme Gradient Boosting
2024-10-15 22:11:02,811:INFO:Total runtime is 0.6694842020670573 minutes
2024-10-15 22:11:02,815:INFO:SubProcess create_model() called ==================================
2024-10-15 22:11:02,816:INFO:Initializing create_model()
2024-10-15 22:11:02,816:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022349787610>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002233A5C7A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 22:11:02,816:INFO:Checking exceptions
2024-10-15 22:11:02,816:INFO:Importing libraries
2024-10-15 22:11:02,816:INFO:Copying training dataset
2024-10-15 22:11:02,825:INFO:Defining folds
2024-10-15 22:11:02,825:INFO:Declaring metric variables
2024-10-15 22:11:02,832:INFO:Importing untrained model
2024-10-15 22:11:02,839:INFO:Extreme Gradient Boosting Imported successfully
2024-10-15 22:11:02,852:INFO:Starting cross validation
2024-10-15 22:11:02,855:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-15 22:11:05,767:INFO:Calculating mean and std
2024-10-15 22:11:05,769:INFO:Creating metrics dataframe
2024-10-15 22:11:05,772:INFO:Uploading results into container
2024-10-15 22:11:05,773:INFO:Uploading model into container now
2024-10-15 22:11:05,773:INFO:_master_model_container: 17
2024-10-15 22:11:05,774:INFO:_display_container: 2
2024-10-15 22:11:05,775:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=123, ...)
2024-10-15 22:11:05,775:INFO:create_model() successfully completed......................................
2024-10-15 22:11:06,003:INFO:SubProcess create_model() end ==================================
2024-10-15 22:11:06,003:INFO:Creating metrics dataframe
2024-10-15 22:11:06,024:INFO:Initializing Light Gradient Boosting Machine
2024-10-15 22:11:06,024:INFO:Total runtime is 0.7230234225591023 minutes
2024-10-15 22:11:06,031:INFO:SubProcess create_model() called ==================================
2024-10-15 22:11:06,031:INFO:Initializing create_model()
2024-10-15 22:11:06,032:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022349787610>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002233A5C7A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 22:11:06,032:INFO:Checking exceptions
2024-10-15 22:11:06,032:INFO:Importing libraries
2024-10-15 22:11:06,032:INFO:Copying training dataset
2024-10-15 22:11:06,040:INFO:Defining folds
2024-10-15 22:11:06,041:INFO:Declaring metric variables
2024-10-15 22:11:06,049:INFO:Importing untrained model
2024-10-15 22:11:06,057:INFO:Light Gradient Boosting Machine Imported successfully
2024-10-15 22:11:06,072:INFO:Starting cross validation
2024-10-15 22:11:06,078:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-15 22:11:07,854:INFO:Calculating mean and std
2024-10-15 22:11:07,856:INFO:Creating metrics dataframe
2024-10-15 22:11:07,863:INFO:Uploading results into container
2024-10-15 22:11:07,864:INFO:Uploading model into container now
2024-10-15 22:11:07,865:INFO:_master_model_container: 18
2024-10-15 22:11:07,865:INFO:_display_container: 2
2024-10-15 22:11:07,866:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-10-15 22:11:07,866:INFO:create_model() successfully completed......................................
2024-10-15 22:11:08,111:INFO:SubProcess create_model() end ==================================
2024-10-15 22:11:08,111:INFO:Creating metrics dataframe
2024-10-15 22:11:08,127:INFO:Initializing CatBoost Regressor
2024-10-15 22:11:08,127:INFO:Total runtime is 0.7580840587615967 minutes
2024-10-15 22:11:08,132:INFO:SubProcess create_model() called ==================================
2024-10-15 22:11:08,132:INFO:Initializing create_model()
2024-10-15 22:11:08,132:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022349787610>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002233A5C7A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 22:11:08,132:INFO:Checking exceptions
2024-10-15 22:11:08,132:INFO:Importing libraries
2024-10-15 22:11:08,132:INFO:Copying training dataset
2024-10-15 22:11:08,140:INFO:Defining folds
2024-10-15 22:11:08,140:INFO:Declaring metric variables
2024-10-15 22:11:08,146:INFO:Importing untrained model
2024-10-15 22:11:08,150:INFO:CatBoost Regressor Imported successfully
2024-10-15 22:11:08,161:INFO:Starting cross validation
2024-10-15 22:11:08,164:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-15 22:11:39,407:INFO:Calculating mean and std
2024-10-15 22:11:39,409:INFO:Creating metrics dataframe
2024-10-15 22:11:39,413:INFO:Uploading results into container
2024-10-15 22:11:39,414:INFO:Uploading model into container now
2024-10-15 22:11:39,414:INFO:_master_model_container: 19
2024-10-15 22:11:39,414:INFO:_display_container: 2
2024-10-15 22:11:39,414:INFO:<catboost.core.CatBoostRegressor object at 0x000002235C0A3820>
2024-10-15 22:11:39,414:INFO:create_model() successfully completed......................................
2024-10-15 22:11:39,631:INFO:SubProcess create_model() end ==================================
2024-10-15 22:11:39,631:INFO:Creating metrics dataframe
2024-10-15 22:11:39,649:INFO:Initializing Dummy Regressor
2024-10-15 22:11:39,649:INFO:Total runtime is 1.2834403713544211 minutes
2024-10-15 22:11:39,653:INFO:SubProcess create_model() called ==================================
2024-10-15 22:11:39,653:INFO:Initializing create_model()
2024-10-15 22:11:39,653:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022349787610>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002233A5C7A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 22:11:39,653:INFO:Checking exceptions
2024-10-15 22:11:39,653:INFO:Importing libraries
2024-10-15 22:11:39,654:INFO:Copying training dataset
2024-10-15 22:11:39,661:INFO:Defining folds
2024-10-15 22:11:39,662:INFO:Declaring metric variables
2024-10-15 22:11:39,667:INFO:Importing untrained model
2024-10-15 22:11:39,673:INFO:Dummy Regressor Imported successfully
2024-10-15 22:11:39,682:INFO:Starting cross validation
2024-10-15 22:11:39,685:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-15 22:11:40,412:INFO:Calculating mean and std
2024-10-15 22:11:40,413:INFO:Creating metrics dataframe
2024-10-15 22:11:40,417:INFO:Uploading results into container
2024-10-15 22:11:40,418:INFO:Uploading model into container now
2024-10-15 22:11:40,418:INFO:_master_model_container: 20
2024-10-15 22:11:40,418:INFO:_display_container: 2
2024-10-15 22:11:40,418:INFO:DummyRegressor()
2024-10-15 22:11:40,418:INFO:create_model() successfully completed......................................
2024-10-15 22:11:40,623:INFO:SubProcess create_model() end ==================================
2024-10-15 22:11:40,623:INFO:Creating metrics dataframe
2024-10-15 22:11:40,652:INFO:Initializing create_model()
2024-10-15 22:11:40,653:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022349787610>, estimator=<catboost.core.CatBoostRegressor object at 0x000002235C0A3820>, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 22:11:40,653:INFO:Checking exceptions
2024-10-15 22:11:40,654:INFO:Importing libraries
2024-10-15 22:11:40,654:INFO:Copying training dataset
2024-10-15 22:11:40,663:INFO:Defining folds
2024-10-15 22:11:40,663:INFO:Declaring metric variables
2024-10-15 22:11:40,663:INFO:Importing untrained model
2024-10-15 22:11:40,663:INFO:Declaring custom model
2024-10-15 22:11:40,664:INFO:CatBoost Regressor Imported successfully
2024-10-15 22:11:40,666:INFO:Cross validation set to False
2024-10-15 22:11:40,666:INFO:Fitting Model
2024-10-15 22:11:46,103:INFO:<catboost.core.CatBoostRegressor object at 0x0000022343ADD480>
2024-10-15 22:11:46,104:INFO:create_model() successfully completed......................................
2024-10-15 22:11:46,324:INFO:Initializing create_model()
2024-10-15 22:11:46,324:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022349787610>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 22:11:46,325:INFO:Checking exceptions
2024-10-15 22:11:46,327:INFO:Importing libraries
2024-10-15 22:11:46,327:INFO:Copying training dataset
2024-10-15 22:11:46,336:INFO:Defining folds
2024-10-15 22:11:46,336:INFO:Declaring metric variables
2024-10-15 22:11:46,336:INFO:Importing untrained model
2024-10-15 22:11:46,337:INFO:Declaring custom model
2024-10-15 22:11:46,338:INFO:Light Gradient Boosting Machine Imported successfully
2024-10-15 22:11:46,341:INFO:Cross validation set to False
2024-10-15 22:11:46,341:INFO:Fitting Model
2024-10-15 22:11:46,479:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-10-15 22:11:46,483:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001010 seconds.
2024-10-15 22:11:46,483:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-10-15 22:11:46,483:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-10-15 22:11:46,484:INFO:[LightGBM] [Info] Total Bins 718
2024-10-15 22:11:46,484:INFO:[LightGBM] [Info] Number of data points in the train set: 473, number of used features: 185
2024-10-15 22:11:46,486:INFO:[LightGBM] [Info] Start training from score 334.169356
2024-10-15 22:11:46,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-15 22:11:46,577:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-10-15 22:11:46,577:INFO:create_model() successfully completed......................................
2024-10-15 22:11:46,807:INFO:Initializing create_model()
2024-10-15 22:11:46,808:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022349787610>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 22:11:46,808:INFO:Checking exceptions
2024-10-15 22:11:46,810:INFO:Importing libraries
2024-10-15 22:11:46,810:INFO:Copying training dataset
2024-10-15 22:11:46,816:INFO:Defining folds
2024-10-15 22:11:46,816:INFO:Declaring metric variables
2024-10-15 22:11:46,817:INFO:Importing untrained model
2024-10-15 22:11:46,817:INFO:Declaring custom model
2024-10-15 22:11:46,817:INFO:Random Forest Regressor Imported successfully
2024-10-15 22:11:46,821:INFO:Cross validation set to False
2024-10-15 22:11:46,821:INFO:Fitting Model
2024-10-15 22:11:47,309:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-10-15 22:11:47,309:INFO:create_model() successfully completed......................................
2024-10-15 22:11:47,530:INFO:Initializing create_model()
2024-10-15 22:11:47,530:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022349787610>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 22:11:47,530:INFO:Checking exceptions
2024-10-15 22:11:47,534:INFO:Importing libraries
2024-10-15 22:11:47,534:INFO:Copying training dataset
2024-10-15 22:11:47,542:INFO:Defining folds
2024-10-15 22:11:47,542:INFO:Declaring metric variables
2024-10-15 22:11:47,542:INFO:Importing untrained model
2024-10-15 22:11:47,543:INFO:Declaring custom model
2024-10-15 22:11:47,544:INFO:Gradient Boosting Regressor Imported successfully
2024-10-15 22:11:47,548:INFO:Cross validation set to False
2024-10-15 22:11:47,548:INFO:Fitting Model
2024-10-15 22:11:47,982:INFO:GradientBoostingRegressor(random_state=123)
2024-10-15 22:11:47,982:INFO:create_model() successfully completed......................................
2024-10-15 22:11:48,176:INFO:Initializing create_model()
2024-10-15 22:11:48,176:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022349787610>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 22:11:48,176:INFO:Checking exceptions
2024-10-15 22:11:48,179:INFO:Importing libraries
2024-10-15 22:11:48,179:INFO:Copying training dataset
2024-10-15 22:11:48,184:INFO:Defining folds
2024-10-15 22:11:48,184:INFO:Declaring metric variables
2024-10-15 22:11:48,184:INFO:Importing untrained model
2024-10-15 22:11:48,184:INFO:Declaring custom model
2024-10-15 22:11:48,185:INFO:Extra Trees Regressor Imported successfully
2024-10-15 22:11:48,187:INFO:Cross validation set to False
2024-10-15 22:11:48,187:INFO:Fitting Model
2024-10-15 22:11:48,696:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-10-15 22:11:48,696:INFO:create_model() successfully completed......................................
2024-10-15 22:11:48,914:INFO:Initializing create_model()
2024-10-15 22:11:48,914:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022349787610>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=123, ...), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 22:11:48,914:INFO:Checking exceptions
2024-10-15 22:11:48,916:INFO:Importing libraries
2024-10-15 22:11:48,916:INFO:Copying training dataset
2024-10-15 22:11:48,923:INFO:Defining folds
2024-10-15 22:11:48,925:INFO:Declaring metric variables
2024-10-15 22:11:48,925:INFO:Importing untrained model
2024-10-15 22:11:48,925:INFO:Declaring custom model
2024-10-15 22:11:48,926:INFO:Extreme Gradient Boosting Imported successfully
2024-10-15 22:11:48,928:INFO:Cross validation set to False
2024-10-15 22:11:48,928:INFO:Fitting Model
2024-10-15 22:11:49,361:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=123, ...)
2024-10-15 22:11:49,361:INFO:create_model() successfully completed......................................
2024-10-15 22:11:49,602:INFO:Initializing create_model()
2024-10-15 22:11:49,602:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022349787610>, estimator=KNeighborsRegressor(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 22:11:49,602:INFO:Checking exceptions
2024-10-15 22:11:49,605:INFO:Importing libraries
2024-10-15 22:11:49,605:INFO:Copying training dataset
2024-10-15 22:11:49,611:INFO:Defining folds
2024-10-15 22:11:49,611:INFO:Declaring metric variables
2024-10-15 22:11:49,611:INFO:Importing untrained model
2024-10-15 22:11:49,611:INFO:Declaring custom model
2024-10-15 22:11:49,612:INFO:K Neighbors Regressor Imported successfully
2024-10-15 22:11:49,614:INFO:Cross validation set to False
2024-10-15 22:11:49,614:INFO:Fitting Model
2024-10-15 22:11:49,745:INFO:KNeighborsRegressor(n_jobs=-1)
2024-10-15 22:11:49,745:INFO:create_model() successfully completed......................................
2024-10-15 22:11:49,945:INFO:Initializing create_model()
2024-10-15 22:11:49,945:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022349787610>, estimator=DecisionTreeRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 22:11:49,946:INFO:Checking exceptions
2024-10-15 22:11:49,948:INFO:Importing libraries
2024-10-15 22:11:49,948:INFO:Copying training dataset
2024-10-15 22:11:49,954:INFO:Defining folds
2024-10-15 22:11:49,954:INFO:Declaring metric variables
2024-10-15 22:11:49,954:INFO:Importing untrained model
2024-10-15 22:11:49,954:INFO:Declaring custom model
2024-10-15 22:11:49,955:INFO:Decision Tree Regressor Imported successfully
2024-10-15 22:11:49,957:INFO:Cross validation set to False
2024-10-15 22:11:49,957:INFO:Fitting Model
2024-10-15 22:11:50,085:INFO:DecisionTreeRegressor(random_state=123)
2024-10-15 22:11:50,085:INFO:create_model() successfully completed......................................
2024-10-15 22:11:50,284:INFO:Initializing create_model()
2024-10-15 22:11:50,284:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022349787610>, estimator=AdaBoostRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 22:11:50,284:INFO:Checking exceptions
2024-10-15 22:11:50,287:INFO:Importing libraries
2024-10-15 22:11:50,288:INFO:Copying training dataset
2024-10-15 22:11:50,293:INFO:Defining folds
2024-10-15 22:11:50,293:INFO:Declaring metric variables
2024-10-15 22:11:50,293:INFO:Importing untrained model
2024-10-15 22:11:50,293:INFO:Declaring custom model
2024-10-15 22:11:50,294:INFO:AdaBoost Regressor Imported successfully
2024-10-15 22:11:50,296:INFO:Cross validation set to False
2024-10-15 22:11:50,296:INFO:Fitting Model
2024-10-15 22:11:50,636:INFO:AdaBoostRegressor(random_state=123)
2024-10-15 22:11:50,636:INFO:create_model() successfully completed......................................
2024-10-15 22:11:50,834:INFO:Initializing create_model()
2024-10-15 22:11:50,834:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022349787610>, estimator=DummyRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-15 22:11:50,834:INFO:Checking exceptions
2024-10-15 22:11:50,837:INFO:Importing libraries
2024-10-15 22:11:50,837:INFO:Copying training dataset
2024-10-15 22:11:50,842:INFO:Defining folds
2024-10-15 22:11:50,842:INFO:Declaring metric variables
2024-10-15 22:11:50,842:INFO:Importing untrained model
2024-10-15 22:11:50,842:INFO:Declaring custom model
2024-10-15 22:11:50,843:INFO:Dummy Regressor Imported successfully
2024-10-15 22:11:50,845:INFO:Cross validation set to False
2024-10-15 22:11:50,845:INFO:Fitting Model
2024-10-15 22:11:50,950:INFO:DummyRegressor()
2024-10-15 22:11:50,950:INFO:create_model() successfully completed......................................
2024-10-15 22:11:51,172:INFO:_master_model_container: 20
2024-10-15 22:11:51,172:INFO:_display_container: 2
2024-10-15 22:11:51,174:INFO:[<catboost.core.CatBoostRegressor object at 0x0000022343ADD480>, LGBMRegressor(n_jobs=-1, random_state=123), RandomForestRegressor(n_jobs=-1, random_state=123), GradientBoostingRegressor(random_state=123), ExtraTreesRegressor(n_jobs=-1, random_state=123), XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=123, ...), KNeighborsRegressor(n_jobs=-1), DecisionTreeRegressor(random_state=123), AdaBoostRegressor(random_state=123), DummyRegressor()]
2024-10-15 22:11:51,174:INFO:compare_models() successfully completed......................................
2024-10-15 22:11:57,174:INFO:Initializing plot_model()
2024-10-15 22:11:57,174:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=<catboost.core.CatBoostRegressor object at 0x0000022343ADD480>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=3, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022349787610>, system=True)
2024-10-15 22:11:57,174:INFO:Checking exceptions
2024-10-15 22:11:57,179:INFO:Preloading libraries
2024-10-15 22:11:57,182:INFO:Copying training dataset
2024-10-15 22:11:57,182:INFO:Plot type: error
2024-10-15 22:11:57,637:INFO:Fitting Model
2024-10-15 22:11:57,638:INFO:Scoring test/hold-out set
2024-10-15 22:11:57,933:INFO:Visual Rendered Successfully
2024-10-15 22:11:58,135:INFO:plot_model() successfully completed......................................
2024-10-15 22:11:58,136:INFO:Initializing plot_model()
2024-10-15 22:11:58,136:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=3, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022349787610>, system=True)
2024-10-15 22:11:58,136:INFO:Checking exceptions
2024-10-15 22:11:58,140:INFO:Preloading libraries
2024-10-15 22:11:58,145:INFO:Copying training dataset
2024-10-15 22:11:58,145:INFO:Plot type: error
2024-10-15 22:11:58,672:INFO:Fitting Model
2024-10-15 22:11:58,673:INFO:Scoring test/hold-out set
2024-10-15 22:11:58,989:INFO:Visual Rendered Successfully
2024-10-15 22:11:59,188:INFO:plot_model() successfully completed......................................
2024-10-15 22:13:01,418:INFO:Initializing plot_model()
2024-10-15 22:13:01,418:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022349787610>, system=True)
2024-10-15 22:13:01,418:INFO:Checking exceptions
2024-10-15 22:13:01,422:INFO:Preloading libraries
2024-10-15 22:13:01,430:INFO:Copying training dataset
2024-10-15 22:13:01,430:INFO:Plot type: feature
2024-10-15 22:13:01,431:WARNING:No coef_ found. Trying feature_importances_
2024-10-15 22:13:01,658:INFO:Visual Rendered Successfully
2024-10-15 22:13:01,841:INFO:plot_model() successfully completed......................................
2024-10-15 22:13:05,523:INFO:Initializing interpret_model()
2024-10-15 22:13:05,523:INFO:interpret_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022349787610>)
2024-10-15 22:13:05,523:INFO:Checking exceptions
2024-10-15 22:13:05,523:INFO:Soft dependency imported: shap: 0.44.1
2024-10-15 22:13:05,553:INFO:plot type: summary
2024-10-15 22:13:05,553:INFO:Creating TreeExplainer
2024-10-15 22:13:05,599:INFO:Compiling shap values
2024-10-15 22:13:06,070:INFO:Visual Rendered Successfully
2024-10-15 22:13:06,070:INFO:interpret_model() successfully completed......................................
2024-10-15 22:13:10,865:INFO:Initializing predict_model()
2024-10-15 22:13:10,865:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022349787610>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022343AC6EF0>)
2024-10-15 22:13:10,865:INFO:Checking exceptions
2024-10-15 22:13:10,865:INFO:Preloading libraries
2024-10-15 22:13:10,868:INFO:Set up data.
2024-10-15 22:13:10,928:INFO:Set up index.
2024-10-15 22:13:11,018:WARNING:'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.

